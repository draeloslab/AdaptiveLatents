{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T14:52:22.302768Z",
     "start_time": "2023-05-03T14:52:21.752294Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "all_inline = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Individual analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Individial file discovery/loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list recently created files\n",
    "\n",
    "files = glob.glob(\"*pickle\")\n",
    "files.sort()\n",
    "files[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select file to use for br\n",
    "\n",
    "file = 'bubblewrap_run_2023-09-01-12-03-51.pickle'\n",
    "file = files[-1]\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load br\n",
    "\n",
    "with open(file, \"rb\") as fhan:\n",
    "    br = pickle.load(fhan)\n",
    "\n",
    "br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "br.behavior_pred_history[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.squeeze(br.behavior_pred_history[1][-1000:])\n",
    "err = np.squeeze(br.behavior_error_history[1][-1000:])\n",
    "\n",
    "true = pred-err\n",
    "\n",
    "# plt.plot(true)\n",
    "plt.plot(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(-pred + err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.corrcoef(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_offsets = br.data_source.time_offsets\n",
    "plt.plot(time_offsets,[np.nanmean(br.behavior_error_history[i]**2) for i in time_offsets], '.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show error over time\n",
    "\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "for offset in time_offsets:\n",
    "    ax.plot((br.behavior_error_history[offset]**2), '-', label=f\"{offset}\")\n",
    "ax.set_ylabel(\"squared error\")\n",
    "ax.legend();\n",
    "ax.set_xlabel(\"time\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show error over time\n",
    "\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "offset = 1\n",
    "ax.plot((br.behavior_error_history[offset]), '-', label=f\"{offset}\")\n",
    "ax.set_ylabel(\"squared error\")\n",
    "ax.legend();\n",
    "ax.set_xlabel(\"time\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_files = glob.glob(\"*pickle\")\n",
    "g_files.sort()\n",
    "\n",
    "# 2023-10-03-13-57-46\n",
    "# 2023-10-03-13-57-46\n",
    "files = [\n",
    "    # 'bubblewrap_run_2023-06-15-15-29-33.pickle',\n",
    "] + g_files[-22*2:]\n",
    "\n",
    "brs = []\n",
    "for file in files:\n",
    "    with open(file, \"rb\") as fhan:\n",
    "        br = pickle.load(fhan)\n",
    "    brs.append(br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# bslice = brs[-18*2-2:-18*1-2]\n",
    "bslice = brs[-18:]\n",
    "for i, br in enumerate(bslice):\n",
    "    ts = br.pickle_file[-18:-7].split(\"-\")\n",
    "    ax.plot(i,int(ts[0])*60*60*24 +int(ts[1])*60*60 + int(ts[2])*60 + int(ts[3]), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=6, figsize=(20,10), layout='tight')\n",
    "\n",
    "input_keys = ['z(s(neural))', 'z(behavior)', 'z([s(neural), behavior])', 's3(z([p(neural), behavior]))', 's1(z([p(neural), behavior]))', 's1(z(s(neural)))']\n",
    "output_keys = ['behavior', 's1(z(s(neural)))', 's1(z([s(neural), behavior]))']\n",
    "\n",
    "\n",
    "for i in range(len(bslice)):\n",
    "\n",
    "    r,c = np.unravel_index(i, (6,3))\n",
    "\n",
    "    pred = bslice[i].behavior_pred_history[1][-1000:]\n",
    "    err = np.squeeze(bslice[i].behavior_error_history[1][-1000:])\n",
    "    \n",
    "    true = pred-err\n",
    "\n",
    "    ax[c,r].plot(true)\n",
    "    ax[c,r].plot(pred)\n",
    "    ax[c,r].text(.01,.99,f\"{np.corrcoef(pred, true)[0,1]:.2f}\", ha='left', va='top', transform=ax[c,r].transAxes)\n",
    "    \n",
    "    if c == 0:\n",
    "        ax[c,r].set_title(input_keys[r])\n",
    "    if r == 0:\n",
    "        ax[c,r].set_ylabel(output_keys[c])\n",
    "fig.savefig(\"table.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "br.prediction_history[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "pred = bslice[i].behavior_pred_history[1][-1000:]\n",
    "err = np.squeeze(bslice[i].behavior_error_history[1][-1000:])\n",
    "true0 = pred-err\n",
    "i=2\n",
    "pred = bslice[i].behavior_pred_history[1][-1000:]\n",
    "err = np.squeeze(bslice[i].behavior_error_history[1][-1000:])\n",
    "true2 = pred-err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(true0,true2,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs, beh = fin.get_from_saved_npz(\"jpca_reduced_sc.npz\")\n",
    "\n",
    "concatenated = fin.zscore(np.hstack([obs, beh]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import bubblewrap.plotting_functions as bpf\n",
    "import bubblewrap.input_sources.functional as fin\n",
    "reload(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpf.compare_metrics(brs, offset=1, colors=[\"C0\"]*4 + [\"C1\"]*4 + [\"C2\"]*4 + [\"C3\"]*4, show_legend=False, show_title=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summarize(brs):\n",
    "    b = np.mean([br.behavior_error_history[1][-400:]**2 for br in brs])\n",
    "    p = np.mean([br.prediction_history[1][-400:] for br in brs])\n",
    "    e = np.mean([br.entropy_history[1][-400:] for br in brs])\n",
    "    d = {\"behavior mse\":b, \"log pred p\":p, \"entropy\":e}\n",
    "    for k in [\"B_thresh\", \"copy_row_on_teleport\"]:\n",
    "        for br in brs:\n",
    "            assert getattr(brs[0].bw, k) == getattr(br.bw, k)\n",
    "        d[k] = getattr(brs[0].bw, k)\n",
    "    return d\n",
    "\n",
    "pd.DataFrame(\n",
    "[summarize(brs[0:4]),\n",
    "summarize(brs[4:8]),\n",
    "summarize(brs[8:12]),\n",
    "summarize(brs[12:16]),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for seed in [0, 33, 75, 100]:\n",
    "    data_source = jpca_dataset_with_time_as_behavior()\n",
    "    data_source.drop_first_n_timesteps(seed)\n",
    "    bw = Bubblewrap(seed=seed)\n",
    "    run_bubblewrap()\n",
    "    save_result()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "u, s, vh = np.linalg.svd(brs[0].alpha_history, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(u[:,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(vh.T[:,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(vh);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "plt.imshow(brs[0].alpha_history, aspect='auto', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.linalg.svd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "middle = brs[0].prediction_history[1].shape[0]//2\n",
    "for br in brs:\n",
    "    l.append(br.prediction_history[1][middle:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.mean(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.std(l,ddof=1)/np.sqrt(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "brs[0].pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs,beh = br.data_source.get_history()\n",
    "beh = beh[-len(br.alpha_history):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "beh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "u,s,vh = np.linalg.svd(br.alpha_history, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "u,s,vh = np.linalg.svd(br.alpha_history[np.squeeze(beh==1)], full_matrices=False)\n",
    "plt.plot(vh[:5,:].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(br.alpha_history[np.squeeze(beh==1)] - br.alpha_history[np.squeeze(beh==2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(s)/s.sum(), '.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = []\n",
    "# df.append(dict(\n",
    "#     data_in=\"f[:,0]\",\n",
    "#     data_predicted=\"f[:,0]\",\n",
    "#     updated_alpha=False,\n",
    "#     file=\"bubblewrap_run_2023-06-13-14-52-42.pickle\"\n",
    "# ))\n",
    "\n",
    "# df.append(dict(\n",
    "#     data_in=\"psvd(n)[:,:6]\",\n",
    "#     data_predicted=\"f[:,0]\",\n",
    "#     updated_alpha=False,\n",
    "#     file=\"bubblewrap_run_2023-06-13-14-54-38.pickle\"\n",
    "# ))\n",
    "\n",
    "\n",
    "# df.append(dict(\n",
    "#     data_in=\"[psvd(n)[:,:6], f[:,0]]\",\n",
    "#     data_predicted=\"f[:,0]\",\n",
    "#     updated_alpha=False,\n",
    "#     file=\"bubblewrap_run_2023-06-13-14-57-42.pickle\"\n",
    "# ))\n",
    "\n",
    "\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f[:20k,0]\",\n",
    "    data_predicted=\"f[:20k+n,0]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-13-15-53-29.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"psvd(n)[:20k,:6]\",\n",
    "    data_predicted=\"f[:20k+n,0]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-13-15-10-19.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6], f[:20k,0]]\",\n",
    "    data_predicted=\"f[:20k+n,0]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-13-15-12-21.pickle\"\n",
    "))\n",
    "\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6], f[:20k,0]]\",\n",
    "    data_predicted=\"psvd(n)[:20k+n,0]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-13-15-25-50.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"psvd(n)[:20k,:6]\",\n",
    "    data_predicted=\"psvd(n)[:20k+n,0]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-13-15-27-02.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f[:20k,0]\",\n",
    "    data_predicted=\"psvd(n)[:20k+n,0]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-13-16-02-33.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"psvd(n)[:20k,:6]\",\n",
    "    data_predicted=\"f[:20k+n,:]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-09-21-15.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6], f[:20k,:]]\",\n",
    "    data_predicted=\"f[:20k+n,:]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-09-25-02.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f[:20k,:]\",\n",
    "    data_predicted=\"f[:20k+n,:]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-09-26-36.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6], f[:20k,1:]]\",\n",
    "    data_predicted=\"f[:20k+n,0]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-09-31-27.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6], f[:20k,:2]]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-09-33-36.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6], f[:20k,:2]]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=5,\n",
    "    file=\"bubblewrap_run_2023-06-14-09-52-32.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6], f[:20k,:2]]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=10,\n",
    "    file=\"bubblewrap_run_2023-06-14-09-55-19.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6], f[:20k,:2]]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=20,\n",
    "    file=\"bubblewrap_run_2023-06-14-09-46-35.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f[:20k,:2]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-10-04-05.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f[:20k,:2]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=5,\n",
    "    file=\"bubblewrap_run_2023-06-14-09-59-56.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f[:20k,:2]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=10,\n",
    "    file=\"bubblewrap_run_2023-06-14-10-02-10.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f[:20k,:2]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=50,\n",
    "    file=\"bubblewrap_run_2023-06-14-11-18-18.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f[:20k,:2]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=99,\n",
    "    file=\"bubblewrap_run_2023-06-14-10-40-34.pickle\"\n",
    "))\n",
    "\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f[:20k,:2]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=100,\n",
    "    file=\"bubblewrap_run_2023-06-14-10-08-48.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f[:20k,:2]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=101,\n",
    "    file=\"bubblewrap_run_2023-06-14-10-38-50.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f[:20k,:2]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=150,\n",
    "    file=\"bubblewrap_run_2023-06-14-10-37-02.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f[:20k,:2]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=200,\n",
    "    file=\"bubblewrap_run_2023-06-14-10-35-03.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f[:20k,:2]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=500,\n",
    "    file=\"bubblewrap_run_2023-06-14-10-30-11.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f[:20k,:2]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=1000,\n",
    "    file=\"bubblewrap_run_2023-06-14-10-31-59.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6], f[:20k,:2]]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=50,\n",
    "    file=\"bubblewrap_run_2023-06-14-11-14-57.pickle\"\n",
    "))\n",
    "\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6], f[:20k,:2]]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=100,\n",
    "    file=\"bubblewrap_run_2023-06-14-10-50-08.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6], f[:20k,:2]]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=200,\n",
    "    file=\"bubblewrap_run_2023-06-14-11-02-29.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6], f[:20k,:2]]\",\n",
    "    data_predicted=\"f[:20k+n,2]\",\n",
    "    n_steps_ahead=500,\n",
    "    file=\"bubblewrap_run_2023-06-14-11-04-56.pickle\"\n",
    "))\n",
    "\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6], f]\",\n",
    "    data_predicted=\"d(f[:20k+n,:])\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-11-31-41.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"psvd(n)[:20k,:6]\",\n",
    "    data_predicted=\"d(f[:20k+n,:])\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-11-34-31.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f\",\n",
    "    data_predicted=\"d(f[:20k+n,:])\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-11-36-36.pickle\"\n",
    "))\n",
    "\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:70587,:6],f[:70587,:2]]\",\n",
    "    data_predicted=\"f[:70587+n,2]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-12-34-23.pickle\"\n",
    "))\n",
    "\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6],f[:20k,:]]\",\n",
    "    data_predicted=\"psvd(n)[:20k+n,:]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-13-59-08.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6],f[:20k,:]]\",\n",
    "    data_predicted=\"psvd(n)[:20k+n,:]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-14-31-53.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6],f[:20k,0]]\",\n",
    "    data_predicted=\"psvd(n)[:20k+n,:]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-14-33-08.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:20k,:6],f[:20k,1]]\",\n",
    "    data_predicted=\"psvd(n)[:20k+n,:]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-14-34-56.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"psvd(n)[:20k,:6]\",\n",
    "    data_predicted=\"psvd(n)[:20k+n,:]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-14-36-08.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f[:20k,0]\",\n",
    "    data_predicted=\"psvd(n)[:20k+n,:]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-14-37-19.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:70k,:6], f[:70k,:]]\",\n",
    "    data_predicted=\"[psvd(n)[:70k+n,:6],f[:70k+n,:]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-15-31-11.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"psvd(n)[:70k,:6]\",\n",
    "    data_predicted=\"[psvd(n)[:70k+n,:6],f[:70k+n,:]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-15-48-02.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"f[:70k,:]\",\n",
    "    data_predicted=\"[psvd(n)[:70k+n,:6],f[:70k+n,:]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-15-53-30.pickle\"\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[psvd(n)[:70k,:6], f[:70k,:]]\",\n",
    "    data_predicted=\"[psvd(n)[:70k+n,:6],f[:70k+n,:]\",\n",
    "    n_steps_ahead=1,\n",
    "    file=\"bubblewrap_run_2023-06-14-17-18-03.pickle\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[n,b]\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=0,\n",
    "    file='bubblewrap_run_2023-06-16-11-18-29.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"n\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=0,\n",
    "    file='bubblewrap_run_2023-06-16-11-21-06.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"b\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=0,\n",
    "    file='bubblewrap_run_2023-06-16-11-23-42.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[n,b]\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=1,\n",
    "    file='bubblewrap_run_2023-06-16-11-26-15.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"n\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=1,\n",
    "    file='bubblewrap_run_2023-06-16-11-28-42.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"b\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=1,\n",
    "    file='bubblewrap_run_2023-06-16-11-31-16.pickle'\n",
    "))\n",
    "\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[n,b]\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=2,\n",
    "    file='bubblewrap_run_2023-06-16-11-33-47.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"n\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=2,\n",
    "    file='bubblewrap_run_2023-06-16-11-36-14.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"b\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=2,\n",
    "    file='bubblewrap_run_2023-06-16-11-38-48.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[n,b]\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=5,\n",
    "    file='bubblewrap_run_2023-06-16-11-41-20.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"n\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=5,\n",
    "    file='bubblewrap_run_2023-06-16-11-43-51.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"b\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=5,\n",
    "    file='bubblewrap_run_2023-06-16-11-46-21.pickle'\n",
    "))\n",
    "\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[n,b]\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=10,\n",
    "    file='bubblewrap_run_2023-06-16-11-48-49.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"n\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=10,\n",
    "    file='bubblewrap_run_2023-06-16-11-51-20.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"b\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=10,\n",
    "    file='bubblewrap_run_2023-06-16-11-53-49.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[n,b]\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=100,\n",
    "    file='bubblewrap_run_2023-06-16-11-56-18.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"n\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=100,\n",
    "    file='bubblewrap_run_2023-06-16-11-58-47.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"b\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=100,\n",
    "    file='bubblewrap_run_2023-06-16-12-01-19.pickle'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"[n, b]\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=1,\n",
    "    file='bubblewrap_run_2023-06-15-16-54-37.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"n\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=1,\n",
    "    file='bubblewrap_run_2023-06-15-16-55-57.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"b\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=1,\n",
    "    file='bubblewrap_run_2023-06-15-16-58-02.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"z(b,n)\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=1,\n",
    "    file='bubblewrap_run_2023-06-16-10-44-49.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"z(b,n)\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=1,\n",
    "    file='bubblewrap_run_2023-06-16-10-56-11.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"z(n)\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=1,\n",
    "    file='bubblewrap_run_2023-06-16-10-57-21.pickle'\n",
    "))\n",
    "\n",
    "df.append(dict(\n",
    "    data_in=\"z(b)\",\n",
    "    data_predicted=\"[n,b]\",\n",
    "    n_steps_ahead=1,\n",
    "    file='bubblewrap_run_2023-06-16-10-58-24.pickle'\n",
    "))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "\n",
    "for idx in df.index:\n",
    "    with open(df.loc[idx,\"file\"], \"rb\") as fhan:\n",
    "        br = pickle.load(fhan)\n",
    "    df.loc[idx,\"mse\"] = br.beh_error_list[len(br.beh_error_list)//2:].mean() \n",
    "    df.loc[idx, 'br'] = br\n",
    "    df.loc[idx, 'data_predicted'] = df.loc[idx, 'data_predicted'].replace(\"+n\", f\"+{df.loc[idx, 'n_steps_ahead']}\")\n",
    "    # df.loc[idx, 'pred_shape'] = ([int(x) for x in br.beh_list.shape],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"data_in\", \"data_predicted\", \"n_steps_ahead\", \"mse\"]][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for i in range(9):\n",
    "    plt.figure(figsize=(5,3))\n",
    "    for group in [\"[n,b]\",\"n\",\"b\"]:\n",
    "        sdf = df[df.data_in == group]\n",
    "        mse_s = []\n",
    "        stds = []\n",
    "        for br in sdf.br:\n",
    "            es = br.beh_error_list[len(br.beh_error_list)//2:,i]\n",
    "            mse_s.append(es.mean())\n",
    "            stds.append(es.std())\n",
    "        plt.errorbar((sdf.n_steps_ahead), mse_s, yerr=stds, label=group) \n",
    "        plt.ylabel(\"last-half MSE over all variables\")\n",
    "        plt.xlabel(\"number of steps ahead predicted\")\n",
    "        plt.title(f\"predicted component {i}\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = df.loc[0,'br'].entropy_list.shape[0]\n",
    "ttr = df.loc[0,'br'].time_to_run\n",
    "print(f\"total time to run: {ttr}\")\n",
    "print(f\"{1000*ttr/steps} ms/it or {steps/ttr}it/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_time = df.loc[0,'br'].time_spent_on_w\n",
    "\n",
    "print(f\"total time spent on w: {w_time}\")\n",
    "print(f\"{1000*w_time/steps} ms/it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [4,5,6]\n",
    "\n",
    "dfile = np.load(\"../../\" + df.loc[rows[0],\"br\"].file)\n",
    "\n",
    "\n",
    "\n",
    "n = df.loc[rows[0],\"br\"].beh_list.shape[0]\n",
    "to_predict = np.hstack([dfile[\"y\"][0], dfile[\"x\"]])[:n]\n",
    "\n",
    "variable_labels = [f\"neural data {x}\" for x in range(4)] + [\"run speed\", \"pupil size\"] + [f\"video svd[:,{x}]\" for x in range(10)] \n",
    "\n",
    "l = []\n",
    "names = []\n",
    "for row in rows:\n",
    "    l.append(((df.loc[row,\"br\"].beh_list - to_predict)**2).mean(axis=0))\n",
    "    names.append(df.loc[row,\"data_in\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(np.array(l), index=names)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "normalized_result = (result - result.mean(axis=0))/result.std(axis=0)\n",
    "plt.imshow(normalized_result)\n",
    "plt.yticks(ticks=[0,1,2],labels=normalized_result.index,rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "jump_size = 2_500\n",
    "edges = np.arange(0,n,jump_size)\n",
    "\n",
    "all_errors = []\n",
    "for i in range(len(edges)-1):\n",
    "    s = slice(edges[i],edges[i+1])\n",
    "    l = []\n",
    "    for row in rows:\n",
    "        l.append(((df.loc[row,\"br\"].beh_list[s,:] - to_predict[s,:])**2).mean(axis=0))\n",
    "    all_errors.append(l)\n",
    "all_errors = np.array(all_errors)\n",
    "# v_number = 0\n",
    "for v_number in range(16):\n",
    "    plt.figure(figsize=(5,10))\n",
    "    this_variable = all_errors[:,:,v_number].T\n",
    "    plt.imshow(this_variable)\n",
    "    plt.xlabel(f\"time (steps/{jump_size})\")\n",
    "    plt.yticks(ticks=[0,1,2],labels=normalized_result.index,rotation=0);\n",
    "    plt.title(f\"{variable_labels[v_number]} MSE\")\n",
    "    for i in range(this_variable.shape[0]):\n",
    "        plt.text(7.6,i-.3, f\"~mean: {this_variable[i,2:].mean()}\", fontfamily=\"monospace\")\n",
    "        plt.text(7.6,i   , f\"~std:  {this_variable[i,2:].std(ddof=1)}\", fontfamily=\"monospace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "i = 1\n",
    "\n",
    "plt.plot(to_predict[:,i], 'k')\n",
    "for row in rows:\n",
    "    plt.plot(df.loc[row, \"br\"].beh_list[:,i], label=df.loc[row, \"data_in\"])\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(all_pred)\n",
    "plt.legend(normalized_result.index)\n",
    "plt.ylabel(\"mean log p.p.\")\n",
    "plt.xlabel(f\"time (steps/{jump_size})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "jump_size = 5_000\n",
    "edges = np.arange(0,70_001,jump_size)\n",
    "\n",
    "all_pred = []\n",
    "for i in range(len(edges)-1):\n",
    "    s = slice(edges[i],edges[i+1])\n",
    "    l = []\n",
    "    for row in rows:\n",
    "        l.append(df.loc[row,\"br\"].pred_list[s,0].mean())\n",
    "    all_pred.append(l)\n",
    "all_pred = np.array(all_pred)\n",
    "# v_number = 0\n",
    "for v_number in range(9):\n",
    "    plt.figure()\n",
    "    plt.imshow(all_pred[:,:,v_number].T)\n",
    "    # plt.xlabel(f\"time (steps/{jump_size})\")\n",
    "    # plt.yticks(ticks=[0,1,2],labels=normalized_result.index,rotation=0);\n",
    "    # plt.title(f\"predicted variable {v_number} MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = np.linalg.norm(f - f[0], axis=1)[:,None]\n",
    "to_predict = f[:,2]\n",
    "to_predict = psvd_n[:,0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "to_predict = f[:,i]\n",
    "plt.plot(to_predict)\n",
    "\n",
    "to_compare = [0]\n",
    "# to_compare = [30]\n",
    "for i in to_compare:\n",
    "    x = np.arange(df.loc[i,\"br\"].beh_list.shape[0])+df.loc[i,\"n_steps_ahead\"]\n",
    "    beh_pred = df.loc[i,\"br\"].beh_list[:,i]\n",
    "    plt.plot(x,beh_pred)\n",
    "    \n",
    "half_width = 3000\n",
    "\n",
    "kernel = np.ones(half_width * 2)\n",
    "kernel = kernel/kernel.sum()\n",
    "mov_avg = np.convolve(np.squeeze(to_predict), kernel, mode='valid')\n",
    "x = np.arange(mov_avg.shape[0])\n",
    "# plt.plot(x + half_width*2, mov_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = beh_pred.shape[0]\n",
    "perm = rng.permutation(np.arange(n))\n",
    "\n",
    "cut_to_predict = to_predict[:n]\n",
    "constant_mse = ((cut_to_predict - cut_to_predict.mean())**2).mean()\n",
    "constant_mse = 1\n",
    "\n",
    "print(((beh_pred - cut_to_predict)**2).mean()/constant_mse)\n",
    "print(((beh_pred[perm] - cut_to_predict)**2).mean()/constant_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.corrcoef(np.hstack([df.loc[i,\"br\"].beh_list]).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = [1, 100, 500, 1000, 1500, 2000, 2500, 3000, 4000, 50000]\n",
    "ds = []\n",
    "for w in ws:\n",
    "    half_width = w\n",
    "    kernel = np.ones(half_width * 2)\n",
    "    kernel = kernel/kernel.sum()\n",
    "    mov_avg = np.convolve(np.squeeze(to_predict), kernel, mode='valid')\n",
    "\n",
    "    aligned_beh = beh_pred[half_width*2-df.loc[i,\"n_steps_ahead\"]:]\n",
    "\n",
    "    ds.append(((mov_avg[aligned_beh.shape[0]] -  aligned_beh)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ws,ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.loc[5,\"br\"].beh_error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [10,11,12,13,25,26,27,28]\n",
    "plt.plot(df.loc[runs,\"n_steps_ahead\"], df.loc[runs,\"mse\"], '.-', label=df.loc[runs[0], \"data_in\"])\n",
    "\n",
    "runs = range(14,24)\n",
    "plt.plot(df.loc[runs,\"n_steps_ahead\"], df.loc[runs,\"mse\"], '.-', label=df.loc[runs[0], \"data_in\"])\n",
    "plt.ylabel(\"mse\")\n",
    "plt.xlabel(\"number of steps ahead\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[18,\"br\"].beh_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "br.beh_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "## Smoothed Entropy/Prop plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_sided_ewma(data, com=100):\n",
    "    return pd.DataFrame(data=dict(data=data)).ewm(com).mean()[\"data\"]\n",
    "\n",
    "def two_sided_ewma(data, half_width=75):\n",
    "    kernel = np.linspace(0,10,half_width)\n",
    "    kernel = np.exp(kernel)\n",
    "    kernel = np.hstack((kernel, np.flip(kernel)))\n",
    "    kernel = kernel/kernel.sum()\n",
    "    return np.convolve(data, kernel, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T14:55:00.787336Z",
     "start_time": "2023-05-03T14:55:00.739230Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculates for the next cell\n",
    "\n",
    "T = new_way_br.pred_list.shape[0]\n",
    "new_way_means = []\n",
    "old_way_means = []\n",
    "shuffled_means = []\n",
    "\n",
    "new_way_stds = []\n",
    "old_way_stds = []\n",
    "shuffled_stds = []\n",
    "for i, step in enumerate(new_way_br.bw_parameters[\"lookahead_steps\"]):\n",
    "    first_nonzero = np.nonzero(np.isnan(new_way_br.pred_list[:,i]))[0]\n",
    "    if len(first_nonzero):\n",
    "        local_T = first_nonzero[0]\n",
    "    else:\n",
    "        local_T = T\n",
    "    new_way_means.append(np.mean(new_way_br.pred_list[-local_T//2:local_T,i]))\n",
    "    new_way_stds.append(np.std(new_way_br.pred_list[-local_T//2:local_T,i], ddof=1))\n",
    "    # print(f\"new way {step:>2} step(s) ahead mean: {new_way_means[-1]}\")\n",
    "\n",
    "for i, step in enumerate(old_way_br.bw_parameters[\"lookahead_steps\"]):\n",
    "    old_way_means.append(np.mean(old_way_br.pred_list[-T//2:,i]))\n",
    "    old_way_stds.append(np.std(old_way_br.pred_list[-T//2:,i], ddof=1))\n",
    "    # print(f\"old way {step:>2} step(s) ahead mean: {old_way_means[-1]}\")\n",
    "\n",
    "if shuffled_br is not None:\n",
    "    for i, step in enumerate(shuffled_br.bw_parameters[\"lookahead_steps\"]):\n",
    "        first_nonzero = np.nonzero(np.isnan(shuffled_br.pred_list[:,i]))[0]\n",
    "        if len(first_nonzero):\n",
    "            local_T = first_nonzero[0]\n",
    "        else:\n",
    "            local_T = T\n",
    "        shuffled_means.append(np.mean(shuffled_br.pred_list[-local_T//2:local_T,i]))\n",
    "        shuffled_stds.append(np.std(shuffled_br.pred_list[-local_T//2:local_T,i], ddof=1))\n",
    "        # print(f\"new way {step:>2} step(s) ahead mean: {new_way_means[-1]}\")\n",
    "\n",
    "\n",
    "new_way_means = np.array(new_way_means)\n",
    "old_way_means = np.array(old_way_means)\n",
    "\n",
    "new_way_stds = np.array(new_way_stds)\n",
    "old_way_stds = np.array(old_way_stds)\n",
    "\n",
    "if shuffled_br is not None:\n",
    "    shuffled_stds = np.array(shuffled_stds)\n",
    "    shuffled_means = np.array(shuffled_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "### Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "#### Tune smoothing factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T14:57:07.753178Z",
     "start_time": "2023-05-03T14:57:07.669119Z"
    }
   },
   "outputs": [],
   "source": [
    "if not all_inline:\n",
    "    %matplotlib qt\n",
    "\n",
    "\n",
    "data = old_way_br.pred_list[:,0]\n",
    "smoothed_data1 = one_sided_ewma(data,40)\n",
    "\n",
    "plt.plot(data, alpha=.5)\n",
    "plt.plot(smoothed_data1);\n",
    "\n",
    "half_width = 100\n",
    "smoothed_data2 = two_sided_ewma(data,half_width)\n",
    "plt.plot(np.arange(smoothed_data2.size) + half_width, smoothed_data2);\n",
    "\n",
    "plt.legend([\"1-step predictions\", \"one-sided smoothed\", \"two-sided smoothed\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81",
   "metadata": {},
   "source": [
    "#### Smoothed Predictions and alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T14:57:34.975945Z",
     "start_time": "2023-05-03T14:57:34.932067Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shows smoothed predictions over time\n",
    "\n",
    "if not all_inline:\n",
    "    %matplotlib qt\n",
    "    \n",
    "show_states_instead_of_alpha = True\n",
    "\n",
    "smoothing_scale = 40\n",
    "br = shuffled_br\n",
    "\n",
    "fig, axs = plt.subplots(2,1, sharex=True)\n",
    "steps = [1,2,3]\n",
    "for si, step in enumerate(steps):\n",
    "    i = br.bw_parameters[\"lookahead_steps\"].index(step)\n",
    "    old_pred = br.pred_list[:,i]\n",
    "    new_pred = br.pred_list[:,i]\n",
    "    # plt.plot(pred)\n",
    "\n",
    "\n",
    "    smoothed_old_pred = one_sided_ewma(old_pred, smoothing_scale)\n",
    "    smoothed_new_pred = one_sided_ewma(new_pred, smoothing_scale)\n",
    "    half_width = 0 # NOTE: set this if you use the two-sided ewma function\n",
    "    \n",
    "    axs[0].plot(np.arange(smoothed_old_pred.size) + half_width, smoothed_old_pred, color=f'C{si}', linestyle='dashed')\n",
    "    x_correction = (step-1)*1\n",
    "    axs[0].plot(np.arange(smoothed_new_pred.size) + half_width + x_correction,smoothed_new_pred, color=f'C{si}',linestyle='solid')\n",
    "\n",
    "legend = []\n",
    "for step in steps:\n",
    "    legend.append(f\"old {step} step\")\n",
    "    legend.append(f\"new {step} step\")\n",
    "axs[0].legend(legend)\n",
    "axs[0].set_title(f\"{dataset} smoothed prediction\")\n",
    "axs[0].set_xlabel(\"timestep\")\n",
    "axs[0].set_ylabel(\"log pred. prob.\");\n",
    "\n",
    "\n",
    "\n",
    "if states is not None and show_states_instead_of_alpha:\n",
    "    axs[1].plot(states,'.')\n",
    "else:\n",
    "    alpha = br.alpha_list.T\n",
    "    state_means = alpha.mean(axis=1)\n",
    "    # alpha = alpha[state_means > np.quantile(state_means, .75),:]\n",
    "    alpha = alpha[np.argsort(-alpha.mean(axis=1)) - (alpha.shape[0]//2),:]\n",
    "    axs[1].imshow((alpha), aspect=\"auto\", interpolation=\"nearest\")\n",
    "# axs[0].set_xlim([500, 1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "#### Smoothed predictions and entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows smoothed predictions and entropy\n",
    "if not all_inline:\n",
    "    %matplotlib qt\n",
    "\n",
    "    \n",
    "br = new_way_br\n",
    "\n",
    "smooting_scale = 50\n",
    "\n",
    "predictions = br.pred_list[:,0]\n",
    "smoothed_predictions = one_sided_ewma(predictions,smooting_scale)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(predictions, alpha=0.25, color='blue')\n",
    "ax1.plot(smoothed_predictions, color='blue', label = \"prediction\")\n",
    "ax1.tick_params(axis='y',labelcolor='blue')\n",
    "ax1.set_title(f\"(Smoothed) Predictions and Entropy ({dataset})\")\n",
    "\n",
    "\n",
    "entropy = br.entropy_list[:,0]\n",
    "smoothed_entropy = one_sided_ewma(entropy, smooting_scale)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(entropy, color='green', alpha=0.25)\n",
    "ax2.plot(smoothed_entropy, color='green', label=\"entropy\")\n",
    "max_entropy = np.log2(br.bw_parameters[\"num\"])\n",
    "ax2.plot([0, entropy.shape[0]], [max_entropy,]*2, 'g--')\n",
    "ax2.tick_params(axis='y',labelcolor='green')\n",
    "ymin, ymax = ax2.get_ylim()\n",
    "ax2.set_ylim((ymin, 2*(ymax-ymin) + ymin))\n",
    "\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "# Alpha analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(br.alpha_list[:,br.dead_nodes].sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "# Exponentially weighted least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "### Artificial Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "n = 100\n",
    "\n",
    "w_true = np.array([-1,1]).reshape(-1,1)\n",
    "\n",
    "C = np.zeros(shape=(0,d))\n",
    "for i in range(n):\n",
    "    alpha = rng.multivariate_normal([1,1],[[1,0],[0,1]]).reshape(-1,1)\n",
    "    C = np.vstack((C,alpha.T))\n",
    "    \n",
    "y= rng.multivariate_normal(np.squeeze(C @ w_true), np.diag([.9**x for x in range(n)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "### Real regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = br.alpha_list\n",
    "\n",
    "y = np.tile(obs,C.shape[0]//obs.shape[0])[:,None]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "### Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 30\n",
    "D = np.linalg.inv(C[:w,:].T @ C[:w,:])\n",
    "Ct_y = C[:w,:].T @ y[:w]\n",
    "\n",
    "for i in range(w,n):\n",
    "    alpha = C[i,:,None]\n",
    "    D = D - D @ alpha @ alpha.T  @ D/(1 + alpha.T @ D @ alpha)\n",
    "    Ct_y = Ct_y + y[i] * alpha\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig, axs = plt.subplots(nrows=2,ncols=1)\n",
    "axs[0].plot(D@Ct_y, label=\"vanilla\")\n",
    "axs[0].plot(wD@wCt_y, label=\"weighted\")\n",
    "\n",
    "axs[1].plot(np.linalg.inv(C.T @ C)@C.T@y, label=\"vanilla\")\n",
    "axs[1].plot(np.linalg.inv(C.T @ C + np.eye(C.shape[1]))@C.T@y, label=\"normalized\")\n",
    "\n",
    "axs[1].plot(np.linalg.inv(C.T @ (pre_V[:,None] * C)) @ (C.T * pre_V)  @ y, label=\"weighted\")\n",
    "axs[1].plot(np.linalg.inv(C.T @ (pre_V[:,None] * C) + np.eye(C.shape[1])) @ (C.T * pre_V)  @ y, label=\"weighted normalized\")\n",
    "\n",
    "\n",
    "axs[0].set_title(\"iterative\")\n",
    "axs[1].set_title(\"batch\")\n",
    "\n",
    "axs[0].legend()\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "### Vanilla with observation number-based reweighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ww = br.beh_counts.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{np.allclose(np.linalg.inv(C.T @ C), D) = }\")\n",
    "print(f\"{np.allclose(C.T @ y, Ct_y) = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "### Weighted version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = .997\n",
    "\n",
    "pre_V = np.array([v**(n-(i+1)) for i in range(C.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 30\n",
    "\n",
    "sub_V = np.diag([v**(w-(i+1)) for i in range(w)])\n",
    "wD = np.linalg.inv(C[:w,:].T @ sub_V @ C[:w,:])\n",
    "wCt_y = C[:w,:].T@ sub_V @ y[:w]\n",
    "\n",
    "for i in range(w,n):\n",
    "    alpha = C[i,:,None]\n",
    "    wD = wD/v\n",
    "    wD = wD - wD @ alpha @ alpha.T  @ wD/(1 + alpha.T @ wD @ alpha)\n",
    "    wCt_y = v*wCt_y + y[i] * alpha\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{np.allclose(np.linalg.inv(C.T * pre_V @ C), wD) = }\")\n",
    "print(f\"{np.allclose(C.T @ (pre_V[:,None] * y), wCt_y) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "((np.linalg.inv(C.T @ C) @ C.T @ y - w_true.T)**2).sum() - ((np.linalg.inv(C.T @ (pre_V[:,None] * C)) @ C.T @ (pre_V[:,None] * y) - w_true.T)**2).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
