{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:12:08.394531Z",
     "start_time": "2024-06-27T16:12:07.261487Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import adaptive_latents as al\n",
    "from adaptive_latents import NumpyTimedDataSource, Bubblewrap, AnimationManager, default_rwd_parameters, BWRun\n",
    "import adaptive_latents.transforms.utils as fin\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "# al.input_sources.datasets.construct_unpublished24()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:12:08.409024Z",
     "start_time": "2024-06-27T16:12:08.369466Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:12:08.737599Z",
     "start_time": "2024-06-27T16:12:08.371509Z"
    }
   },
   "outputs": [],
   "source": [
    "mat = loadmat(al.CONFIG['data_path'] / 'Chestek' / 'jgould_first_extraction.mat', squeeze_me=True, simplify_cells=True)\n",
    "pre_smooth_beh = mat[\"feats\"][1]\n",
    "pre_smooth_A = mat[\"feats\"][0]\n",
    "pre_smooth_t = mat[\"feats\"][2] / 1000\n",
    "\n",
    "idx = pre_smooth_A.shape[0]//2\n",
    "pre_smooth_A = np.vstack([pre_smooth_A[:idx], pre_smooth_A[idx:2*idx]@ortho_group.rvs(pre_smooth_A.shape[1])])\n",
    "pre_smooth_A, pre_smooth_t = fin.clip(pre_smooth_A, pre_smooth_t) \n",
    "\n",
    "pre_smooth_beh = pre_smooth_beh.reshape((pre_smooth_beh.shape[0], 3, 5))\n",
    "\n",
    "nonzero_columns = pre_smooth_beh.std(axis=0) > 0\n",
    "assert np.all(~(nonzero_columns[0,:] ^ nonzero_columns)) # checks that fingers always have the same values\n",
    "pre_smooth_beh = pre_smooth_beh[:,:,nonzero_columns[0,:]] # the booleans select for position, velocity, and acceleration\n",
    "pre_smooth_beh = pre_smooth_beh[:, [True, False, False], :].reshape(pre_smooth_beh.shape[0], -1) # the three booleans select for position, velocity, and acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:12:08.971222Z",
     "start_time": "2024-06-27T16:12:08.715583Z"
    }
   },
   "outputs": [],
   "source": [
    "# pre_A, pre_beh, pre_t, _ = al.input_sources.datasets.construct_nason20_dataset()\n",
    "%matplotlib inline\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, layout=\"tight\")\n",
    "ax[0].plot(pre_smooth_t, pre_smooth_A[:,0])\n",
    "signal = pre_smooth_A[:,0]\n",
    "\n",
    "\n",
    "kernel = np.exp(np.linspace(0,-1,5))\n",
    "kernel /= kernel.sum()\n",
    "ax[1].plot(kernel)\n",
    "\n",
    "mode = 'valid'\n",
    "smoothed = np.convolve(kernel, signal, mode)\n",
    "smoothed_t = np.convolve(np.hstack([[1],kernel[:-1]*0]), pre_smooth_t, mode)\n",
    "ax[0].plot(smoothed_t,smoothed)\n",
    "\n",
    "\n",
    "ax[0].set_xlim([80, 100])\n",
    "ax[0].set_ylim([10, 30])\n",
    "ax[0].set_title(\"Original and smoothed data\")\n",
    "ax[1].set_title(\"Convolution kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:12:16.115857Z",
     "start_time": "2024-06-27T16:12:09.017635Z"
    }
   },
   "outputs": [],
   "source": [
    "mode = 'valid'\n",
    "pre_prosvd_A = np.column_stack([np.convolve(kernel, column, mode) for column in pre_smooth_A.T])\n",
    "pre_prosvd_t = np.convolve(np.hstack([[1],kernel[:-1]*0]), pre_smooth_t, mode)\n",
    "pre_prosvd_beh = pre_smooth_beh\n",
    "\n",
    "# n = pre_prosvd_A.shape[0]\n",
    "# slice = np.arange(n) < n//2\n",
    "# pre_prosvd_A, pre_prosvd_beh, pre_prosvd_t = (np.vstack([pre_prosvd_A[slice], pre_prosvd_A[slice] @ permutation][::-1]),\n",
    "#              pre_prosvd_beh, \n",
    "#              pre_prosvd_t\n",
    "#             )\n",
    "\n",
    "\n",
    "pre_prosvd_A = fin.center_from_first_n(pre_prosvd_A, 100)\n",
    "pre_prosvd_A, pre_prosvd_beh, pre_prosvd_t = fin.clip(pre_prosvd_A, pre_prosvd_beh, pre_prosvd_t)\n",
    "\n",
    "\n",
    "\n",
    "pre_jpca_A, Qs = fin.prosvd_data_with_Qs(pre_prosvd_A, 4, 50)\n",
    "pre_jpca_A, pre_jpca_t, pre_jpca_beh = fin.clip(pre_jpca_A, pre_prosvd_t, pre_prosvd_beh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:12:16.119054Z",
     "start_time": "2024-06-27T16:12:16.117681Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_splice_A, pre_splice_beh, pre_splice_t = pre_jpca_A, pre_jpca_beh, pre_jpca_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:12:16.163106Z",
     "start_time": "2024-06-27T16:12:16.119303Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "A, beh, t = pre_jpca_A, pre_jpca_beh, pre_jpca_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "##### to skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:12:17.128699Z",
     "start_time": "2024-06-27T16:12:16.158439Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(pre_prosvd_A)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "var_explained = np.cumsum([0] + list(pca.explained_variance_ratio_))\n",
    "ax.plot(var_explained, '.-')\n",
    "ax.set_ylim([0,1])\n",
    "cutoff = np.nonzero(var_explained > .9)[0][0]\n",
    "ax.axvline(cutoff, color='k', alpha=.5)\n",
    "ax.axhline(.9, color='k', alpha=.25)\n",
    "ax.text(.65,.1, f'n_components $\\\\approx$ {cutoff}', transform=ax.transAxes)\n",
    "ax.set_ylabel(\"cumulative variance explained\")\n",
    "ax.set_xlabel(\"number of components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:12:17.741184Z",
     "start_time": "2024-06-27T16:12:17.138055Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, layout=\"tight\")\n",
    "dQ = np.linalg.norm(np.diff(Qs, axis=0), axis=1)\n",
    "dt = np.diff(pre_jpca_t)\n",
    "ax[0].plot(t[:-1], dQ/dt[:,None]);\n",
    "ax[0].set_ylabel(\"$\\\\frac{ \\\\Vert dQ_i \\\\Vert}{dt}$\");\n",
    "ax[0].set_title(\"Change in proSVD vectors over time\");\n",
    "ax[0].set_xlabel(\"time (s)\");\n",
    "\n",
    "ax[1].plot(t[:-1], np.log(dQ/dt[:,None]));\n",
    "ax[1].set_ylabel(\"$\\\\ln \\\\frac{ \\\\Vert dQ_i \\\\Vert}{dt}$\");\n",
    "ax[1].set_title(\"(log scale)\");\n",
    "ax[1].set_xlabel(\"time (s)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T16:12:17.743031Z",
     "start_time": "2024-06-27T16:12:17.741840Z"
    }
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# fig, axs = plt.subplots(nrows=3, ncols=3, sharey='row')\n",
    "\n",
    "# slice_half_width = 20\n",
    "# time_slices = [slice(0,slice_half_width*2), \n",
    "#                slice(len(t)//2-slice_half_width, len(t)//2+slice_half_width) , \n",
    "#                slice(-slice_half_width*2, -1)]\n",
    "# for i in range(3):\n",
    "#     s = time_slices[i]\n",
    "#     axs[0,i].plot(t[s],beh[s])\n",
    "#     axs[0,i].set_xlim([min(t[s]), max(t[s])])\n",
    "#     axs[1,i].imshow(A[s,:].T, aspect='auto', interpolation='none')\n",
    "#     axs[1,i].set_xticks([])\n",
    "#     axs[2,i].plot(t[s],A[s,:], color='k', alpha=.25)\n",
    "#     axs[2,i].set_xlim([min(t[s]), max(t[s])])\n",
    "\n",
    "# axs[0,0].set_title(f\"first {slice_half_width*2} points\")\n",
    "# axs[0,1].set_title(f\"middle {slice_half_width*2} points\")\n",
    "# axs[0,2].set_title(f\"last {slice_half_width*2} points\")\n",
    "\n",
    "# axs[0,0].set_ylabel(\"Behavior\")\n",
    "# axs[1,0].set_ylabel(\"Neural Latents\")\n",
    "# axs[2,0].set_ylabel(\"Neural Latents\")\n",
    "# axs[2,1].set_xlabel(\"time (s)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "##### bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ds = NumpyTimedDataSource(A, t, time_offsets=(0,1))\n",
    "out_ds = NumpyTimedDataSource(beh, t, time_offsets=(0,1))\n",
    "\n",
    "# define the adaptive_latents object\n",
    "bw = Bubblewrap(dim=in_ds.output_shape,  **dict(default_rwd_parameters, M=300, num=500, num_grad_q=1))\n",
    "\n",
    "# define the (optional) method to regress the HMM state from `bw.alpha`\n",
    "# reg = SymmetricNoisyRegressor(input_d=bw.N, output_d=1)\n",
    "\n",
    "reg = None\n",
    "# reg = al.regressions.SymmetricNoisyRegressor(input_d=bw.N, output_d=out_ds.output_shape, init_min_ratio=.5)\n",
    "\n",
    "class CustomAnimation(AnimationManager):\n",
    "    n_rows = 1\n",
    "    n_cols = 3\n",
    "    figsize = (15,10)\n",
    "    extension = \"mp4\"\n",
    "    fps=10\n",
    "\n",
    "    def custom_draw_frame(self, step, bw: Bubblewrap, br: BWRun):\n",
    "        historical_observations, _ = br.input_ds.get_history()\n",
    "\n",
    "        al.plotting_functions.show_active_bubbles_and_connections_2d(self.ax[0,1], historical_observations, bw, n_sds=3, history_length=10)\n",
    "        self.ax[0,1].set_title(f\"Step {step}\")\n",
    "        al.plotting_functions.show_alpha(self.ax[0,0], br)\n",
    "        al.plotting_functions.show_behavior(self.ax[0,2], br)\n",
    "        \n",
    "    def frame_draw_condition(self, step_number, bw):\n",
    "        condition = True\n",
    "        condition = condition and (step_number % 1 == 0)\n",
    "        condition = condition and (350 < step_number < 2000)\n",
    "        return condition\n",
    "        \n",
    "am = CustomAnimation() if False else None\n",
    "\n",
    "br = BWRun(bw=bw, in_ds=in_ds, out_ds=out_ds, behavior_regressor=reg, animation_manager=am, show_tqdm=True, log_level=1)\n",
    "\n",
    "br.run(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "al.plotting_functions.compare_metrics([br],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "al.plotting_functions.compare_metrics([br],1)\n",
    "print(br.output_regressor.get_beta()[:2,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "beh[1:] =  * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "inputs = beh[:-1]\n",
    "outputs = beh[1:]\n",
    "beta, res, _, _ = np.linalg.lstsq(inputs, outputs, rcond=None)\n",
    "ax.plot(t[1:],(inputs @ beta - outputs)**2);\n",
    "ax.set_xlabel(\"time (s)\")\n",
    "ax.set_xlabel(\"square error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ds = NumpyTimedDataSource(A, t, time_offsets=(0,1))\n",
    "out_ds = NumpyTimedDataSource(beh, t, time_offsets=(0,1))\n",
    "\n",
    "# define the adaptive_latents object\n",
    "bw = Bubblewrap(dim=in_ds.output_shape,  **dict(default_rwd_parameters, M=300, num=500, num_grad_q=1))\n",
    "\n",
    "# define the (optional) method to regress the HMM state from `bw.alpha`\n",
    "# reg = SymmetricNoisyRegressor(input_d=bw.N, output_d=1)\n",
    "reg = al.regressions.SymmetricNoisyRegressor(input_d=bw.N, output_d=out_ds.output_shape, init_min_ratio=.5)\n",
    "\n",
    "class CustomAnimation(AnimationManager):\n",
    "    n_rows = 1\n",
    "    n_cols = 3\n",
    "    figsize = (15,10)\n",
    "    extension = \"mp4\"\n",
    "    fps=10\n",
    "\n",
    "    def custom_draw_frame(self, step, bw: Bubblewrap, br: BWRun):\n",
    "        historical_observations, _ = br.obs_ds.get_history()\n",
    "\n",
    "        al.plotting_functions.show_active_bubbles_and_connections_2d(self.ax[0,1], historical_observations, bw, n_sds=3, history_length=10)\n",
    "        self.ax[0,1].set_title(f\"Step {step}\")\n",
    "        al.plotting_functions.show_alpha(self.ax[0,0], br)\n",
    "        al.plotting_functions.show_behavior(self.ax[0,2], br)\n",
    "        \n",
    "    def frame_draw_condition(self, step_number, bw):\n",
    "        condition = True\n",
    "        condition = condition and (step_number % 1 == 0)\n",
    "        condition = condition and (350 < step_number < 1600)\n",
    "        return condition\n",
    "        \n",
    "am = CustomAnimation() if False else None\n",
    "\n",
    "br = BWRun(bw=bw, in_ds=in_ds, out_ds=out_ds, behavior_regressor=reg, animation_manager=am, show_tqdm=True, log_level=1)\n",
    "\n",
    "br.run(limit=557,save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_observations, _ = br.input_ds.get_history()\n",
    "n_steps = 15\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(historical_observations[:,0], historical_observations[:,1], '.')\n",
    "ax.plot(historical_observations[-n_steps:,0], historical_observations[-n_steps:,1])\n",
    "\n",
    "ms = []\n",
    "for i in range(n_steps):\n",
    "    m = np.argmax(br.model_step_variable_history['alpha'][-1-i])\n",
    "    ms.append(m)\n",
    "\n",
    "for m in set(ms):    \n",
    "    pass\n",
    "    al.plotting_functions.add_2d_bubble(ax, br.bw.L[m], br.bw.mu[m], 3, alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.interpolate import BSpline, make_interp_spline\n",
    "historical_observations, _ = br.obs_ds.get_history()\n",
    "n_steps = 25\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "all_observations = br.obs_ds.a\n",
    "idx = br.obs_ds.index\n",
    "width1= idx\n",
    "width2 = 4*idx\n",
    "ax.plot(all_observations[idx-width1:idx+width2,0], all_observations[idx-width1:idx+width2,1], '.',color=\"#505050\", ms=15, alpha=.1, mew=0)\n",
    "\n",
    "points = np.array([historical_observations[-n_steps:,0], historical_observations[-n_steps:,1]]).T\n",
    "t = np.linspace(0,1,n_steps)\n",
    "\n",
    "b = make_interp_spline(t,points)\n",
    "\n",
    "points = b(np.linspace(0,1,n_steps))\n",
    "ax.plot(points[:,0],points[:,1])\n",
    "\n",
    "ms = []\n",
    "for i in range(n_steps):\n",
    "    m = np.argmax(br.alpha_history[0][-1-i])\n",
    "    ms.append(m)\n",
    "\n",
    "for m in set(ms):    \n",
    "    al.plotting_functions.add_2d_bubble(ax, br.bw.L[m], br.bw.mu[m], 3, alpha=.5)\n",
    "\n",
    "ax.set_xlim([-15,35])\n",
    "ax.set_ylim([-10,35])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.interpolate import BSpline, make_interp_spline\n",
    "historical_observations, _ = br.obs_ds.get_history()\n",
    "n_steps = 15\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "all_observations = br.obs_ds.a\n",
    "idx = br.obs_ds.index\n",
    "width1= idx\n",
    "width2 = 4*idx\n",
    "ax.plot(all_observations[idx-width1:idx+width2,0], all_observations[idx-width1:idx+width2,1], '.',color=\"#505050\", ms=15, alpha=.1, mew=0)\n",
    "\n",
    "points = np.array([historical_observations[-n_steps:,0], historical_observations[-n_steps:,1]]).T\n",
    "t = np.linspace(0,1,n_steps)\n",
    "\n",
    "b = make_interp_spline(t,points)\n",
    "\n",
    "points = b(np.linspace(0,1,n_steps*1))\n",
    "ax.plot(points[:,0],points[:,1])\n",
    "\n",
    "for i in range(n_steps):\n",
    "    m = np.argmax(br.alpha_history[0][-1-i])\n",
    "    # todo: check that these indexes line up\n",
    "    al.plotting_functions.add_2d_bubble(ax, br.L_history[-1-i][m], br.mu_history[-1-i][m], 3, alpha=.5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "\n",
    "files = sorted(glob.glob(f\"{al.CONFIG[\"output_path\"]/\"bubblewrap_runs\"}/*.pickle\"))\n",
    "brs = []\n",
    "for file in files[-8:]:\n",
    "    with open(file, 'br') as fhan:\n",
    "        brs.append(pickle.load(fhan))\n",
    "br = brs[-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib qt\n",
    "import importlib\n",
    "import copy\n",
    "importlib.reload(al.plotting_functions)\n",
    "\n",
    "br2 = copy.deepcopy(br)\n",
    "br2.obs_ds.t = np.arange(br.obs_ds.t.size) * 0.05 +  br.obs_ds.t[0]\n",
    "br = br2\n",
    "al.plotting_functions.compare_metrics([br], offset=1, red_lines=[pre_jpca_t[n//3-1] ,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polar_path(points):\n",
    "    angles = []\n",
    "    lengths = []\n",
    "    for i in range(1,points.shape[0]-1):\n",
    "        # here we define unit vectors paralell to the i and (i+1)th line segments in `points`\n",
    "        current_segment = points[i] - points[i-1]\n",
    "        next_segment = points[i+1] - points[i]\n",
    "        lengths.append(np.linalg.norm(next_segment))\n",
    "        current_segment /= np.linalg.norm(current_segment)\n",
    "        next_segment /= np.linalg.norm(next_segment)\n",
    "        \n",
    "        # calculate the angle using arccos\n",
    "        angle_magnitude = np.arccos(current_segment @ next_segment)\n",
    "        angle_sign = -np.sign(np.linalg.det(np.column_stack([current_segment, next_segment])))\n",
    "        angle_by_cos = angle_magnitude * angle_sign\n",
    "        \n",
    "        # calculate the angle using atan2\n",
    "        orth_to_current_segment = np.array([[0,-1],[1,0]]) @ current_segment\n",
    "        angle_by_atan2 = np.arctan2(next_segment @ orth_to_current_segment, next_segment @ current_segment)\n",
    "        \n",
    "        # check that both methods give the correct answer\n",
    "        if not np.isclose(-angle_by_cos, angle_by_atan2):\n",
    "            print(f\"{-angle_by_cos} {angle_by_atan2}\")\n",
    "        \n",
    "        \n",
    "        angles.append(angle_by_cos)\n",
    "    return angles, lengths\n",
    "def make_angle_plot(ax, angles, lengths, bins=16, density=True):\n",
    "    bins = np.linspace(-np.pi, np.pi, num=bins+1)\n",
    "    \n",
    "    # Bin data and record counts\n",
    "    n, bins = np.histogram(angles, weights=lengths, bins=bins)\n",
    "    widths = np.diff(bins)\n",
    "    \n",
    "    if density:\n",
    "        # Area to assign each bin\n",
    "        area = n / len(angles)\n",
    "        # Calculate corresponding bin radius\n",
    "        radius = (area/np.pi) ** .5\n",
    "    # Otherwise plot frequency proportional to radius\n",
    "    else:\n",
    "        radius = n\n",
    "    \n",
    "    # Plot data on ax\n",
    "    patches = ax.bar(bins[:-1], radius, zorder=1, align='edge', width=widths,\n",
    "                     edgecolor='C0', fill=False, linewidth=1)\n",
    "    \n",
    "    # Set the direction of the zero angle\n",
    "    ax.set_theta_offset(np.pi/2)\n",
    "    \n",
    "    # Remove ylabels for area plots (they are mostly obstructive)\n",
    "    if density:\n",
    "        ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_high_d(A, fig=None, axs=None):\n",
    "    k = A.shape[1]\n",
    "    if fig is None or axs is None:\n",
    "        fig, axs = plt.subplots(nrows=k, ncols=k, figsize=(8,8), tight_layout=True)\n",
    "    \n",
    "    for i in range(k):\n",
    "        for j in range(k):\n",
    "            if i < j:\n",
    "                axs[i,j].scatter(A[:,i], A[:,j], c=t, s=1)\n",
    "                axs[i,j].set_xticks([])\n",
    "                axs[i,j].set_yticks([])\n",
    "            elif i == j:\n",
    "                axs[i,j].hist(A[:,i], bins=A.shape[0]//100)\n",
    "                axs[i,i].set_xticks([])\n",
    "                axs[i,i].set_yticks([])\n",
    "            else:\n",
    "                axs[i,j].remove()\n",
    "                axs[i,j] = fig.add_subplot(k, k, (i*k +j)+1, projection='polar')\n",
    "                angles, lengths = get_polar_path(A[:,[i,j]])\n",
    "                make_angle_plot(axs[i,j], angles, lengths)\n",
    "                \n",
    "                axs[i,j].set_yticks([])\n",
    "                axs[i,j].set_xticks([0])\n",
    "                axs[i,j].set_xticklabels([\"\"])\n",
    "inspect_high_d(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Some sort of continuity measure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_making_powerpoints():\n",
    "    from pathlib import Path\n",
    "    import io\n",
    "    from pptx import Presentation\n",
    "    from pptx.util import Inches, Pt\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    layouts_to_indexes = {\n",
    "        \"title\":0,\n",
    "        \"blank\":6,\n",
    "    }\n",
    "    \n",
    "    prs = Presentation()\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[layouts_to_indexes[\"blank\"]])\n",
    "    \n",
    "    In = Inches(1)\n",
    "    left = top = width = height = Inches(0)\n",
    "    txBox = slide.shapes.add_textbox(0, 0, 3*In, 2*In)\n",
    "    tf = txBox.text_frame\n",
    "    \n",
    "    tf.text = \"This is text inside a textbox\"\n",
    "    \n",
    "    tf.paragraphs[0].font.size = Pt(10)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    ax.plot(range(2), range(2))\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png', dpi=200)\n",
    "    buf.seek(0)\n",
    "    slide.shapes.add_picture(buf, 1*In, 1*In, 2*In)\n",
    "    \n",
    "    prs.save(Path(\"/home/jgould/Dropbox (University of Michigan)/bwruns\") / \"testy.pptx\")\n",
    "test_making_powerpoints()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
