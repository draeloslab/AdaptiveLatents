{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# A quick intro to `adaptive_latents`\n",
    "\n",
    "This document introduces the basics of the structure of `adaptive_latents` estimators, first by comparing transformers to sklearn estimators, and then by comparing AL pipelines with sklearn Pipelines.\n",
    "\n",
    "By the end of the document, readers should understand:\n",
    "* what an AL (adaptive latents) transformer is\n",
    "* the difference between AL `partial_fit` functions and sklearn `fit` functions\n",
    "* the purpose of an AL pipeline\n",
    "* the semantics of `input_streams` and `output_streams` in AL transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from adaptive_latents import VanillaOnlineRegressor, CenteringTransformer, Pipeline\n",
    "import adaptive_latents\n",
    "import sklearn.pipeline\n",
    "import time\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Estimators\n",
    "\n",
    "One of the central ideas of scikit-learn is that of an estimator object.\n",
    "This is how the library organizes its algorithms, where each algorithm has a specific class you can instantiate objects of;\n",
    "You use a `PCA` estimator to do dimensionality reduction, and a `LinearRegression` to estimate a regression.\n",
    "Transformers in `adaptive_latents` are similar.\n",
    "\n",
    "Let's take a look at the correspondence for a basic regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "First, we create a simple regression problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(100).reshape(-1, 1)\n",
    "true_y = x * 2 \n",
    "noise = rng.normal(size=x.shape, scale=0.01)\n",
    "y = true_y + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "A sklearn user might estimate the regression between `y` and `x` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression(fit_intercept=True)\n",
    "\n",
    "reg.fit(x, y)\n",
    "\n",
    "new_x = np.array([[3]])\n",
    "reg.predict(new_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "The `adaptive_latents` code looks similar. In general, `adaptive_latents` functions are inspired by the sklearn API.\n",
    "(This is also why they use `partial_fit` instead of `fit`, because that's what sklearn uses for online algorithms.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = VanillaOnlineRegressor()\n",
    "\n",
    "reg.partial_fit(x, stream=0)\n",
    "reg.partial_fit(y, stream=1)\n",
    "\n",
    "new_x = np.array([[3]])\n",
    "reg.predict(new_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "The main difference is that there are two calls to `fit` functions.\n",
    "Why make this choice? This allows us to regress between $x$ and $y$ variables that aren't sampled at the same time.\n",
    "This is what the `stream` arguments are for; they tell the regression when the variable it got passed is an $x$ or a $y$ observation.\n",
    "By default, the transformer assumes stream `0` should be treated as $x$ observations and stream `1` should be treated as $y$ observations, but it's configurable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = VanillaOnlineRegressor(input_streams={5:'X', 700:'Y'})\n",
    "# data in stream 5 should be treated as 'X' observations\n",
    "# data in stream 700 should be treated as 'Y' observations\n",
    "\n",
    "reg.partial_fit(x, stream=5)\n",
    "reg.partial_fit(y, stream=700)\n",
    "\n",
    "new_x = np.array([[3]])\n",
    "reg.predict(new_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "You can use any hashable object as a stream, but the convention is to use small positive integers (and 0). \n",
    "Unless they are configured otherwise, most estimators will expect $x$ inputs from the `0` stream.\n",
    "\n",
    "Breaking up the fit function also allows us to fit \"out-of-order\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = VanillaOnlineRegressor()\n",
    "\n",
    "reg.partial_fit(x, stream=0)\n",
    "reg.partial_fit(x, stream=0)\n",
    "time.sleep(.25)\n",
    "reg.partial_fit(y, stream=1)\n",
    "\n",
    "new_x = np.array([[3]])\n",
    "reg.predict(new_x)\n",
    "reg.transform(new_x, stream=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Note I used `transform` instead of `predict` above.\n",
    "While some `adaptive_latents` transformers have `predict` functions, the main API uses `transform` or `partial_fit_transform`.\n",
    "\n",
    "The final point I'll introduce here is that estimators ignore inputs that aren't in a stream they care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = VanillaOnlineRegressor()\n",
    "\n",
    "for data, stream in [\n",
    "    (y, 1),\n",
    "    (np.zeros([5,5,5,5]), 5),\n",
    "    (None, 6),\n",
    "    ('data', 'stream'),\n",
    "    (lambda x: x, 100),\n",
    "    (type(type(type)), 1211),\n",
    "    (adaptive_latents, -3),\n",
    "    (x, 0),\n",
    "]:\n",
    "    reg.partial_fit(data=data, stream=stream)\n",
    "\n",
    "\n",
    "new_x = np.array([[3]])\n",
    "reg.transform(new_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Chaining Estimators\n",
    "Individual estimators can be useful, but they're more useful in groups.\n",
    "Let's assume we wanted to center our $x$ variable before the regression.\n",
    "In sklearn, we might do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "centerer = StandardScaler()\n",
    "reg = LinearRegression()\n",
    "\n",
    "centered_x = centerer.fit_transform(x)\n",
    "reg.fit(centered_x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "This is how you might do something similar in `adaptive_latents`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "centerer = CenteringTransformer()\n",
    "reg = VanillaOnlineRegressor()\n",
    "\n",
    "centered_x = centerer.partial_fit_transform(x, stream=0)\n",
    "reg.partial_fit(centered_x, stream=0)\n",
    "reg.partial_fit(y, stream=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "For bigger groups of estimators, sklearn uses `Pipelines`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_pipeline = sklearn.pipeline.Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('reg', LinearRegression())\n",
    "])\n",
    "sk_pipeline.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "And `adaptive_latents` does too (although its own implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "al_pipeline = adaptive_latents.Pipeline([\n",
    "    CenteringTransformer(),\n",
    "    VanillaOnlineRegressor()\n",
    "])\n",
    "\n",
    "al_pipeline.partial_fit(x, stream=0)\n",
    "al_pipeline.partial_fit(y, stream=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "At its core, an `adaptive_latents` pipeline is mostly a wrapper for calling its member steps in order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_fit_transform(al_pipeline, data, stream=0, return_output_stream=False):\n",
    "    for step in al_pipeline.steps:\n",
    "        data, stream = step.partial_fit_transform(data, stream, return_output_stream=True)\n",
    "    return (data, stream) if return_output_stream else data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "This works because each estimator ignores streams it doesn't care about.\n",
    "In the regression case, the centering estimator ignores the `1` stream.\n",
    "\n",
    "If you're familiar with piping data in the command line, this may seem familiar; it's partially inspired by POSIX-style pipe commands.\n",
    "Also like command-line piping, we can redirect streams.\n",
    "This is accomplished with the `output_streams` argument to transformers.\n",
    "The exact semantics of output streams are up to the transformer, but usually they redirect to an output stream based on the input stream data appeared in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pipeline([], output_streams={0:1}) # an empty pipeline is basically a NOOP transformer\n",
    "\n",
    "data, stream = None, 0\n",
    "print(stream)\n",
    "\n",
    "data, stream = p.partial_fit_transform(data, stream, return_output_stream=True)\n",
    "print(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pipeline([], output_streams={0:1, 1:2, 2:0})\n",
    "# inputs from stream 0 get redirected to stream 1, \n",
    "# inputs from stream 1 get redirected to stream 2,\n",
    "# inputs from stream 2 get redirected back to stream 0\n",
    "\n",
    "data, stream = None, 0\n",
    "print(stream)\n",
    "for _ in range(3):\n",
    "    data, stream = p.partial_fit_transform(data, stream, return_output_stream=True)\n",
    "    print(stream)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "\n",
    "Using pipelines of Transformers, you can construct complex analyses without using special classes or custom control flow.\n",
    "Any computation that can be represented by a directed acyclic graph can be computed in a Pipeline, and for cases beyond that, you can still use individual estimators.\n",
    "\n",
    "This is a pipeline I've used to create real figures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from adaptive_latents import Bubblewrap, Pipeline, sjPCA, KernelSmoother, Concatenator, proSVD\n",
    "\n",
    "bw = functools.partial(\n",
    "    Bubblewrap,\n",
    "    num=100,\n",
    "    M=500,\n",
    "    lam=1e-3,\n",
    "    nu=1e-3,\n",
    "    eps=1e-4,\n",
    "    step=1e-2,\n",
    "    num_grad_q=1,\n",
    "    sigma_orig_adjustment=100,\n",
    "    check_consistent_dt=False,\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    CenteringTransformer(init_size=100),\n",
    "    KernelSmoother(tau=.5),\n",
    "    Concatenator(input_streams={0: 0, 1: 1}, output_streams={0: 0, 1: 0, 'skip': -1}),\n",
    "    proSVD(k=6),\n",
    "    sjPCA(),\n",
    "    bw(input_streams={0: 'X', 3: 'dt'}), # 'dt' means to predict ahead the inputted amount\n",
    "    VanillaOnlineRegressor(input_streams={0: 'X', 2: 'Y', 3: 'qX'})\n",
    "])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
