{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T20:29:29.433527Z",
     "start_time": "2024-10-22T20:29:29.426223Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import adaptive_latents.input_sources.datasets as datasets\n",
    "import adaptive_latents.plotting_functions as pf\n",
    "import matplotlib.pyplot as plt\n",
    "import prediction_regression_pipeline as prp\n",
    "from adaptive_latents.plotting_functions import PredictionVideo\n",
    "from adaptive_latents import (\n",
    "    AnimationManager\n",
    ")\n",
    "import adaptive_latents\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "from IPython import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T20:29:30.030104Z",
     "start_time": "2024-10-22T20:29:30.027573Z"
    }
   },
   "outputs": [],
   "source": [
    "from adaptive_latents.plotting_functions import plot_history_with_tail\n",
    "adaptive_latents.plotting_functions = reload(adaptive_latents.plotting_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "* [jPCA figure](https://www.dropbox.com/scl/fo/duf5zbwcibsux467c6oc9/AIN-ZiFsy2Huyh8h7VMdL7g?dl=0&e=1&preview=Basic+jPCA+plot.pdf&rlkey=3o5axmq5hirel4cij7g64jc0r)\n",
    "* [gpfa figure](https://users.ece.cmu.edu/~byronyu/software.shtml)\n",
    "* [lfads figure](https://www.nature.com/articles/s41592-018-0109-9/figures/1) (copied from the paper)\n",
    "* [cebra figure](https://www.nature.com/articles/s41586-023-06031-6/figures/1) (copied from the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T20:29:31.635858Z",
     "start_time": "2024-10-22T20:29:31.219222Z"
    }
   },
   "outputs": [],
   "source": [
    "!echo $(hostname) $(git rev-parse --short HEAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Intro Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T20:29:33.785796Z",
     "start_time": "2024-10-22T20:29:33.768237Z"
    }
   },
   "outputs": [],
   "source": [
    "def intro_plot(d, tail_length=5, duration=10, start_time=10, fps=20):\n",
    "    with AnimationManager(n_cols=2, n_rows=1, figsize=(10, 5), filetype='mp4', fps=fps) as am:\n",
    "        am.axs[0,1].scatter(d.behavioral_data.a[:,0,0], d.behavioral_data.a[:,0,1])\n",
    "        for current_t in np.linspace(start_time, start_time + duration, duration*fps):\n",
    "            am.axs[0,0].cla()\n",
    "    \n",
    "            n_columns = np.floor(tail_length / np.median(np.diff(d.neural_data.t))).astype(int)\n",
    "            idx = np.nonzero(~(d.neural_data.t < current_t))[0][0]\n",
    "            \n",
    "            \n",
    "            am.axs[0,0].imshow(d.neural_data.a[idx-n_columns:idx,0,:].T, aspect='auto', interpolation='none', extent=[current_t - tail_length, current_t, d.neural_data.a.shape[2], 0],\n",
    "                              vmin=d.neural_data.a.min(),vmax=d.neural_data.a.max())\n",
    "            am.axs[0,0].set_xticklabels([])\n",
    "    \n",
    "    \n",
    "    \n",
    "            old_lims = am.axs[0,1].axis()\n",
    "            am.axs[0,1].cla()\n",
    "            am.axs[0,1].axis('off')\n",
    "            \n",
    "            s = ((current_t - tail_length) < d.behavioral_data.t) & (d.behavioral_data.t < current_t)\n",
    "            am.axs[0,1].plot(d.behavioral_data.a[s,0,0], d.behavioral_data.a[s,0,1])\n",
    "            pf.use_bigger_lims(am.axs[0,1], old_lims)\n",
    "            \n",
    "            am.grab_frame()\n",
    "    \n",
    "    display.display(display.Video(am.outfile, embed=True))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datasets.Odoherty21Dataset()\n",
    "intro_plot(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datasets.Peyrache15Dataset()\n",
    "intro_plot(d,start_time=16185)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.Peyrache15Dataset().neural_data.a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datasets.Zong22Dataset()\n",
    "intro_plot(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datasets.Schaffer23Datset()\n",
    "intro_plot(d, start_time=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datasets.TostadoMarcos24Dataset()\n",
    "intro_plot(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Odoherty21 Portion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Intro video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Trajectory with 2d histogram background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T22:23:04.376908Z",
     "start_time": "2024-10-22T21:58:45.347209Z"
    }
   },
   "outputs": [],
   "source": [
    "odoherty_run = prp.PipelineRun(**prp.PipelineRun.default_parameter_values['odoherty21'])\n",
    "run = odoherty_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T17:05:10.647632Z",
     "start_time": "2024-10-04T17:05:10.535061Z"
    }
   },
   "outputs": [],
   "source": [
    "run = odoherty_run\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "\n",
    "\n",
    "tail_length = 1\n",
    "with AnimationManager(fig=fig, make_axs=False, fps=20, filetype='mp4') as am:\n",
    "    for current_t in np.linspace(600, 610, 200):\n",
    "        plot_history_with_tail(axs[0], run.neural_target, current_t, tail_length, hist_bins=30)\n",
    "        plot_history_with_tail(axs[1], run.jpca_latents,  current_t, tail_length, hist_bins=30)\n",
    "        plot_history_with_tail(axs[2], run.beh_target, current_t, tail_length, hist_bins=30)\n",
    "        am.grab_frame()\n",
    "\n",
    "plt.close();\n",
    "display.display(display.Video(am.outfile, embed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Data, Latent, Prediction graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T16:43:30.921132Z",
     "start_time": "2024-10-04T16:43:02.270087Z"
    }
   },
   "outputs": [],
   "source": [
    "run = odoherty_run\n",
    "\n",
    "import adaptive_latents.plotting_functions\n",
    "pv = reload(adaptive_latents.plotting_functions).PredictionVideo(run.d, fps=20, filetype='mp4')\n",
    "\n",
    "\n",
    "\n",
    "assert (run.next_bubble_joint_predictions.t == run.beh_predictions.t).all()\n",
    "with pv.am:\n",
    "    for current_t in np.linspace(600, 610, 200):\n",
    "        pv.plot_for_video_t(\n",
    "            current_t, \n",
    "            run.jpca_latents, run.jpca_latents.t, \n",
    "            run.next_bubble_joint_predictions, run.beh_predictions, run.beh_predictions.t,\n",
    "            run.streams\n",
    "        )\n",
    "plt.close()\n",
    "display.display(display.Video(pv.am.outfile, embed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Stream table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T21:39:48.823513Z",
     "start_time": "2024-10-23T21:39:46.639010Z"
    }
   },
   "outputs": [],
   "source": [
    "run_all = odoherty_run\n",
    "if True:\n",
    "    run_no_neural = prp.PipelineRun(**(prp.PipelineRun.default_parameter_values['odoherty21'] | dict(concat_zero_streams=[0])))\n",
    "    run_no_beh = prp.PipelineRun(**(prp.PipelineRun.default_parameter_values['odoherty21'] | dict(concat_zero_streams=[1])))\n",
    "    def make_row(run):\n",
    "        return ({\n",
    "            'beh_x': run.beh_nrmses[0],\n",
    "            'beh_y': run.beh_nrmses[1],\n",
    "        } | {f'neural_{n}': run.neural_nrmses[n] for n in range(len(run.neural_correlations))})\n",
    "        \n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            make_row(run_all),\n",
    "            make_row(run_no_neural),\n",
    "            make_row(run_no_beh)\n",
    "        ], \n",
    "        index = ['all', 'no_neural', 'no_beh']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T21:40:12.169790Z",
     "start_time": "2024-10-23T21:40:12.164585Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    [\n",
    "        make_row(run_all),\n",
    "        make_row(run_no_neural),\n",
    "        make_row(run_no_beh)\n",
    "    ],\n",
    "    index = ['all', 'no_neural', 'no_beh']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T21:27:36.912178Z",
     "start_time": "2024-10-23T21:27:36.767137Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=1, squeeze=False, sharex=True, figsize=(4, 9))\n",
    "\n",
    "pred_color = 'C0'\n",
    "control_color = 'C1'\n",
    "\n",
    "# pred_color = '#D11149'\n",
    "# control_color = '#6610F2'\n",
    "\n",
    "run_all = odoherty_run\n",
    "\n",
    "xlim = [500, 550]\n",
    "\n",
    "mode = 'neural'\n",
    "pred, target = getattr(run_all, f'{mode}_predictions'), getattr(run_all, f'{mode}_target')\n",
    "s = target.t\n",
    "s = (xlim[0] < s) & (s < xlim[1])\n",
    "axs[0,0].plot(target.t[s], target[s, 1], 'k')\n",
    "s = pred.t\n",
    "s = (xlim[0] < s) & (s < xlim[1])\n",
    "axs[0,0].plot(pred.t[s], pred[s,1], color=pred_color)\n",
    "\n",
    "control = getattr(run_no_neural, f'{mode}_predictions')\n",
    "s = control.t\n",
    "s = (xlim[0] < s) & (s < xlim[1])\n",
    "axs[0,0].plot(control.t[s], control[s,1], '-', color=control_color)\n",
    "\n",
    "\n",
    "mode = 'beh'\n",
    "pred, target = getattr(run_all, f'{mode}_predictions'), getattr(run_all, f'{mode}_target')\n",
    "s = target.t\n",
    "s = (xlim[0] < s) & (s < xlim[1])\n",
    "axs[1,0].plot(target.t[s], target[s], 'k')\n",
    "s = pred.t\n",
    "s = (xlim[0] < s) & (s < xlim[1])\n",
    "axs[1,0].plot(pred.t[s], pred[s], color=pred_color)\n",
    "\n",
    "control = getattr(run_no_neural, f'{mode}_predictions')\n",
    "s = control.t\n",
    "s = (xlim[0] < s) & (s < xlim[1])\n",
    "axs[1,0].plot(control.t[s], control[s,:], '-', color=control_color)\n",
    "\n",
    "\n",
    "axs[0,0].set_ylabel('neural latent 1')\n",
    "axs[1,0].set_ylabel('arm position x and y (mm)')\n",
    "\n",
    "\n",
    "for axis in axs[:, 0]:\n",
    "    data_lim = np.array(axis.dataLim).T.flatten()\n",
    "    bounds = data_lim\n",
    "    bounds[:2] = (bounds[:2] - bounds[:2].mean()) * np.array([1.02, 1.02]) + bounds[:2].mean()\n",
    "    bounds[2:] = (bounds[2:] - bounds[2:].mean()) * np.array([1.05, 1.05]) + bounds[2:].mean()\n",
    "    axis.axis(bounds)\n",
    "    axis.format_coord = lambda x, y: 'x={:g}, y={:g}'.format(x, y)\n",
    "\n",
    "# this prints the last-half means\n",
    "for i, l in enumerate([\n",
    "    [\n",
    "        (0,f'{run_all.neural_correlations[1]:.2f}',dict(color=pred_color)),\n",
    "        (1,f'{run_no_neural.neural_correlations[1]:.2f}',dict(color=control_color)),\n",
    "    ], \n",
    "    [\n",
    "        (0, f'{run_all.beh_correlations[0]:.2f}', dict(color=pred_color)),\n",
    "        (1, f'{run_all.beh_correlations[1]:.2f}', dict(color=pred_color)),\n",
    "        (2, f'{run_no_neural.beh_correlations[0]:.2f}', dict(color=control_color)),\n",
    "        (3, f'{run_no_neural.beh_correlations[1]:.2f}', dict(color=control_color)),\n",
    "    ]\n",
    "]):\n",
    "    for idx, text, kw in l:\n",
    "        x, y = 1.01, .93 - .1 * idx\n",
    "        x, y = axs[i, 0].transLimits.inverted().transform([x, y])\n",
    "        axs[i, 0].text(x, y, text, clip_on=False, verticalalignment='top', **kw)\n",
    "\n",
    "\n",
    "fig.savefig(adaptive_latents.CONFIG['plot_save_path']/'performance.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T21:40:00.147935Z",
     "start_time": "2024-10-23T21:39:59.455026Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, squeeze=False, sharex=True, figsize=(5, 7), layout='tight')\n",
    "\n",
    "pred_color = [\n",
    "    '#770058',\n",
    "    '#8E0045',\n",
    "    '#9E0031',\n",
    "]\n",
    "control_color = [\n",
    "    '#9CA3DB',\n",
    "    '#677DB7',\n",
    "    '#454B66',\n",
    "]\n",
    "\n",
    "# control_color = [\n",
    "#     '#BF3100',\n",
    "#     '#EC9F05',\n",
    "#     '#FF4E00',\n",
    "# ]\n",
    "\n",
    "# pred_color = '#D11149'\n",
    "# control_color = '#6610F2'\n",
    "\n",
    "run_all = odoherty_run\n",
    "control_run = run_no_beh\n",
    "\n",
    "xlim = [500, 550]\n",
    "\n",
    "mode = 'neural'\n",
    "pred, target = getattr(run_all, f'{mode}_predictions'), getattr(run_all, f'{mode}_target')\n",
    "s = target.t\n",
    "s = (xlim[0] < s) & (s < xlim[1])\n",
    "axs[0,0].plot(target.t[s], target[s, 1], 'k')\n",
    "axs[1, 0].plot(target.t[s], target[s, 1], 'k')\n",
    "s = pred.t\n",
    "s = (xlim[0] < s) & (s < xlim[1])\n",
    "axs[0,0].plot(pred.t[s], pred[s,1], color=pred_color[0])\n",
    "\n",
    "control = getattr(control_run, f'{mode}_predictions')\n",
    "s = control.t\n",
    "s = (xlim[0] < s) & (s < xlim[1])\n",
    "axs[1,0].plot(control.t[s], control[s,1], '-', color=control_color[0])\n",
    "\n",
    "\n",
    "mode = 'beh'\n",
    "pred, target = getattr(run_all, f'{mode}_predictions'), getattr(run_all, f'{mode}_target')\n",
    "s = target.t\n",
    "s = (xlim[0] < s) & (s < xlim[1])\n",
    "axs[0,1].plot(target.t[s], target[s], 'k')\n",
    "axs[1,1].plot(target.t[s], target[s], 'k')\n",
    "s = pred.t\n",
    "s = (xlim[0] < s) & (s < xlim[1])\n",
    "axs[0,1].plot(pred.t[s], pred[s, 0], color=pred_color[1])\n",
    "axs[0,1].plot(pred.t[s], pred[s, 1], color=pred_color[2])\n",
    "\n",
    "control = getattr(control_run, f'{mode}_predictions')\n",
    "s = control.t\n",
    "s = (xlim[0] < s) & (s < xlim[1])\n",
    "axs[1,1].plot(control.t[s], control[s,0], '-', color=control_color[1])\n",
    "axs[1,1].plot(control.t[s], control[s,1], '-', color=control_color[2])\n",
    "\n",
    "\n",
    "axs[0,0].set_title('neural latent 1')\n",
    "axs[0,1].set_title('arm position x and y (mm)')\n",
    "\n",
    "axs[0,0].set_ylabel('from joint latents')\n",
    "axs[1,0].set_ylabel('from behavior')\n",
    "\n",
    "\n",
    "for axis in axs[:, 0]:\n",
    "    data_lim = np.array(axis.dataLim).T.flatten()\n",
    "    bounds = data_lim\n",
    "    bounds[:2] = (bounds[:2] - bounds[:2].mean()) * np.array([1.02, 1.02]) + bounds[:2].mean()\n",
    "    bounds[2:] = (bounds[2:] - bounds[2:].mean()) * np.array([1.05, 1.05]) + bounds[2:].mean()\n",
    "    axis.axis(bounds)\n",
    "    axis.format_coord = lambda x, y: 'x={:g}, y={:g}'.format(x, y)\n",
    "\n",
    "# this prints the last-half means\n",
    "for i, l in enumerate([\n",
    "    [\n",
    "        (0,0,f'{run_all.neural_correlations[1]:.2f}',dict(color=pred_color[0])),\n",
    "        (0,1, f'{run_all.beh_correlations[1]:.2f}', dict(color=pred_color[2])),\n",
    "        (1,1, f'{run_all.beh_correlations[0]:.2f}', dict(color=pred_color[1])),\n",
    "    ], \n",
    "    [\n",
    "        (0,0,f'{control_run.neural_correlations[1]:.2f}',dict(color=control_color[0])),\n",
    "        (0,1, f'{control_run.beh_correlations[0]:.2f}', dict(color=control_color[1])),\n",
    "        (1,1, f'{control_run.beh_correlations[1]:.2f}', dict(color=control_color[2])),\n",
    "    ]\n",
    "]):\n",
    "    for idx, j, text, kw in l:\n",
    "        x, y = .8, .98 - .05 * idx\n",
    "        x, y = axs[i, j].transLimits.inverted().transform([x, y])\n",
    "        axs[i, j].text(x, y, text, clip_on=False, verticalalignment='top', **kw)\n",
    "\n",
    "axs[0,1].set_yticks([])\n",
    "axs[1,1].set_yticks([])\n",
    "axs[1,0].set_xlabel('time (s)')\n",
    "axs[1,1].set_xlabel('time (s)')\n",
    "\n",
    "fig.savefig(adaptive_latents.CONFIG['plot_save_path']/'performance.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T18:19:08.547680Z",
     "start_time": "2024-10-23T18:19:07.756280Z"
    }
   },
   "outputs": [],
   "source": [
    "run_all.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# Zong22 Portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T16:55:38.534593Z",
     "start_time": "2024-10-04T16:49:55.034880Z"
    }
   },
   "outputs": [],
   "source": [
    "zong_run = prp.PipelineRun(**(prp.PipelineRun.default_parameter_values['zong22'] | dict(drop_behavior=True, sub_dataset_identifier=0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Dimensionality reduction comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T17:05:18.245911Z",
     "start_time": "2024-10-04T17:05:17.959691Z"
    }
   },
   "outputs": [],
   "source": [
    "run = zong_run\n",
    "fig, axs = plt.subplots(ncols=3, nrows=1, squeeze=False, figsize=(10,4), layout='tight')\n",
    "\n",
    "\n",
    "tail_length = 1\n",
    "with AnimationManager(fig=fig, make_axs=False, fps=10, filetype='mp4') as am:\n",
    "    for current_t in np.linspace(540, 550, 100):\n",
    "        plot_history_with_tail(axs[0,0], run.pro_latents, current_t, tail_length=1)\n",
    "        plot_history_with_tail(axs[0,1], run.jpca_latents, current_t, tail_length=1)\n",
    "        plot_history_with_tail(axs[0,2], run.ica_latents, current_t, tail_length=1)\n",
    "        axs[0,2].set_ylim([-3,5])\n",
    "        am.grab_frame()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.display(display.Video(am.outfile, embed=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T19:02:30.461620Z",
     "start_time": "2024-10-23T19:02:29.224570Z"
    }
   },
   "outputs": [],
   "source": [
    "run = odoherty_run\n",
    "current_t = 507.8\n",
    "grid_n=13\n",
    "square_radius=None\n",
    "arrow_alpha=0\n",
    "scatter_alpha=0\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, squeeze=False, layout='tight', figsize=(10, 4))\n",
    "axs = axs.T\n",
    "e1, e2 = np.zeros(6), np.zeros(6)\n",
    "e1[0] = 1\n",
    "e2[1] = 1\n",
    "\n",
    "for idx, latents in enumerate([run.pro_latents, run.jpca_latents, run.ica_latents]):\n",
    "    ax: plt.Axes = axs[idx,0]\n",
    "    \n",
    "    plot_history_with_tail(ax, latents, current_t, tail_length=.5, invisible=False)\n",
    "\n",
    "    if idx == 2:\n",
    "        ax.set_xlim([-6,6])\n",
    "        ax.set_ylim([-3,5])\n",
    "\n",
    "    d_latents = np.diff(latents, axis=0)\n",
    "    d_latents = d_latents / np.linalg.norm(d_latents, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    x1, x2, y1, y2 = ax.axis()\n",
    "    x_points = np.linspace(x1, x2, grid_n)\n",
    "    y_points = np.linspace(y1, y2, grid_n)\n",
    "    if square_radius is not None:\n",
    "        x_points = np.linspace(-square_radius, square_radius, grid_n)\n",
    "        y_points = np.linspace(-square_radius, square_radius, grid_n)\n",
    "\n",
    "    origins = []\n",
    "    arrows = []\n",
    "    n_points = []\n",
    "    for i in range(len(x_points) - 1):\n",
    "        for j in range(len(y_points) - 1):\n",
    "            proj_1 = (latents[:-1] @ e1)\n",
    "            proj_2 = (latents[:-1] @ e2)\n",
    "            s = (x_points[i] <= proj_1) & (proj_1 < x_points[i + 1]) & (y_points[j] <= proj_2) & (\n",
    "                    proj_2 < y_points[j + 1])\n",
    "            if s.sum():\n",
    "                arrow = d_latents[s].mean(axis=0)\n",
    "                arrow = arrow / np.linalg.norm(arrow)\n",
    "                arrows.append(arrow)\n",
    "                origins.append([x_points[i:i + 2].mean(), y_points[j:j + 2].mean()])\n",
    "                n_points.append(s.sum())\n",
    "    origins, arrows, n_points = np.array(origins), np.array(arrows), np.array(n_points)\n",
    "    # n_points = n_points / 5\n",
    "    n_points = n_points > 15\n",
    "    # n_points = 1\n",
    "    ax.quiver(origins[:, 0], origins[:, 1], arrows @ e1, arrows @ e2, scale=1 / 20, alpha=n_points, units='dots', color='red')\n",
    "\n",
    "    # ax.axis('equal')\n",
    "    ax.axis('off')\n",
    "\n",
    "axs[0, 0].set_ylabel('pro')\n",
    "axs[1, 0].set_ylabel('jpca')\n",
    "axs[2, 0].set_ylabel('ica')\n",
    "fig.savefig(adaptive_latents.CONFIG['plot_save_path']/'monkey_flow.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Stimulation figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T20:48:20.978307Z",
     "start_time": "2024-10-23T20:45:16.747605Z"
    }
   },
   "outputs": [],
   "source": [
    "fish_run = prp.PipelineRun(**prp.PipelineRun.default_parameter_values['naumann24u'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T16:55:39.633898Z",
     "start_time": "2024-10-04T16:55:39.558276Z"
    }
   },
   "outputs": [],
   "source": [
    "run = zong_run\n",
    "latents = run.jpca_latents\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2,figsize=(8,4), layout='tight')\n",
    "\n",
    "\n",
    "dim_1, dim_2 = 0,1\n",
    "\n",
    "\n",
    "planes = []\n",
    "for i in range(500):\n",
    "    run.d.raw_images.seek(i)\n",
    "    planes.append(np.array(run.d.raw_images))\n",
    "\n",
    "im = np.mean(planes, axis=0)\n",
    "\n",
    "means = np.mean(latents, axis=0)\n",
    "\n",
    "tail_length = 1\n",
    "with AnimationManager(fig=fig, make_axs=False, fps=20, filetype='mp4', dpi=400) as am:\n",
    "    a = 500\n",
    "    l = 10.5\n",
    "    for current_t in np.linspace(a, a+l, int(round(l*20))):\n",
    "        last_frame = current_t == a+l\n",
    "        \n",
    "        ax = axs[0]\n",
    "        ax.cla()\n",
    "        # plot_history_with_tail(ax, latents, current_t, tail_length=1)\n",
    "        plot_history_with_tail(ax, latents, current_t, tail_length=1, invisible=False)\n",
    "\n",
    "        s = latents.t <= current_t\n",
    "        current_state = latents[s][-1]\n",
    "\n",
    "        if last_frame:\n",
    "            ax.arrow(\n",
    "            current_state[dim_1], current_state[dim_2], means[dim_1] - current_state[dim_1], means[dim_2] - current_state[dim_2], \n",
    "            zorder=5, color='k', length_includes_head=True,  width=0.001, head_width=.04,\n",
    "            )\n",
    "        ax.axis('equal');\n",
    "        # ax.set_title(f'{current_t:.2f}')\n",
    "\n",
    "\n",
    "        \n",
    "        ax = axs[1]\n",
    "        ax.cla()\n",
    "        if last_frame:\n",
    "            desired_state = means - current_state\n",
    "            desired_stim = (desired_state @ run.pro.Q.T)[:run.d.neural_data.a.shape[-1]]\n",
    "    \n",
    "            desired_stim = np.abs(desired_stim)\n",
    "            desired_stim[np.abs(desired_stim) < .1] = np.nan\n",
    "    \n",
    "            ax.matshow(-im, cmap='Grays')\n",
    "            xs, ys = list(zip(*[cell['med'] for cell in run.d.stat]))\n",
    "            \n",
    "    \n",
    "            ax.scatter(ys, xs, s=desired_stim*30, color='red')\n",
    "        ax.axis('off')\n",
    "\n",
    "        am.grab_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T16:55:39.633898Z",
     "start_time": "2024-10-04T16:55:39.558276Z"
    }
   },
   "outputs": [],
   "source": [
    "run = zong_run\n",
    "latents = run.jpca_latents\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2,figsize=(8,4), layout='tight')\n",
    "\n",
    "\n",
    "dim_1, dim_2 = 0,1\n",
    "\n",
    "\n",
    "planes = []\n",
    "for i in range(500):\n",
    "    run.d.raw_images.seek(i)\n",
    "    planes.append(np.array(run.d.raw_images))\n",
    "\n",
    "im = np.mean(planes, axis=0)\n",
    "\n",
    "means = np.mean(latents, axis=0)\n",
    "\n",
    "tail_length = 1\n",
    "with AnimationManager(fig=fig, make_axs=False, fps=20, filetype='mp4', dpi=400) as am:\n",
    "    a = 500 + 10.5\n",
    "    l = 3\n",
    "    for current_t in np.linspace(a, a+l, int(round(l*20))):\n",
    "        last_frame = current_t == a+l\n",
    "        \n",
    "        ax = axs[0]\n",
    "        ax.cla()\n",
    "        # plot_history_with_tail(ax, latents, current_t, tail_length=1)\n",
    "        plot_history_with_tail(ax, latents, current_t, tail_length=1, invisible=False)\n",
    "\n",
    "        s = latents.t <= current_t\n",
    "        current_state = latents[s][-1]\n",
    "\n",
    "        if last_frame:\n",
    "            ax.arrow(\n",
    "            current_state[dim_1], current_state[dim_2], means[dim_1] - current_state[dim_1], means[dim_2] - current_state[dim_2], \n",
    "            zorder=5, color='k', length_includes_head=True,  width=0.001, head_width=.04,\n",
    "            )\n",
    "        ax.axis('equal');\n",
    "        # ax.set_title(f'{current_t:.2f}')\n",
    "\n",
    "\n",
    "        \n",
    "        ax = axs[1]\n",
    "        ax.cla()\n",
    "        if last_frame:\n",
    "            desired_state = means - current_state\n",
    "            desired_stim = (desired_state @ run.pro.Q.T)[:run.d.neural_data.a.shape[-1]]\n",
    "    \n",
    "            desired_stim = np.abs(desired_stim)\n",
    "            desired_stim[np.abs(desired_stim) < .1] = np.nan\n",
    "    \n",
    "            ax.matshow(-im, cmap='Grays')\n",
    "            xs, ys = list(zip(*[cell['med'] for cell in run.d.stat]))\n",
    "            \n",
    "    \n",
    "            ax.scatter(ys, xs, s=desired_stim*30, color='red')\n",
    "        ax.axis('off')\n",
    "\n",
    "        am.grab_frame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
