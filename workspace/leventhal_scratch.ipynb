{
 "cells": [
  {
   "cell_type": "code",
   "id": "48f777644b4b6a3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:16:04.913249Z",
     "start_time": "2024-08-12T15:16:03.218177Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import adaptive_latents\n",
    "import itertools\n",
    "from adaptive_latents import CenteringTransformer, Pipeline, proSVD, KernelSmoother, sjPCA, mmICA\n",
    "from adaptive_latents.bw_run import AnimationManager\n",
    "from datasets import Leventhal24uDataset\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:16:05.053013Z",
     "start_time": "2024-08-12T15:16:04.913973Z"
    }
   },
   "cell_type": "code",
   "source": "d = Leventhal24uDataset(bin_size=.2)",
   "id": "43cafc3b-6a7e-48ba-9102-0e02062e5b13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading Intan Technologies RHD Data File, Version 1.5\n",
      "\n",
      "Found 64 amplifier channels.\n",
      "Found 3 auxiliary input channels.\n",
      "Found 1 supply voltage channel.\n",
      "Found 8 board ADC channels.\n",
      "Found 16 board digital input channels.\n",
      "Found 16 board digital output channels.\n",
      "Found 0 temperature sensors channels.\n",
      "\n",
      "Header file contains no data.  Amplifiers were sampled at 20.00 kS/s.\n",
      "Done!  Elapsed time: 0.0 seconds\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:16:05.057036Z",
     "start_time": "2024-08-12T15:16:05.053447Z"
    }
   },
   "cell_type": "code",
   "source": "d.trial_data[d.trial_data['correct']==True].tone",
   "id": "95d93b3e9d2eb93d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       211.12585\n",
       "5       274.62790\n",
       "6       288.62475\n",
       "7       300.11055\n",
       "9       321.03705\n",
       "          ...    \n",
       "119    3264.95535\n",
       "121    3356.51145\n",
       "123    3414.59035\n",
       "124    3433.77315\n",
       "126    3582.67150\n",
       "Name: tone, Length: 67, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = d.trial_data\n",
    "\n",
    "for column in ['timing', 'timestamps']:\n",
    "    df = pd.concat([df.drop(column, axis=1), df[column].apply(pd.Series)], axis=1)\n",
    "df"
   ],
   "id": "94907b0cae4a7e99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "d.trial_data['timing'].apply(pd.Series)",
   "id": "82e6ca92cd2208b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "d.trial_data['timing'][1]",
   "id": "f89bb9ab94d6d82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* pretone is tone - centerIn\n",
    "* RT is centerOUt - tone\n",
    "* MT is sideIn - centerOut "
   ],
   "id": "4a48c9bfd6c3ddc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib qt\n",
    "plt.scatter(d.spike_times, d.spike_clusters, marker='|')\n",
    "for i, row in d.trial_data.iterrows():\n",
    "    if row['valid']:\n",
    "        plt.axvline(row['cueOn'], color='k')\n",
    "        if row['correct']:\n",
    "            plt.axvline(row['tone'], color='green')\n",
    "        else:\n",
    "            plt.axvline(row['tone'], color='red')\n",
    "\n",
    "        # plt.axvline(row['centerOut'], color='C1')\n",
    "    # plt.axvline(row['Time'] + row['SideInToFood'], color='C2')\n",
    "    # plt.axvline(row['Time'] + row['MT'], color='C3')\n",
    "    # plt.axvline(row['Time'] + row['pretone'], color='C1')\n",
    "    "
   ],
   "id": "ee6dd343c1fef58f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots()\n",
    "KernelSmoother(tau=1, kernel_length=5*1).plot_impulse_response(ax)"
   ],
   "id": "735c1258f9d93d2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "a = np.squeeze(d.neural_data.a)\n",
    "plt.plot(PCA().fit(a).explained_variance_)\n",
    "print(a.sum())\n",
    "a = KernelSmoother(kernel_length=10, tau=2).offline_run_on(a)\n",
    "plt.plot(PCA().fit(a).explained_variance_)\n",
    "print(a.sum())\n",
    "\n"
   ],
   "id": "f7b2c50f4a8a0825",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "a = np.squeeze(d.neural_data.a)\n",
    "plt.plot(a[:,0], '.')\n",
    "b = KernelSmoother(kernel_length=25, tau=8).offline_run_on(a, convinient_return=False)\n",
    "b = np.squeeze(b[0])\n",
    "plt.plot(b[:,0])\n",
    "plt.xlim([200, 400])"
   ],
   "id": "17acc33b293e58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "d = Leventhal24uDataset(bin_size=.1)\n",
    "p = Pipeline([\n",
    "    KernelSmoother(tau=8),\n",
    "    CenteringTransformer(),\n",
    "    proSVD(k=6, init_size=50, whiten=False, log_level=0),\n",
    "    # mmICA()\n",
    "])\n",
    "output = p.offline_run_on(d.neural_data, convinient_return=True)"
   ],
   "id": "e06296aaa27acbde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib qt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "axes = (0,1,2)\n",
    "\n",
    "start = 2000\n",
    "time_slice = slice(start, start + 3000)\n",
    "\n",
    "ax.scatter(output[time_slice, axes[0]], output[time_slice, axes[1]], output[time_slice, axes[2]], alpha=.1, color='C1')\n",
    "ax.set_xlabel(f'dimension {axes[0]}')\n",
    "ax.set_ylabel(f'dimension {axes[1]}')\n",
    "ax.set_zlabel(f'dimension {axes[2]}')\n",
    "plt.tight_layout()\n",
    "plt.axis('equal');"
   ],
   "id": "6645fecaa4c01555",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "\n",
    "def random_walk(num_steps, max_step=0.05):\n",
    "    \"\"\"Return a 3D random walk as (num_steps, 3) array.\"\"\"\n",
    "    start_pos = np.random.random(3)\n",
    "    steps = np.random.uniform(-max_step, max_step, size=(num_steps, 3))\n",
    "    walk = start_pos + np.cumsum(steps, axis=0)\n",
    "    return walk\n",
    "\n",
    "\n",
    "def update_lines(num, walks, lines):\n",
    "    for line, walk in zip(lines, walks):\n",
    "        line.set_data_3d(walk[:num, :].T)\n",
    "    return lines\n",
    "\n",
    "\n",
    "# Data: 40 random walks as (num_steps, 3) arrays\n",
    "num_steps = 30\n",
    "walks = [random_walk(num_steps) for index in range(40)]\n",
    "\n",
    "# Attaching 3D axis to the figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "# Create lines initially without data\n",
    "lines = [ax.plot([], [], [])[0] for _ in walks]\n",
    "\n",
    "# Setting the Axes properties\n",
    "ax.set(xlim3d=(0, 1), xlabel='X')\n",
    "ax.set(ylim3d=(0, 1), ylabel='Y')\n",
    "ax.set(zlim3d=(0, 1), zlabel='Z')\n",
    "\n",
    "# Creating the Animation object\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, update_lines, num_steps, fargs=(walks, lines), interval=100)\n",
    "\n",
    "plt.show()"
   ],
   "id": "7e7bc45fa0bf8ff7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots()\n",
    "# plt.scatter(output[100:, 0], output[100:, 1], alpha=.1)\n",
    "plt.plot(output[-500:, 0], output[-500:, 1], color='C1')\n",
    "plt.tight_layout()\n",
    "plt.axis('equal');"
   ],
   "id": "982f34fe797b8399",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "d.trial_data['Time'][43] - 1",
   "id": "aa6efc1a1d0c7d6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.argmin(np.abs(d.neural_data.t - (d.trial_data['Time'][43] - 1)))",
   "id": "93797662f5dc7bb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "d = Leventhal24uDataset(bin_size=.1)\n",
    "p = Pipeline([\n",
    "    KernelSmoother(tau=8),\n",
    "    CenteringTransformer(),\n",
    "    proSVD(k=6, init_size=50, whiten=False, log_level=0),\n",
    "    KernelSmoother(tau=1),\n",
    "    mmICA()\n",
    "])\n",
    "\n",
    "start = 1238\n",
    "video_time = 40\n",
    "tq = tqdm(total=start+video_time)\n",
    "\n",
    "with AnimationManager(fps=40) as am:\n",
    "    output = []\n",
    "    for i, output_row in enumerate(p.run_on(d.neural_data, return_output_stream=False)):\n",
    "        if i < 100:\n",
    "            continue\n",
    "        output.append(output_row)\n",
    "        o = np.squeeze(output)\n",
    "\n",
    "        next_t = d.neural_data.current_sample_time()\n",
    "        if len(o.shape) == 2 and start < next_t < start + video_time:\n",
    "            am.ax[0,0].cla()\n",
    "            am.ax[0,0].autoscale(True)\n",
    "            \n",
    "            am.ax[0,0].scatter(o[:,0], o[:,1], alpha=.999**np.arange(o.shape[0])[::-1], color='C0', linewidth=0, s=5)\n",
    "            am.ax[0,0].plot(o[-10:,0], o[-10:,1], color='C1')\n",
    "            am.ax[0,0].set_title(f'{i}')\n",
    "            am.ax[0,0].axis('equal')\n",
    "\n",
    "            # if np.abs(next_t - (d.trial_data['Time'] + d.trial_data['preTone'])).min() < .5:\n",
    "            if np.abs(next_t - (d.trial_data['Time'])).min() < .5:\n",
    "                x = (am.ax[0,0].transAxes + am.ax[0,0].transData.inverted()).transform((.98,.98))\n",
    "                am.ax[0,0].autoscale(False)\n",
    "                am.ax[0,0].scatter(*x, color='green', s=100)\n",
    "\n",
    "            am.grab_frame()\n",
    "        elif next_t > start + video_time:\n",
    "            break\n",
    "        tq.update(np.floor(next_t - tq.n).astype(int))\n"
   ],
   "id": "ae6fe951676c670d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "\n",
    "d = Leventhal24uDataset(bin_size=.1)\n",
    "\n",
    "pipelines = [\n",
    "    Pipeline([\n",
    "        KernelSmoother(tau=8),\n",
    "        CenteringTransformer(),\n",
    "        proSVD(k=6),\n",
    "        KernelSmoother(tau=8),\n",
    "        mmICA()\n",
    "    ]),\n",
    "    # Pipeline([\n",
    "    #     KernelSmoother(tau=8),\n",
    "    #     CenteringTransformer(),\n",
    "    #     proSVD(k=6, whiten=True),\n",
    "    #     KernelSmoother(tau=8),\n",
    "    #     mmICA()\n",
    "    # ]),\n",
    "]\n",
    "\n",
    "start = 1238 # in s\n",
    "video_time = 80 # in s\n",
    "tq = tqdm(total=start+video_time)\n",
    "\n",
    "with AnimationManager(fps=40) as am:\n",
    "    \n",
    "    outputs = [[] for p in pipelines]\n",
    "    for i, output_rows in enumerate(zip(*[p.run_on(d.neural_data) for p in pipelines])):\n",
    "        if i < 100:\n",
    "            continue\n",
    "        \n",
    "        for j, row in enumerate(output_rows):\n",
    "            outputs[j].append(row)\n",
    "        os = [np.squeeze(o) for o in outputs]\n",
    "\n",
    "        next_ts = [p.mid_run_sources[0][0].current_sample_time() for p in pipelines]\n",
    "        assert all(t == next_ts[0] for t in next_ts)\n",
    "        next_t = next_ts[0]\n",
    "        o = os[0]\n",
    "        if len(o.shape) == 2 and start < next_t < start + video_time:\n",
    "            am.ax[0,0].cla()\n",
    "            am.ax[0,0].autoscale(True)\n",
    "            \n",
    "            for j, o in enumerate(os):\n",
    "                am.ax[0,0].scatter(o[:,0], o[:,1], alpha=.999**np.arange(o.shape[0])[::-1], color=f'C{j}', linewidth=0, s=5)\n",
    "                am.ax[0,0].plot(o[-10:,0], o[-10:,1], color=f'C{j}')\n",
    "            am.ax[0,0].set_title(f'frame={i}, time={next_t:.1f}')\n",
    "            am.ax[0,0].axis('equal')\n",
    "\n",
    "            # if np.abs(next_t - (d.trial_data['Time'] + d.trial_data['preTone'])).min() < .5:\n",
    "            if np.abs(next_t - (d.trial_data['Time'])).min() < .5:\n",
    "                dot_point = np.array([.98,.98])\n",
    "                # dot_point = (am.ax[0,0].transAxes + am.ax[0,0].transData.inverted()).transform(dot_point)\n",
    "                # am.ax[0,0].autoscale(False)\n",
    "                dot_point = dot_point * 10\n",
    "                am.ax[0,0].scatter(*dot_point, color='green', s=100)\n",
    "\n",
    "            am.ax[0,0].set_xlim([-10, 10])\n",
    "            am.ax[0,0].set_ylim([-10, 10])\n",
    "            am.grab_frame()\n",
    "        elif next_t > start + video_time:\n",
    "            break\n",
    "        tq.update(np.floor(next_t - tq.n).astype(int))\n"
   ],
   "id": "56deff4760605f0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
