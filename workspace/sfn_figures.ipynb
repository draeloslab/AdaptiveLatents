{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:28:47.347895Z",
     "start_time": "2024-09-30T18:28:45.571810Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import adaptive_latents\n",
    "from adaptive_latents import (\n",
    "    AnimationManager, \n",
    "    Pipeline, \n",
    "    CenteringTransformer, \n",
    "    proSVD, \n",
    "    Bubblewrap, \n",
    "    VanillaOnlineRegressor, \n",
    "    NumpyTimedDataSource, \n",
    "    KernelSmoother, \n",
    "    Concatenator, \n",
    "    sjPCA, \n",
    "    ZScoringTransformer, \n",
    "    mmICA\n",
    ")\n",
    "import adaptive_latents.input_sources.datasets as datasets\n",
    "import adaptive_latents.plotting_functions as pf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from adaptive_latents.timed_data_source import ArrayWithTime\n",
    "from IPython.display import Video, Image, display\n",
    "\n",
    "from importlib import reload\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "rng = np.random.default_rng()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:28:47.527130Z",
     "start_time": "2024-09-30T18:28:47.348790Z"
    }
   },
   "outputs": [],
   "source": [
    "!echo $(hostname) $(git rev-parse --short HEAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "\n",
    "## Prediction tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-30T18:43:32.124284Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "%matplotlib inline\n",
    "shortrun = hostname == 'tycho' and True\n",
    "\n",
    "\n",
    "d = datasets.Odoherty21Dataset(neural_lag=0, pos_rescale_factor=1/30, vel_rescale_factor=1/75)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "0: [neural_data] -> center -> smooth -> concat[0] -> 2\n",
    "1: [behavior] -> Zscore -> concat[1] -> 2\n",
    "2: prosvd -> jpca -> bubblewrap -> regression1['x']\n",
    "3: [behavior] -> regression1['y']\n",
    "4: [neural_data] -> center -> smooth -> prosvd -> regression2['y']\n",
    "5: joints\n",
    "\"\"\"\n",
    "\n",
    "streams = []\n",
    "streams.append((d.neural_data, 0))\n",
    "streams.append((d.beh_pos, 1))\n",
    "# 2 is reserved for the post-concatination pipeline\n",
    "streams.append((d.beh_pos, 3))\n",
    "streams.append((d.neural_data, 4))\n",
    "# 5 for the alpha to joint\n",
    "\n",
    "# this pipeline makes the latent space\n",
    "p1 = Pipeline([\n",
    "    neural_centerer:=CenteringTransformer(init_size=100, input_streams={0:'X'}, output_streams={0:0}),\n",
    "    CenteringTransformer(init_size=100, input_streams={1:'X'}, output_streams={1:1}),\n",
    "    nerual_smoother:=KernelSmoother(tau=0.12/d.bin_width, input_streams={0:'X'}, output_streams={0:0}),\n",
    "    Concatenator(input_streams={0: 0, 1: 1}, output_streams={0:2, 1:2, 'skip':-1}, zero_sreams={}),\n",
    "])\n",
    "\n",
    "pro=proSVD(k=6, init_size=100, input_streams={2:'X'}, output_streams={2:2})\n",
    "jpca=sjPCA(init_size=100, input_streams={2:'X'}, output_streams={2:2})\n",
    "ica=mmICA(init_size=100, input_streams={2:'X'}, output_streams={2:2})\n",
    "\n",
    "\n",
    "latents_for_bw = ['prosvd', 'jpca', 'mmica'][1]\n",
    "pre_bw_latent_dims_to_drop = 0\n",
    "\n",
    "\n",
    "# this pipeline handles the prediction and regression\n",
    "bw = Bubblewrap(\n",
    "    num=1100,\n",
    "    M=500,\n",
    "    lam=1e-3,\n",
    "    nu=1e-3,\n",
    "    eps=1e-4,\n",
    "    step=1,\n",
    "    num_grad_q=1,\n",
    "    sigma_orig_adjustment=100, # 0\n",
    "    input_streams={2:'X'},\n",
    "    output_streams={2:2},\n",
    "    log_level=1,\n",
    ")\n",
    "\n",
    "alpha_to_beh_reg = VanillaOnlineRegressor(\n",
    "    input_streams={2:'X', 3:'Y'},\n",
    ")\n",
    "\n",
    "neural_only_reg_pipeline = Pipeline([\n",
    "    CenteringTransformer(**(neural_centerer.get_params() | dict(input_streams={4:'X'}, output_streams={4:4}))),\n",
    "    KernelSmoother(**(nerual_smoother.get_params() | dict(input_streams={4:'X'}, output_streams={4:4}))),\n",
    "    proSVD(k=4, init_size=100, input_streams={4:'X'}, output_streams={4:4}),\n",
    "    alpha_to_neural_reg:=VanillaOnlineRegressor(\n",
    "        input_streams={2:'X', 4:'Y'},\n",
    "    )\n",
    "    \n",
    "], \n",
    "reroute_inputs=False\n",
    ")\n",
    "\n",
    "alpha_to_joint_latents_reg = VanillaOnlineRegressor(\n",
    "    input_streams={2:'X', 5:'Y'},\n",
    ")\n",
    "\n",
    "\n",
    "exit_time = 40 if shortrun else 300\n",
    "\n",
    "pbar = tqdm(total=exit_time)\n",
    "pro_latents = []\n",
    "jpca_latents = []\n",
    "ica_latents = []\n",
    "\n",
    "next_bubble_predictions = []\n",
    "beh_predictions = []\n",
    "neural_predictions = []\n",
    "joint_predictions = []\n",
    "\n",
    "beh_target = []\n",
    "neural_target = []\n",
    "joint_target = []\n",
    "\n",
    "\n",
    "for output, stream in p1.streaming_run_on(streams, return_output_stream=True):\n",
    "    # prosvd step\n",
    "    pro_output, pro_stream = pro.partial_fit_transform(output, stream, return_output_stream=True)\n",
    "    if pro_stream == 2 and np.isfinite(pro_output).all():\n",
    "        pro_latents.append(pro_output)\n",
    "\n",
    "    # sjpca step\n",
    "    jpca_output, jpca_stream = jpca.partial_fit_transform(pro_output, pro_stream, return_output_stream=True)\n",
    "    if jpca_stream == 2 and np.isfinite(jpca_output).all():\n",
    "        jpca_latents.append(jpca_output)\n",
    "\n",
    "    # ica step (not in main line)\n",
    "    ica_output, ica_stream = ica.partial_fit_transform(pro_output, pro_stream, return_output_stream=True)\n",
    "    if ica_stream == 2 and np.isfinite(ica_output).all():\n",
    "        ica_latents.append(ica_output)\n",
    "\n",
    "    # bw step\n",
    "    pre_bw_output, pre_bw_stream = {\n",
    "        'prosvd': (pro_output, pro_stream),\n",
    "        'jpca': (jpca_output, jpca_stream),\n",
    "        'mmica': (ica_output, ica_stream),\n",
    "    }[latents_for_bw] \n",
    "    \n",
    "    if pre_bw_stream == 2 and pre_bw_latent_dims_to_drop > 0:\n",
    "        pre_bw_output = pre_bw_output[:,:-pre_bw_latent_dims_to_drop]\n",
    "    \n",
    "    output, stream = bw.partial_fit_transform(pre_bw_output, pre_bw_stream, return_output_stream=True)\n",
    "\n",
    "    # fit all the regressions on alpha\n",
    "    alpha_to_beh_reg.partial_fit_transform(output, stream)\n",
    "    neural_stream_output, neural_stream_stream = neural_only_reg_pipeline.partial_fit_transform(output, stream, return_output_stream=True)\n",
    "    \n",
    "    alpha_to_joint_latents_reg.partial_fit_transform(output, stream)\n",
    "    alpha_to_joint_latents_reg.partial_fit_transform(pre_bw_output, 5 if pre_bw_stream == 2 else pre_bw_stream)\n",
    "    \n",
    "    if stream == 3:\n",
    "        beh_target.append(output)\n",
    "        \n",
    "    if neural_stream_stream == 4 and not np.isnan(neural_stream_output).any():\n",
    "        neural_target.append(neural_stream_output)\n",
    "        \n",
    "    if pre_bw_stream == 2 and np.isfinite(pre_bw_output).all():\n",
    "        joint_target.append(pre_bw_output)\n",
    "    \n",
    "    if stream == 2 and np.isfinite(output).all(): # do predictions\n",
    "        prediction_t = output.t + bw.dt\n",
    "\n",
    "        # alpha_pred = bw.get_alpha_at_t(0, relative_t=True)\n",
    "\n",
    "        alpha_pred = bw.get_alpha_at_t(prediction_t)\n",
    "\n",
    "        # alpha_pred[np.argmax(bw.alpha)] = 0\n",
    "        # alpha_pred[alpha_pred < alpha_pred.max()] = 0\n",
    "        # alpha_pred = alpha_pred / alpha_pred.sum()\n",
    "\n",
    "\n",
    "        next_bubble_predictions.append(ArrayWithTime(bw.mu[np.argmax(alpha_pred)], t=prediction_t))\n",
    "        \n",
    "        beh_predictions.append(ArrayWithTime(alpha_to_beh_reg.predict(alpha_pred), t=prediction_t))\n",
    "        neural_predictions.append(ArrayWithTime(alpha_to_neural_reg.predict(alpha_pred), t=prediction_t))\n",
    "        joint_predictions.append(ArrayWithTime(alpha_to_joint_latents_reg.predict(alpha_pred), t=prediction_t))\n",
    "    \n",
    "\n",
    "    if output.t >= exit_time:\n",
    "        break\n",
    "\n",
    "    pbar.update(round(output.t,1) - pbar.n)\n",
    "\n",
    "\n",
    "pro_latents = ArrayWithTime.from_list(pro_latents)\n",
    "jpca_latents = ArrayWithTime.from_list(jpca_latents)\n",
    "ica_latents = ArrayWithTime.from_list(ica_latents)\n",
    "\n",
    "next_bubble_predictions = ArrayWithTime.from_list(next_bubble_predictions)\n",
    "\n",
    "beh_predictions = ArrayWithTime.from_list(beh_predictions)\n",
    "neural_predictions = ArrayWithTime.from_list(neural_predictions)\n",
    "joint_predictions = ArrayWithTime.from_list(joint_predictions)\n",
    "\n",
    "\n",
    "beh_target = ArrayWithTime.from_list(beh_target)\n",
    "neural_target = ArrayWithTime.from_list(neural_target)\n",
    "joint_target = ArrayWithTime.from_list(joint_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:42.110700Z",
     "start_time": "2024-09-30T18:29:41.554069Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "behavior_dicts = [\n",
    "    dict(\n",
    "        true_behavior=beh_target,\n",
    "        true_behavior_t=beh_target.t,\n",
    "        predicted_behavior=beh_predictions,\n",
    "        predicted_behavior_t=beh_predictions.t,\n",
    "        label='beh'\n",
    "    ),\n",
    "    dict(\n",
    "        true_behavior=neural_target,\n",
    "        true_behavior_t=neural_target.t,\n",
    "        predicted_behavior=neural_predictions,\n",
    "        predicted_behavior_t=neural_predictions.t,\n",
    "        label='neural'\n",
    "    ),\n",
    "    dict(\n",
    "        true_behavior=joint_target,\n",
    "        true_behavior_t=joint_target.t,\n",
    "        predicted_behavior=joint_predictions,\n",
    "        predicted_behavior_t=joint_predictions.t,\n",
    "        label='joint'\n",
    "    ),\n",
    "    ]\n",
    "adaptive_latents.plotting_functions = reload(adaptive_latents.plotting_functions)\n",
    "adaptive_latents.plotting_functions.plot_bw_pipeline([bw], behavior_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:43:16.121055Z",
     "start_time": "2024-09-30T18:43:15.611323Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, squeeze=False, layout='tight', figsize=(10,10))\n",
    "\n",
    "e1, e2 = np.zeros(6), np.zeros(6)\n",
    "e1[0] = 1\n",
    "e2[1] = 1\n",
    "\n",
    "for idx, latents in enumerate([pro_latents, jpca_latents, ica_latents]):\n",
    "    ax = axs[idx, 0]\n",
    "    # ax.scatter(latents[:,0], latents[:,1], s=5)\n",
    "\n",
    "    d_latents = np.diff(latents, axis=0)\n",
    "    d_latents = d_latents / np.linalg.norm(d_latents, axis=1)[:, np.newaxis]\n",
    "    # ax.quiver(latents[:-1] @ e1, latents[:-1]@e2, d_latents@e1, d_latents@e2, scale=1 / 20, units='dots', alpha=.5)\n",
    "    x1, x2, y1, y2 = ax.axis()\n",
    "    x_points = np.linspace(x1, x2, 51)\n",
    "    y_points = np.linspace(y1, y2, 51)\n",
    "    # mgrid = np.meshgrid(*[np.linspace(latents[:, i].min(), latents[:, i].max(), 10) for i in range(2)])\n",
    "    origins = []\n",
    "    arrows = []\n",
    "    for i in range(len(x_points)-1):\n",
    "        for j in range(len(y_points)-1):\n",
    "            proj_1 = (latents[:-1] @ e1)\n",
    "            proj_2 = (latents[:-1] @ e2)\n",
    "            s = (x_points[i] <= proj_1) & (proj_1 < x_points[i+1]) & (y_points[j] <= proj_2) & (proj_2 < y_points[j+1])\n",
    "            if s.sum():\n",
    "                arrow = d_latents[s].mean(axis=0)\n",
    "                arrow = arrow / np.linalg.norm(arrow)\n",
    "                arrows.append(arrow)\n",
    "                origins.append([x_points[i:i+2].mean(), y_points[j:j+2].mean()])\n",
    "    origins, arrows = np.array(origins), np.array(arrows)\n",
    "    ax.quiver(origins[:,0], origins[:,1], arrows@e1, arrows@e2, scale=1 / 20, units='dots', color='red') \n",
    "            \n",
    "\n",
    "    ax.axis('equal')\n",
    "\n",
    "    ax = axs[idx, 1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "axs[0,1].plot(pro.inverse_transform(e1, 2))\n",
    "axs[0,1].plot(pro.inverse_transform(e2, 2))\n",
    "axs[0,0].set_ylabel('pro')\n",
    "\n",
    "axs[1,1].plot(pro.inverse_transform(jpca.inverse_transform(e1, 2), 2))\n",
    "axs[1,1].plot(pro.inverse_transform(jpca.inverse_transform(e2, 2), 2))\n",
    "axs[1,0].set_ylabel('jpca')\n",
    "\n",
    "axs[2,1].plot(pro.inverse_transform(ica.inverse_transform(e1, 2), 2))\n",
    "axs[2,1].plot(pro.inverse_transform(ica.inverse_transform(e2, 2), 2))\n",
    "axs[2,0].set_ylabel('ica')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:42.819954Z",
     "start_time": "2024-09-30T18:29:42.817872Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:42.940969Z",
     "start_time": "2024-09-30T18:29:42.820422Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "latents = jpca_latents\n",
    "\n",
    "dim_1, dim_2 = 0,1\n",
    "pf.plot_history_with_tail(ax, latents, dim_1=dim_1, dim_2=dim_2)\n",
    "means = np.mean(latents, axis=0)\n",
    "\n",
    "ax.arrow(latents[-1,dim_1], latents[-1,dim_2], means[dim_1] - latents[-1,dim_1], means[dim_2] - latents[-1,dim_2], zorder=5, head_width=.1, color='k')\n",
    "\n",
    "ax.axis('equal');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:43.106176Z",
     "start_time": "2024-09-30T18:29:42.941794Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.matshow(bw.log['alpha'][-300:])\n",
    "ax.set_title('alpha')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:43.197942Z",
     "start_time": "2024-09-30T18:29:43.107035Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "d.plot_variances(ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T18:29:43.324132Z",
     "start_time": "2024-09-30T18:29:43.198997Z"
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(d, datasets.Zong22Dataset)\n",
    "desired_pattern = np.mean(latents[-101:-1], axis=0)\n",
    "current_pattern = latents[-1]\n",
    "desired_stim = desired_pattern - current_pattern\n",
    "\n",
    "desired_pattern = (desired_stim @ pro.Q.T)[:d.neural_data.a.shape[-1]]\n",
    "\n",
    "near_zero = np.abs(desired_stim) < 100\n",
    "print(near_zero.sum())\n",
    "desired_stim[near_zero] = np.nan\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "d.show_stim_pattern(ax, np.abs(desired_pattern))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Intro video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datasets.Odoherty21Dataset()\n",
    "\n",
    "tail_length = 5  # seconds\n",
    "\n",
    "with AnimationManager(n_cols=2, n_rows=1, figsize=(10, 5)) as am:\n",
    "    for current_t in np.linspace(100, 110, 51):\n",
    "        am.axs[0,0].cla()\n",
    "\n",
    "        n_columns = np.floor(tail_length / d.bin_width).astype(int)\n",
    "        idx = np.nonzero(~(d.neural_data.t < current_t))[0][0]\n",
    "        \n",
    "        \n",
    "        am.axs[0,0].imshow(d.neural_data.a[idx-n_columns:idx,0,:].T, aspect='auto', interpolation='none', extent=[current_t - tail_length, current_t, d.neural_data.a.shape[2], 0])\n",
    "\n",
    "\n",
    "\n",
    "        old_lims = am.axs[0,1].axis()\n",
    "        am.axs[0,1].cla()\n",
    "        am.axs[0,1].axis('off')\n",
    "        \n",
    "        s = ((current_t - tail_length) < d.behavioral_data.t) & (d.behavioral_data.t < current_t)\n",
    "        am.axs[0,1].plot(d.behavioral_data.a[s,0,0], d.behavioral_data.a[s,0,1])\n",
    "        pf.use_bigger_lims(am.axs[0,1], old_lims)\n",
    "        \n",
    "        am.grab_frame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
