{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T16:09:07.891557Z",
     "start_time": "2024-10-04T16:09:06.235384Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import adaptive_latents.input_sources.datasets as datasets\n",
    "import adaptive_latents.plotting_functions as pf\n",
    "import matplotlib.pyplot as plt\n",
    "import prediction_regression_pipeline as prp\n",
    "from adaptive_latents.plotting_functions import PredictionVideo\n",
    "from adaptive_latents import (\n",
    "    AnimationManager\n",
    ")\n",
    "import adaptive_latents\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "from IPython import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "* [jPCA figure](https://www.dropbox.com/scl/fo/duf5zbwcibsux467c6oc9/AIN-ZiFsy2Huyh8h7VMdL7g?dl=0&e=1&preview=Basic+jPCA+plot.pdf&rlkey=3o5axmq5hirel4cij7g64jc0r)\n",
    "* [gpfa figure](https://users.ece.cmu.edu/~byronyu/software.shtml)\n",
    "* [lfads figure](https://www.nature.com/articles/s41592-018-0109-9/figures/1) (copied from the paper)\n",
    "* [cebra figure](https://www.nature.com/articles/s41586-023-06031-6/figures/1) (copied from the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T16:09:08.172203Z",
     "start_time": "2024-10-04T16:09:07.892410Z"
    }
   },
   "outputs": [],
   "source": [
    "!echo $(hostname) $(git rev-parse --short HEAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptive_latents.plotting_functions import plot_history_with_tail\n",
    "adaptive_latents.plotting_functions = reload(adaptive_latents.plotting_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Intro Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intro_plot(d, tail_length=5, duration=10, start_time=10, fps=20):\n",
    "    with AnimationManager(n_cols=2, n_rows=1, figsize=(10, 5), filetype='mp4', fps=fps) as am:\n",
    "        am.axs[0,1].scatter(d.behavioral_data.a[:,0,0], d.behavioral_data.a[:,0,1])\n",
    "        for current_t in np.linspace(start_time, start_time + duration, duration*fps):\n",
    "            am.axs[0,0].cla()\n",
    "    \n",
    "            n_columns = np.floor(tail_length / np.median(np.diff(d.neural_data.t))).astype(int)\n",
    "            idx = np.nonzero(~(d.neural_data.t < current_t))[0][0]\n",
    "            \n",
    "            \n",
    "            am.axs[0,0].imshow(d.neural_data.a[idx-n_columns:idx,0,:].T, aspect='auto', interpolation='none', extent=[current_t - tail_length, current_t, d.neural_data.a.shape[2], 0],\n",
    "                              vmin=d.neural_data.a.min(),vmax=d.neural_data.a.max())\n",
    "            am.axs[0,0].set_xticklabels([])\n",
    "    \n",
    "    \n",
    "    \n",
    "            old_lims = am.axs[0,1].axis()\n",
    "            am.axs[0,1].cla()\n",
    "            am.axs[0,1].axis('off')\n",
    "            \n",
    "            s = ((current_t - tail_length) < d.behavioral_data.t) & (d.behavioral_data.t < current_t)\n",
    "            am.axs[0,1].plot(d.behavioral_data.a[s,0,0], d.behavioral_data.a[s,0,1])\n",
    "            pf.use_bigger_lims(am.axs[0,1], old_lims)\n",
    "            \n",
    "            am.grab_frame()\n",
    "    \n",
    "    display.display(display.Video(am.outfile, embed=True))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datasets.Odoherty21Dataset()\n",
    "intro_plot(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datasets.Peyrache15Dataset()\n",
    "intro_plot(d,start_time=16185)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datasets.Zong22Dataset()\n",
    "intro_plot(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datasets.Schaffer23Datset()\n",
    "intro_plot(d, start_time=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datasets.TostadoMarcos24Dataset()\n",
    "intro_plot(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Odoherty21 Portion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Intro video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Trajectory with 2d histogram background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T16:34:23.476191Z",
     "start_time": "2024-10-04T16:09:12.568680Z"
    }
   },
   "outputs": [],
   "source": [
    "odoherty_run = prp.PipelineRun(**prp.PipelineRun.default_parameter_values['odoherty21'])\n",
    "run = odoherty_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T17:05:10.647632Z",
     "start_time": "2024-10-04T17:05:10.535061Z"
    }
   },
   "outputs": [],
   "source": [
    "run = odoherty_run\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "\n",
    "\n",
    "tail_length = 1\n",
    "with AnimationManager(fig=fig, make_axs=False, fps=20, filetype='mp4') as am:\n",
    "    for current_t in np.linspace(600, 610, 200):\n",
    "        plot_history_with_tail(axs[0], run.neural_target, current_t, tail_length, hist_bins=30)\n",
    "        plot_history_with_tail(axs[1], run.jpca_latents,  current_t, tail_length, hist_bins=30)\n",
    "        plot_history_with_tail(axs[2], run.beh_target, current_t, tail_length, hist_bins=30)\n",
    "        am.grab_frame()\n",
    "\n",
    "plt.close();\n",
    "display.display(display.Video(am.outfile, embed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Data, Latent, Prediction graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T16:43:30.921132Z",
     "start_time": "2024-10-04T16:43:02.270087Z"
    }
   },
   "outputs": [],
   "source": [
    "run = odoherty_run\n",
    "\n",
    "import adaptive_latents.plotting_functions\n",
    "pv = reload(adaptive_latents.plotting_functions).PredictionVideo(run.d, fps=20, filetype='mp4')\n",
    "\n",
    "\n",
    "\n",
    "assert (run.next_bubble_joint_predictions.t == run.beh_predictions.t).all()\n",
    "with pv.am:\n",
    "    for current_t in np.linspace(600, 610, 200):\n",
    "        pv.plot_for_video_t(\n",
    "            current_t, \n",
    "            run.jpca_latents, run.jpca_latents.t, \n",
    "            run.next_bubble_joint_predictions, run.beh_predictions, run.beh_predictions.t,\n",
    "            run.streams\n",
    "        )\n",
    "plt.close()\n",
    "display.display(display.Video(pv.am.outfile, embed=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Stream table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T16:49:55.001572Z",
     "start_time": "2024-10-04T16:43:30.921820Z"
    }
   },
   "outputs": [],
   "source": [
    "run_all = odoherty_run\n",
    "if False:\n",
    "    run_no_neural = prp.PipelineRun(**(prp.PipelineRun.default_parameter_values['odoherty21'] | dict(concat_zero_streams=[0])))\n",
    "    run_no_beh = prp.PipelineRun(**(prp.PipelineRun.default_parameter_values['odoherty21'] | dict(concat_zero_streams=[1])))\n",
    "    def make_row(run):\n",
    "        return ({\n",
    "            'beh_x': run.beh_correlations[0],\n",
    "            'beh_y': run.beh_correlations[1],\n",
    "        } | {f'neural_{n}': run.neural_correlations[n] for n in range(len(run.neural_correlations))})\n",
    "        \n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            make_row(run_all),\n",
    "            make_row(run_no_neural),\n",
    "            make_row(run_no_beh)\n",
    "        ], \n",
    "        index = ['all', 'no_neural', 'no_beh']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# Zong22 Portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T16:55:38.534593Z",
     "start_time": "2024-10-04T16:49:55.034880Z"
    }
   },
   "outputs": [],
   "source": [
    "zong_run = prp.PipelineRun(**(prp.PipelineRun.default_parameter_values['zong22'] | dict(drop_behavior=True, sub_dataset_identifier=0)))\n",
    "run = zong_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Dimensionality reduction comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T17:05:18.245911Z",
     "start_time": "2024-10-04T17:05:17.959691Z"
    }
   },
   "outputs": [],
   "source": [
    "run = zong_run\n",
    "fig, axs = plt.subplots(ncols=3, nrows=1, squeeze=False, figsize=(10,4), layout='tight')\n",
    "\n",
    "\n",
    "tail_length = 1\n",
    "with AnimationManager(fig=fig, make_axs=False, fps=10, filetype='mp4') as am:\n",
    "    for current_t in np.linspace(540, 550, 100):\n",
    "        plot_history_with_tail(axs[0,0], run.pro_latents, current_t, tail_length=1)\n",
    "        plot_history_with_tail(axs[0,1], run.jpca_latents, current_t, tail_length=1)\n",
    "        plot_history_with_tail(axs[0,2], run.ica_latents, current_t, tail_length=1)\n",
    "        axs[0,2].set_ylim([-3,5])\n",
    "        am.grab_frame()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.display(display.Video(am.outfile, embed=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T17:05:23.856250Z",
     "start_time": "2024-10-04T17:05:23.488430Z"
    }
   },
   "outputs": [],
   "source": [
    "run = zong_run\n",
    "grid_n=13\n",
    "square_radius=None\n",
    "arrow_alpha=0\n",
    "scatter_alpha=0\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, squeeze=False, layout='tight', figsize=(10, 4))\n",
    "axs = axs.T\n",
    "e1, e2 = np.zeros(6), np.zeros(6)\n",
    "e1[0] = 1\n",
    "e2[1] = 1\n",
    "\n",
    "for idx, latents in enumerate([run.pro_latents, run.jpca_latents, run.ica_latents]):\n",
    "    ax: plt.Axes = axs[idx,0]\n",
    "    \n",
    "    plot_history_with_tail(ax, latents, current_t, tail_length=1, invisible=True)\n",
    "\n",
    "    if idx == 2:\n",
    "        ax.set_xlim([-6,6])\n",
    "        ax.set_ylim([-3,5])\n",
    "\n",
    "    d_latents = np.diff(latents, axis=0)\n",
    "    d_latents = d_latents / np.linalg.norm(d_latents, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    x1, x2, y1, y2 = ax.axis()\n",
    "    x_points = np.linspace(x1, x2, grid_n)\n",
    "    y_points = np.linspace(y1, y2, grid_n)\n",
    "    if square_radius is not None:\n",
    "        x_points = np.linspace(-square_radius, square_radius, grid_n)\n",
    "        y_points = np.linspace(-square_radius, square_radius, grid_n)\n",
    "\n",
    "    origins = []\n",
    "    arrows = []\n",
    "    n_points = []\n",
    "    for i in range(len(x_points) - 1):\n",
    "        for j in range(len(y_points) - 1):\n",
    "            proj_1 = (latents[:-1] @ e1)\n",
    "            proj_2 = (latents[:-1] @ e2)\n",
    "            s = (x_points[i] <= proj_1) & (proj_1 < x_points[i + 1]) & (y_points[j] <= proj_2) & (\n",
    "                    proj_2 < y_points[j + 1])\n",
    "            if s.sum():\n",
    "                arrow = d_latents[s].mean(axis=0)\n",
    "                arrow = arrow / np.linalg.norm(arrow)\n",
    "                arrows.append(arrow)\n",
    "                origins.append([x_points[i:i + 2].mean(), y_points[j:j + 2].mean()])\n",
    "                n_points.append(s.sum())\n",
    "    origins, arrows, n_points = np.array(origins), np.array(arrows), np.array(n_points)\n",
    "    # n_points = n_points / 5\n",
    "    n_points = n_points > 15\n",
    "    # n_points = 1\n",
    "    ax.quiver(origins[:, 0], origins[:, 1], arrows @ e1, arrows @ e2, scale=1 / 20, alpha=n_points, units='dots', color='red')\n",
    "\n",
    "    # ax.axis('equal')\n",
    "    ax.axis('off')\n",
    "\n",
    "axs[0, 0].set_ylabel('pro')\n",
    "axs[1, 0].set_ylabel('jpca')\n",
    "axs[2, 0].set_ylabel('ica')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Stimulation figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T16:55:39.633898Z",
     "start_time": "2024-10-04T16:55:39.558276Z"
    }
   },
   "outputs": [],
   "source": [
    "run = zong_run\n",
    "latents = run.jpca_latents\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2,figsize=(8,4))\n",
    "\n",
    "\n",
    "dim_1, dim_2 = 0,1\n",
    "\n",
    "\n",
    "planes = []\n",
    "for i in range(500):\n",
    "    run.d.raw_images.seek(i)\n",
    "    planes.append(np.array(run.d.raw_images))\n",
    "\n",
    "im = np.mean(planes, axis=0)\n",
    "\n",
    "means = np.mean(latents, axis=0)\n",
    "\n",
    "tail_length = 1\n",
    "with AnimationManager(fig=fig, make_axs=False, fps=20, filetype='mp4') as am:\n",
    "    for current_t in np.linspace(500, 540, 40*20):\n",
    "        last_frame = current_t == 540\n",
    "        \n",
    "        ax = axs[0]\n",
    "        ax.cla()\n",
    "        # plot_history_with_tail(ax, latents, current_t, tail_length=1)\n",
    "        plot_history_with_tail(ax, latents, current_t, tail_length=1, invisible=False)\n",
    "\n",
    "        s = latents.t <= current_t\n",
    "        current_state = latents[s][-1]\n",
    "\n",
    "        if last_frame:\n",
    "            ax.arrow(\n",
    "            current_state[dim_1], current_state[dim_2], means[dim_1] - current_state[dim_1], means[dim_2] - current_state[dim_2], \n",
    "            zorder=5, color='k', length_includes_head=True,  width=0.001, head_width=.04,\n",
    "            )\n",
    "        ax.axis('equal');\n",
    "\n",
    "        \n",
    "        ax = axs[1]\n",
    "        ax.cla()\n",
    "        if last_frame:\n",
    "            desired_state = means - current_state\n",
    "            desired_stim = (desired_state @ run.pro.Q.T)[:run.d.neural_data.a.shape[-1]]\n",
    "    \n",
    "            desired_stim = np.abs(desired_stim)\n",
    "            desired_stim[np.abs(desired_stim) < .1] = np.nan\n",
    "    \n",
    "            ax.matshow(-im, cmap='Grays')\n",
    "            xs, ys = list(zip(*[cell['med'] for cell in run.d.stat]))\n",
    "            \n",
    "    \n",
    "            ax.scatter(ys, xs, s=desired_stim*30, color='red')\n",
    "            # ax.set_title(f'{current_t:.2f}')\n",
    "        ax.axis('off')\n",
    "        if not last_frame:\n",
    "            am.grab_frame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
