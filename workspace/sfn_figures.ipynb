{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T21:00:55.075656Z",
     "start_time": "2024-09-28T21:00:55.072313Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import adaptive_latents\n",
    "from adaptive_latents import AnimationManager, Pipeline, CenteringTransformer, proSVD, Bubblewrap, VanillaOnlineRegressor, NumpyTimedDataSource, KernelSmoother, Concatenator, sjPCA\n",
    "import adaptive_latents.input_sources.datasets as datasets\n",
    "import adaptive_latents.plotting_functions as pf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import Video, Image, display\n",
    "from importlib import reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T21:00:55.641040Z",
     "start_time": "2024-09-28T21:00:55.289282Z"
    }
   },
   "outputs": [],
   "source": [
    "!echo $(hostname) $(git rev-parse --short HEAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "\n",
    "## Combination and prediction video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T21:05:29.714228Z",
     "start_time": "2024-09-28T21:00:55.645387Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "d = datasets.Odoherty21Dataset(neural_lag=0)\n",
    "# d = TestDataset()\n",
    "\n",
    "streams = []\n",
    "streams.append( (d.neural_data,     0) )\n",
    "streams.append( (d.beh_vel, 1) )\n",
    "streams.append( (d.beh_vel, 3) )\n",
    "\n",
    "p1 = Pipeline([\n",
    "    CenteringTransformer(init_size=50, input_streams={0:'X'}, output_streams={0:0}),\n",
    "    # CenteringTransformer(init_size=0, input_streams={1:'X'}, output_streams={1:1}),\n",
    "    KernelSmoother(tau=0.04/d.bin_width, input_streams={0:'X'}, output_streams={0:0}),\n",
    "    Concatenator(input_streams={0: 0, 1: 1}, output_streams={0:2, 1:2, 'skip':-1}),\n",
    "    pro:=proSVD(k=6, init_size=100, input_streams={2:'X'}, output_streams={2:2}),\n",
    "    jpca:=sjPCA(init_size=100, input_streams={2:'X'}, output_streams={2:2}),\n",
    "])\n",
    "\n",
    "p2 = Pipeline([\n",
    "    bw:=Bubblewrap(\n",
    "        num=1100,\n",
    "        M=500,\n",
    "        lam=1e-3,\n",
    "        nu=1e-3,\n",
    "        eps=1e-4,\n",
    "        step=1,\n",
    "        num_grad_q=1,\n",
    "        sigma_orig_adjustment=100, # 0\n",
    "        input_streams={2:'X'},\n",
    "        output_streams={2:2},\n",
    "        log_level=1,\n",
    "    ),\n",
    "    reg:=VanillaOnlineRegressor(\n",
    "        input_streams={2:'X', 3:'Y'},\n",
    "        output_streams={2:2},\n",
    "    ),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "video_dt = 0.05\n",
    "video_ts = np.arange(100)*video_dt + 150\n",
    "streams.append( (NumpyTimedDataSource(np.nan * video_ts, video_ts), 'video') )\n",
    "\n",
    "\n",
    "pbar = tqdm(total=video_ts[-1])\n",
    "latents = []\n",
    "latent_ts = []\n",
    "\n",
    "latent_predictions = []\n",
    "beh_predictions = []\n",
    "prediction_ts = []\n",
    "\n",
    "pred_am = None\n",
    "bw_am = None\n",
    "with (\n",
    "    plt.ioff(),\n",
    "    AnimationManager(fps=1/video_dt, filetype='gif') as bw_am, \n",
    "    (vid:=pf.PredictionVideo(d, fps=1/video_dt, filetype='gif')).am as pred_am\n",
    "):\n",
    "    for output, stream in Pipeline().streaming_run_on(streams, return_output_stream=True):\n",
    "        # dim reduction part of pipeline\n",
    "        output, stream = p1.partial_fit_transform(output, stream, return_output_stream=True)\n",
    "        if stream == 2 and np.isfinite(output).all():\n",
    "            latents.append(output)\n",
    "            latent_ts.append(output.t)\n",
    "\n",
    "        # prediction part of pipeline\n",
    "        output, stream = p2.partial_fit_transform(output, stream, return_output_stream=True)\n",
    "        if stream == 2 and np.isfinite(output).all():\n",
    "            prediction_t = output.t + bw.dt\n",
    "            \n",
    "            # alpha_pred = bw.get_alpha_at_t(0, relative_t=True)\n",
    "            \n",
    "            alpha_pred = bw.get_alpha_at_t(prediction_t)\n",
    "            \n",
    "            # alpha_pred[np.argmax(bw.alpha)] = 0\n",
    "            # alpha_pred[alpha_pred < alpha_pred.max()] = 0\n",
    "            # alpha_pred = alpha_pred / alpha_pred.sum()\n",
    "            \n",
    "            latent_prediction = np.array(bw.mu[np.argmax(alpha_pred)])\n",
    "            beh_prediction = reg.predict(alpha_pred)\n",
    "\n",
    "            latent_predictions.append(latent_prediction)\n",
    "            beh_predictions.append(beh_prediction)\n",
    "            prediction_ts.append(prediction_t)\n",
    "            \n",
    "        \n",
    "        if stream == 'video':\n",
    "            \n",
    "            if bw_am is not None:\n",
    "                if output.t == video_ts[0]:\n",
    "                    ax: plt.Axes = bw_am.axs[0,0]\n",
    "                    ax.text(0,1, f\"p1={str(p1)}\\np2={str(p2)}\\nmin video t={video_ts.min()}\", transform=ax.transAxes, fontsize='xx-small', verticalalignment='top', wrap=True)\n",
    "                    bw_am.grab_frame()\n",
    "                    \n",
    "                ax: plt.Axes = bw_am.axs[0,0]\n",
    "                ax.cla()\n",
    "                bw.scatter_data_with_decay(ax,np.squeeze(latents))\n",
    "                bw.show_active_bubbles_and_connections_2d(ax, np.squeeze(latents))\n",
    "                bw_am.grab_frame()\n",
    "                \n",
    "            if pred_am is not None:\n",
    "                if output.t == video_ts[0]:\n",
    "                    ax = vid.neural_data_ax\n",
    "                    ax.text(0,1, f\"p1={str(p1)}\\np2={str(p2)}\\nmin video t={video_ts.min()}\", transform=ax.transAxes, fontsize='xx-small', verticalalignment='top', wrap=True)\n",
    "                    ax.set_zorder(1)\n",
    "                    pred_am.grab_frame()\n",
    "                \n",
    "                vid.plot_for_video_t(output.t, latents, latent_ts, latent_predictions, beh_predictions, prediction_ts)\n",
    "            \n",
    "            if output.t == video_ts[-1]:\n",
    "                break\n",
    "\n",
    "        pbar.update(round(output.t,1) - pbar.n)\n",
    "\n",
    "\n",
    "latents = np.squeeze(latents)\n",
    "latent_predictions = np.squeeze(latent_predictions)\n",
    "beh_predictions = np.squeeze(beh_predictions)\n",
    "prediction_ts = np.squeeze(prediction_ts)\n",
    "\n",
    "plt.close()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T21:05:30.072385Z",
     "start_time": "2024-09-28T21:05:29.715080Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "behavior_dict = dict(\n",
    "    true_behavior=np.squeeze(d.behavioral_data.a),\n",
    "    true_behavior_t=d.behavioral_data.t,\n",
    "    predicted_behavior=beh_predictions,\n",
    "    predicted_behavior_t=prediction_ts,\n",
    ")\n",
    "adaptive_latents.bubblewrap.Bubblewrap.compare_runs([bw], [behavior_dict], t_in_samples=True)\n",
    "plt.show()\n",
    "\n",
    "if pred_am is not None:\n",
    "    display_class = Image if 'gif' in str(pred_am.outfile) else Video\n",
    "    display(display_class(pred_am.outfile, embed=True, width=900))\n",
    "\n",
    "\n",
    "if bw_am is not None:\n",
    "    display_class = Image if 'gif' in str(bw_am.outfile) else Video\n",
    "    display(display_class(bw_am.outfile, embed=True, width=700))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.matshow(bw.log['alpha'][-300:])\n",
    "ax.set_title('alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T21:05:30.155693Z",
     "start_time": "2024-09-28T21:05:30.073701Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "s = np.array(latent_ts) > 10\n",
    "# ax.scatter(latents[s,0], latents[s,1], s=5, alpha=.1, c='C0', edgecolors='none')\n",
    "sub_latents = latents[s]\n",
    "d_sub_latents = np.diff(sub_latents, axis=0)\n",
    "d_sub_latents = d_sub_latents / np.linalg.norm(d_sub_latents, axis=1)[:, np.newaxis]\n",
    "\n",
    "ax.quiver(sub_latents[:-1,0], sub_latents[:-1,1], d_sub_latents[:,0], d_sub_latents[:,1], scale=1/20, units='dots')\n",
    "\n",
    "x1, x2, y1, y2 = ax.axis()\n",
    "\n",
    "x_points = np.linspace(x1, x2, 10)\n",
    "y_points = np.linspace(y1, y2, 10)\n",
    "mgrid = np.meshgrid(*[np.linspace(sub_latents[:,i].min(),sub_latents[:,i].max(), 10) for i in range(sub_latents.shape[1])])\n",
    "\n",
    "# arrows = np.zeros(shape=(len(points), sub_latents.shape[1]))\n",
    "\n",
    "# ax.quiver(points[:,0], points[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T21:05:30.198499Z",
     "start_time": "2024-09-28T21:05:30.156320Z"
    }
   },
   "outputs": [],
   "source": [
    "e1, e2 = np.zeros(6), np.zeros(6)\n",
    "e1[0] = 1\n",
    "e2[1] = 1\n",
    "\n",
    "plt.plot(pro.inverse_transform(jpca.inverse_transform(e1, 2), 2))\n",
    "plt.plot(pro.inverse_transform(jpca.inverse_transform(e2, 2), 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T21:05:30.203839Z",
     "start_time": "2024-09-28T21:05:30.199174Z"
    }
   },
   "outputs": [],
   "source": [
    "jpca.get_U()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T21:05:30.444297Z",
     "start_time": "2024-09-28T21:05:30.204657Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.matshow(bw.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T21:05:30.662122Z",
     "start_time": "2024-09-28T21:05:30.446891Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "dim_1, dim_2 = 0,1\n",
    "pf.plot_history_with_tail(ax, latents, dim_1=dim_1, dim_2=dim_2)\n",
    "means = np.mean(latents, axis=0)\n",
    "\n",
    "ax.arrow(latents[-1,dim_1], latents[-1,dim_2], means[dim_1] - latents[-1,dim_1], means[dim_2] - latents[-1,dim_2], zorder=5, head_width=.1, color='k')\n",
    "\n",
    "ax.axis('equal');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T21:05:30.910601Z",
     "start_time": "2024-09-28T21:05:30.663256Z"
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(d, datasets.Zong22Dataset)\n",
    "desired_pattern = np.mean(latents[-101:-1], axis=0)\n",
    "current_pattern = latents[-1]\n",
    "desired_stim = desired_pattern - current_pattern\n",
    "\n",
    "desired_pattern = (desired_stim @ pro.Q.T)[:d.neural_data.a.shape[-1]]\n",
    "\n",
    "near_zero = np.abs(desired_stim) < 100\n",
    "print(near_zero.sum())\n",
    "desired_stim[near_zero] = np.nan\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "d.show_stim_pattern(ax, np.abs(desired_pattern))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Intro video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datasets.Odoherty21Dataset()\n",
    "\n",
    "tail_length = 5  # seconds\n",
    "\n",
    "with AnimationManager(n_cols=2, n_rows=1, figsize=(10, 5)) as am:\n",
    "    for current_t in np.linspace(100, 110, 51):\n",
    "        am.axs[0,0].cla()\n",
    "\n",
    "        n_columns = np.floor(tail_length / d.bin_width).astype(int)\n",
    "        idx = np.nonzero(~(d.neural_data.t < current_t))[0][0]\n",
    "        \n",
    "        \n",
    "        am.axs[0,0].imshow(d.neural_data.a[idx-n_columns:idx,0,:].T, aspect='auto', interpolation='none', extent=[current_t - tail_length, current_t, d.neural_data.a.shape[2], 0])\n",
    "\n",
    "\n",
    "\n",
    "        old_lims = am.axs[0,1].axis()\n",
    "        am.axs[0,1].cla()\n",
    "        am.axs[0,1].axis('off')\n",
    "        \n",
    "        s = ((current_t - tail_length) < d.behavioral_data.t) & (d.behavioral_data.t < current_t)\n",
    "        am.axs[0,1].plot(d.behavioral_data.a[s,0,0], d.behavioral_data.a[s,0,1])\n",
    "        pf.use_bigger_lims(am.axs[0,1], old_lims)\n",
    "        \n",
    "        am.grab_frame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
