{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import adaptive_latents as al\n",
    "import tensortools as tt\n",
    "from tensortools.cpwarp import fit_shifted_cp\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import scipy\n",
    "\n",
    "from naumann_utility_functions import make_responses, find_decompositions, reshape_by_group, compare_rows, plot_comparison, plot_per_neuron\n",
    "\n",
    "rng = np.random.default_rng()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = al.datasets.Naumann24uDataset(sub_dataset_identifier=2)\n",
    "responses = make_responses(d)\n",
    "non_nan_responses = responses[...,:d.n_neurons_in_optical]\n",
    "\n",
    "models = find_decompositions(non_nan_responses, n_restarts=200)\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "template = [[1.]]\n",
    "convolved = scipy.signal.convolve2d(template, d.neural_data[:,:d.n_neurons_in_optical], mode='valid')\n",
    "plt.matshow(convolved.T, aspect='auto')\n",
    "# 83\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "template = model.factors[2].T\n",
    "convolved = scipy.signal.convolve2d(template, d.neural_data[:,:d.n_neurons_in_optical], mode='valid')\n",
    "plt.matshow(convolved.T, aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "signal = 100 * np.array(d.neural_data[50:,75])\n",
    "divisor = 100 * model.factors[2].flatten()\n",
    "\n",
    "divisor = divisor[np.cumsum(np.abs(divisor)) > 1]\n",
    "quotient, remainder = scipy.signal.deconvolve(signal, divisor)\n",
    "\n",
    "fig, axs = plt.subplots(2,2)\n",
    "axs[0,0].plot(signal)\n",
    "axs[0,1].plot(divisor)\n",
    "\n",
    "axs[1,0].plot(quotient)\n",
    "axs[1,0].set_ylim([-10,10])\n",
    "axs[1,1].plot(remainder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.factors[2].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "template = model.factors[2].T @ model.factors[0]\n",
    "convolved = scipy.signal.convolve2d(template, d.neural_data[:,:d.n_neurons_in_optical], mode='valid')\n",
    "plt.plot(convolved)\n",
    "for s in d.opto_stimulations['sample']:\n",
    "    plt.axvline(s, color='g', alpha=.5)\n",
    "\n",
    "for s in d.visual_stimuli['sample']:\n",
    "    plt.axvline(s, color='r', alpha=.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "responses = make_responses(d)\n",
    "responses_by_group = reshape_by_group(responses, d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Initial Plot\n",
    "My initial question was whether the stimulations influenced neural activity, so I inspected the correspondence between stimulation times and neural activity (the C matrix) using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.matshow(d.neural_data.T)\n",
    "\n",
    "red_line = ax.axvline(d.last_visual_sample, color='r')\n",
    "for x in d.opto_stimulations['sample']:\n",
    "    white_line = ax.axvline(x, color='w', alpha = .5)\n",
    "\n",
    "ax.legend([red_line, white_line], ['last visual stimulus', 'optogenetic stimuli'])\n",
    "ax.set_xlabel(\"sample\")\n",
    "ax.set_ylabel(\"neuron\")\n",
    "\n",
    "ax.set_xlim([1000, 1500])\n",
    "ax.set_ylim([300, 0]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "Checking the image of the neural traces, it seems reasonable that some of the neural traces (especially around 75) are responding to the stimuli.\n",
    "I was next interested in the consistency of the responses to multiple stimulations of the same neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Extract responses\n",
    "To check the consistency of the neural responses to a single group of stimuli, I first extracted the neural activity after each stimulus.\n",
    "For each stimulus, I defined the response period to be as long as possible while staying between stimuli, so 30 samples for 'output_012824_ds3'.\n",
    "'Responses' were then neural activity during the response period normalized by the activity during the first sample. \n",
    "Psudeocode with the `C` matrix would look something like this: `responses[...] = C[:, stim_start:stim_start + 30] - C[:, stim_start]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Some neural responses are consistent\n",
    "To compare the responses of a group of stimulations to the same neuron, I plotted the 'response' flouresence traces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_single_group_responses(group_n, responses_by_group):\n",
    "    target_neurons = np.squeeze([np.unique(x) for x in reshape_by_group(d.opto_stimulations.target_neuron, d)])\n",
    "    assert abs(len(responses_by_group) - len(target_neurons)) <= 1\n",
    "    \n",
    "    single_group_responses = responses_by_group[group_n]\n",
    "    target_neuron = target_neurons[group_n]\n",
    "\n",
    "    fig, axs = plt.subplots(ncols=max(single_group_responses.shape[0],2), nrows=2,  figsize=(10, 5), sharey='row')\n",
    "    gs = axs[1,0].get_gridspec()\n",
    "    for ax in axs[1, :4]:\n",
    "        ax.remove()\n",
    "    axs[1,0] = fig.add_subplot(gs[1,:2])\n",
    "\n",
    "    stimuli_in_previous_groups = sum([r.shape[0] for r in responses_by_group[:group_n]])\n",
    "    for i, ax in enumerate(axs[0,:]):\n",
    "        stimulus_number = stimuli_in_previous_groups + i\n",
    "        ax.plot(single_group_responses[i,:,:])\n",
    "        ax.set_xlabel('samples from stim')\n",
    "        ax.set_title(f'stim {stimulus_number}, neuron = {d.opto_stimulations.loc[stimulus_number,\"target_neuron\"]}', fontsize='small')\n",
    "\n",
    "    mean_responses = single_group_responses.mean(axis=0)\n",
    "    axs[1,0].plot(mean_responses)\n",
    "\n",
    "    axs[0,0].set_ylabel('response magnitude (a.u.)')\n",
    "\n",
    "    axs[1,0].set_ylabel('response magnitude (a.u.)')\n",
    "    axs[1,0].set_title(f'average response for group {group_n}')\n",
    "    axs[1,0].set_xlabel('samples from stim')\n",
    "    \n",
    "    sizes = np.mean(mean_responses, axis=0)\n",
    "    sizes = np.abs(sizes / 7.3) * 15\n",
    "    sizes[sizes < 5]  = np.nan\n",
    "    plot_per_neuron(axs[1,4], sizes, d)\n",
    "    axs[1,4].scatter(d.neuron_df.loc[target_neuron, 'x'], d.neuron_df.loc[target_neuron, 'y'], s=10, color='blue')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    print(f\"Neuron with the highest average peak: {np.unravel_index(np.nanargmax(mean_responses), mean_responses.shape)[1]}\")\n",
    "\n",
    "def make_stim_subplot(ax, group_n, responses_by_group):\n",
    "    target_neurons = np.squeeze([np.unique(x) for x in reshape_by_group(d.opto_stimulations.target_neuron, d)])\n",
    "    assert abs(len(responses_by_group) - len(target_neurons)) <= 1\n",
    "\n",
    "    single_group_responses = responses_by_group[group_n]\n",
    "    target_neuron = target_neurons[group_n]\n",
    "\n",
    "    mean_responses = single_group_responses.mean(axis=0)\n",
    "\n",
    "    sizes = np.mean(mean_responses, axis=0)\n",
    "    sizes = np.abs(sizes / 7.3) * 15\n",
    "    sizes[sizes < 5]  = np.nan\n",
    "    plot_per_neuron(ax, sizes, d)\n",
    "    ax.scatter(d.neuron_df.loc[target_neuron, 'x'], d.neuron_df.loc[target_neuron, 'y'], s=10, color='blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_to_inspect = {\n",
    "    'output_012824_ds6_fish3': [5,7,13],\n",
    "    'output_012824_ds3': [4,8,11],\n",
    "    'output_020424_ds1': [9,14,19],\n",
    "}.get(d.sub_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_single_group_responses(group_n=groups_to_inspect[0], responses_by_group=responses_by_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Some neurons showed consistent responses; group 5, stimulating neuron 107, is a good example of a consistent response.\n",
    "This group of responses displays variability, but there is clearly a pattern for the average to pick up on; particularly the red trace (neuron 83).\n",
    "Note, however, that the most consistently active neuron (83) is not the neuron that was targeted for stimulation (107.)\n",
    "This plot works for identifying consistent large-magnitude responses, but a limitation I haven't addressed is that it will not clearly show low-magnitude (but still consistent) responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_group_responses(group_n=groups_to_inspect[1], responses_by_group=responses_by_group)\n",
    "plot_single_group_responses(group_n=groups_to_inspect[2], responses_by_group=responses_by_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5,5, layout='tight')\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i < len(responses_by_group):\n",
    "        make_stim_subplot(ax, group_n=i, responses_by_group=responses_by_group)\n",
    "    else:\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Comparison matrices\n",
    "To visualize more completely how the responses within groups compare, I next constructed comparison matrices.\n",
    "I was mostly looking to see if the responses within groups  were more similar than responses between groups; this would \n",
    "indicate that targeting specific neurons had consistent, distinguishable effects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoint = 14\n",
    "responses_sub_mat = np.vstack([responses_by_group[i] for i in groups_to_inspect])[:, timepoint, :d.n_neurons_in_optical]\n",
    "\n",
    "comparison_methods = [ 'distances', 'angles', 'norm_distances']\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(10,5))\n",
    "\n",
    "for ax, method in zip(axs, comparison_methods):\n",
    "    plot_comparison(ax, compare_rows(responses_sub_mat, method=method), group_sizes=[responses_by_group[i].shape[0] for i in groups_to_inspect], group_names=[chr(65+i) for i in groups_to_inspect])\n",
    "    ax.set_title(f'Comparison using {method}')\n",
    "    \n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Next, I wanted to see if the responses within groups were more similar than the responses between groups.\n",
    "From the traces in the previous section, it appears that group 5 has more internal consistency than groups 7 and 13, which I want to quantify here.\n",
    "The distance metric that ended up being most useful for this comparison is the angle (`method='angles'` above) between responses at a given timepoint (here, timepoint 14).\n",
    "I tried using distances at first, but I think that metric was too sensitive to bulk changes in excitation, like in the 3rd trial of group 13.\n",
    "\n",
    "I interpret the comparisons above to mean that stimuli in group 5 had a consistent response, whereas groups 7 and 13 had varying responses that did not align.\n",
    "(I cherry-picked these from the next graph.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoint = 13 \n",
    "non_nan_responses = responses[...,:d.n_neurons_in_optical]\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, gridspec_kw={'width_ratios': [20, 1]}, figsize=(7,7))\n",
    "\n",
    "comparison_matrix = compare_rows(non_nan_responses[:,timepoint,:], method='angles')\n",
    "plot_comparison(axs[0], comparison_matrix, group_sizes=[g.shape[0] for g in responses_by_group], ax_colorbar=axs[1])\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trials_indexes_to_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoint = 13 \n",
    "non_nan_responses = responses[...,:d.n_neurons_in_optical]\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, gridspec_kw={'width_ratios': [20, 1]}, figsize=(7,7))\n",
    "\n",
    "comparison_matrix = compare_rows(non_nan_responses[:,timepoint,:], method='angles')\n",
    "plot_comparison(axs[0], comparison_matrix, group_sizes=[g.shape[0] for g in responses_by_group], ax_colorbar=axs[1])\n",
    "\n",
    "\n",
    "trials_to_mark = \"N2 C0 L2 D2 I3 G0 N3 C1 G1\".split(' ')\n",
    "trials_indexes_to_mark = [(ord(g) - 65) * 5 + int(i) for g,i in trials_to_mark]\n",
    "\n",
    "axs[0].set_xticks(trials_indexes_to_mark)\n",
    "axs[0].set_xticklabels(trials_to_mark, rotation=90, size='small')\n",
    "axs[0].set_yticks(trials_indexes_to_mark)\n",
    "\n",
    "axs[0].set_xlabel(\"\")\n",
    "axs[0].set_ylabel(\"\")\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "This is a similar graph, but now considering all pairs of stimuli.\n",
    "Note that much of the variation centers around 90°, as we might expect.\n",
    "In the next plot, I will center the color axis range on 90° to give the colorscale more dynamic range.\n",
    "\n",
    "Note that for many groups, the within-group similarity is similar to across-group similarities.\n",
    "For example, the reactions to stimuli in group 4 are about as similar to each other as they are to reactions in group 5.\n",
    "If this were a covariance matrix, I would immediately suspect a single low-rank principal component that most groups are aligned to.\n",
    "But, since I'm looking at angles instead of covariance, I need to check more explicitly in the next section.\n",
    "Having one dominating response component makes me wonder what's going on biologically, though.\n",
    "\n",
    "Also note that groups 7 and 13 don't seem to align to the others; this makes me suspect that those stimulations were different somehow.\n",
    "Since their angles are all about 90°, I wonder if those stimuli failed somehow.\n",
    "\n",
    "Next, I wanted to check how these relationships vary as a function of time since the stimulus delivery, which led to the animation below.\n",
    "The animation creates comparison matrices very similar to the one above, but for varying timepoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, axs = plt.subplots(ncols=2, gridspec_kw={'width_ratios': [20, 1]}, figsize=(10,10))\n",
    "with al.plotting_functions.AnimationManager(fig=fig, make_axs=False, fps=10, filetype='gif') as am:\n",
    "    for step in range(responses.shape[1]):\n",
    "        axs[0].cla()\n",
    "        \n",
    "        comparison_matrix = compare_rows(responses[:,step,:d.n_neurons_in_optical])\n",
    "        plot_comparison(axs[0], comparison_matrix, vmin=60, vmax=120, ax_colorbar=axs[1], group_sizes=[g.shape[0] for g in responses_by_group])\n",
    "        axs[0].set_title(f\"{step = }\")\n",
    "        \n",
    "        am.grab_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "My biggest conclusion from the animation is that there is a temporal organization to the response angle convergence. \n",
    "Later stimuli seem to reach peak convergence before the earlier stimuli do; this is what the wave-like pattern in the animation shows.\n",
    "\n",
    "Another way to show this is to extract the dominant component of the neural activity at a time we know there is a response (timestep 14), and\n",
    "project all of the responses over time onto this neural component.\n",
    "Assuming the neurons active in the response are stable over time (which I checked), this projection shows the ramp in response for each trial. \n",
    "In the graph below, we can see later stimulations had faster responses, just like was suggested in the animations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_, vh = np.linalg.svd(non_nan_responses[:,14,:])\n",
    "svd_neural_component = vh[0]\n",
    "activation_of_neural_component = (non_nan_responses @ svd_neural_component).T\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(10,5))\n",
    "axs[0].bar(np.arange(svd_neural_component.size), svd_neural_component)\n",
    "scatter_sizes = svd_neural_component.copy()\n",
    "scatter_sizes[scatter_sizes < .001] = np.nan\n",
    "scatter_sizes = scatter_sizes * 40\n",
    "plot_per_neuron(axs[1], scatter_sizes, d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.matshow(activation_of_neural_component)\n",
    "ax.set_xlabel(\"stimulation\")\n",
    "ax.set_ylabel(\"timepoint\")\n",
    "ax.set_title(\"Projection of neural activity onto timestep 14's dominant activity pattern\")\n",
    "\n",
    "group_sizes = [g.shape[0] for g in responses_by_group]\n",
    "group_edges = np.cumsum(group_sizes)-.5\n",
    "for boundary in group_edges:\n",
    "    ax.axvline(boundary, color='w', lw=.5)\n",
    "ax.set_xticks([e - s/2 for s,e in zip(group_sizes, group_edges)], [chr(65+i) for i in range(len(group_edges))]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "peri_stim_recordings = []\n",
    "d.opto_stimulations.sort_values(by='time')\n",
    "borders = list(d.opto_stimulations['sample']) + [d.neural_data.shape[0]]\n",
    "for i in range(len(borders)-1):\n",
    "    peri_stim_recordings.append(d.neural_data[borders[i]:borders[i+1],:d.n_neurons_in_optical])\n",
    "\n",
    "temp = np.zeros([len(peri_stim_recordings)] + list(np.max([s.shape for s in peri_stim_recordings], axis=0))) * np.nan\n",
    "for i, psr in enumerate(peri_stim_recordings):\n",
    "    temp[i, :psr.shape[0], :psr.shape[1]] = psr - psr[0]\n",
    "peri_stim_recordings = temp\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.matshow((peri_stim_recordings @ svd_neural_component).T)\n",
    "for boundary in np.cumsum([g.shape[0] for g in responses_by_group])-.5:\n",
    "    ax.axvline(boundary, color='w', lw=.5)\n",
    "\n",
    "group_sizes = [g.shape[0] for g in responses_by_group]\n",
    "group_edges = np.cumsum(group_sizes)-.5\n",
    "for boundary in group_edges:\n",
    "    ax.axvline(boundary, color='w', lw=.5)\n",
    "ax.set_xticks([e - s/2 for s,e in zip(group_sizes, group_edges)], [chr(65+i) for i in range(len(group_edges))]);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Tensor decomposition\n",
    "I suspected that what I did in the figure above, where I projected a 3d array onto 1 neural activity pattern, giving an array, \n",
    "was trying to reinvent tensor decompositions.\n",
    "Therefore, I used the ideas and code from [Williams et al. 2018](https://doi.org/10.1016/j.neuron.2018.05.015) to do a proper\n",
    "tensor decomposition, with the 3 modes being neurons, trials, and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_decompositions(non_nan_responses, n_restarts=200):\n",
    "    models = []\n",
    "    for _ in range(n_restarts):\n",
    "        try:\n",
    "            m = tt.cpwarp.fit_shifted_cp(\n",
    "                non_nan_responses.transpose(2,0,1), \n",
    "                1,\n",
    "                max_iter=1000,\n",
    "                boundary=\"edge\",\n",
    "                max_shift_axis0=None,\n",
    "                max_shift_axis1=.3,\n",
    "                u_nonneg=True, # neurons\n",
    "                v_nonneg=True, # trials\n",
    "            )\n",
    "            models.append(m)\n",
    "        except ZeroDivisionError:\n",
    "            pass\n",
    "\n",
    "    models.sort(key=lambda m: m.loss_hist[-1])\n",
    "    return models\n",
    "\n",
    "models = find_decompositions(non_nan_responses, n_restarts=200)\n",
    "model = models[0]\n",
    "        \n",
    "print(f\"proportion of variance unexplained: {model.loss_hist[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "_, axs = plt.subplots(ncols=3, figsize=(10,5), layout='tight')\n",
    "result = model\n",
    "neural_component = np.squeeze(result.factors[0])\n",
    "axs[0].bar(x=np.arange(neural_component.size), height=neural_component)\n",
    "axs[0].set_title(\"neural loadings (U)\")\n",
    "axs[0].set_xlabel(\"neuron #\")\n",
    "\n",
    "per_stim_component = result.factors[1].T\n",
    "all_group_loadings = []\n",
    "total = 0\n",
    "for group_loadings in reshape_by_group(per_stim_component, d):\n",
    "    axs[1].plot(np.arange(total, total+len(group_loadings)), group_loadings, '.-')\n",
    "    total = total + len(group_loadings)\n",
    "    all_group_loadings.append(group_loadings)\n",
    "axs[1].set_title(\"trial loadings (V)\")\n",
    "axs[1].set_xlabel(\"trial #\")\n",
    "\n",
    "temporal_component = result.factors[2].T\n",
    "axs[2].plot(temporal_component)\n",
    "axs[2].set_title(\"temporal component\")\n",
    "axs[2].set_xlabel(\"time (steps)\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inferred_responses = model.predict().transpose([1,0,2])\n",
    "background = rng.normal(size=inferred_responses.shape) * .01\n",
    "inferred_responses = inferred_responses + background\n",
    "\n",
    "timepoint = 13\n",
    "fig, axs = plt.subplots(ncols=2, gridspec_kw={'width_ratios': [20, 1]}, figsize=(7,7))\n",
    "comparison_matrix = compare_rows(inferred_responses[:,timepoint,:], method='angles')\n",
    "plot_comparison(axs[0], comparison_matrix, group_sizes=[g.shape[0] for g in responses_by_group], ax_colorbar=axs[1])\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "The result of this decomposition isn't particularly inspiring in the neural or trial loadings (although the neuron loadings \n",
    "match well with the SVD from above). The interesting part is that all of the datasets admit a decomposition which appears to replicate the \n",
    "dynamics of the reporter.\n",
    "It has a near-zero response for the first ~7 timepoints, quickly rises to a peak, and then decays.\n",
    "\n",
    "If these dynamics match anything we can externally verify, I think cross-referencing the dynamics with a ground-truth would give a lot of credibility to the validity of the rest of the decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "\n",
    "Below is a debugging cell for the decomposition; the problem is non-convex, and there are often multiple solution basins.\n",
    "This code lets you look at the clusters of solutions in case the lowest-loss basin isn't the one you want.\n",
    "I used it for hyperparameter tuning in the code above.\n",
    "The third dataset didn't need tuning, it always gave satisfactory decompositions, but the first one was more difficult.\n",
    "However, I've found values that work for all 3 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "t_traces = np.vstack([m.factors[2] for m in models])\n",
    "t_traces = t_traces / np.linalg.norm(t_traces, axis=1)[:,None]\n",
    "\n",
    "\n",
    "c = SpectralClustering(n_clusters=3, affinity='precomputed')\n",
    "predictions = c.fit_predict(t_traces @ t_traces.T)\n",
    "clusters, counts = np.unique(predictions, return_counts=True)\n",
    "for cluster, count in zip(clusters, counts):\n",
    "    predictions[predictions==cluster] = count\n",
    "\n",
    "p = np.argsort(predictions)[::-1]\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(10,5))\n",
    "axs[0].matshow(t_traces[p] @ t_traces[p].T)\n",
    "comp_mat_examples = np.convolve(np.cumsum([0] + sorted(counts)[::-1]), [.5,.5], 'valid').astype(int)\n",
    "axs[0].set_xticks(comp_mat_examples)\n",
    "example_trials = p[comp_mat_examples]\n",
    "axs[1].plot(t_traces[example_trials].T);\n",
    "\n",
    "axs[1].set_title(\"extracted temporal profile\")\n",
    "axs[0].set_title(\"temporal profile covariance (clusters)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, sharey=True, layout='tight', figsize=(10,5))\n",
    "\n",
    "for sub_dataset_index in [0, 0, 2, 1]:\n",
    "    d = al.datasets.Naumann24uDataset(sub_dataset_index=sub_dataset_index)\n",
    "    responses = make_responses(d)\n",
    "    non_nan_responses = responses[...,:d.n_neurons_in_optical]\n",
    "    models = decompositions = find_decompositions(non_nan_responses, n_restarts=200)\n",
    "    model = models[0]\n",
    "    temporal_component = np.squeeze(models[0].factors[2].T)\n",
    "\n",
    "    t = np.arange(len(temporal_component))\n",
    "    axs[0].plot(t, temporal_component / temporal_component.max(), label=d.sub_dataset)\n",
    "    \n",
    "    t = t - np.argmax(temporal_component)\n",
    "    axs[1].plot(t, temporal_component / temporal_component.max(), label=d.sub_dataset)\n",
    "    \n",
    "\n",
    "axs[0].set_title(\"Cross-dataset temporal component comparison (unaligned)\")\n",
    "axs[0].set_xlabel(\"time (samples)\")\n",
    "axs[0].set_ylabel(\"temporal response magnitude (normalized)\")\n",
    "axs[1].set_title(\"(aligned)\")\n",
    "axs[1].set_xlabel(\"time from peak (samples)\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Above, I compare the temporal component discovered for all of the datasets; they have similar dynamics.\n",
    "Note that although I do one of the datasets twice, the result isn't consistent; this decomposition is stochastic.\n",
    "This makes the delays it discovers also stochastic, so phase misalignment between the temporal components between runs could be a problem.\n",
    "(As an aside, the library uses paralellization in a way that makes it difficult to control the randomness with a seed; this is bad for replicability.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## Dataset 1 delay recovery\n",
    "In dataset 1, the delays discovered per trial replicate the peaks of the activation of the trial 14 dominant neural component unusually well.\n",
    "This doesn't work as well in the other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_, vh = np.linalg.svd(non_nan_responses[:,14,:])\n",
    "svd_neural_component = vh[0]\n",
    "activation_of_neural_component = (non_nan_responses @ svd_neural_component).T\n",
    "\n",
    "per_trial_shifts = model.v_s.T\n",
    "pc1_argmaxes = np.argmax(activation_of_neural_component,axis=0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot((pc1_argmaxes - pc1_argmaxes.mean()))\n",
    "ax.plot(per_trial_shifts - per_trial_shifts.mean());\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
