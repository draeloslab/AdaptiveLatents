{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: this was originally copied from the Bubblewrap repo here:\n",
    "https://github.com/pearsonlab/Bubblewrap/blob/9639b97e0f77a2793031a932ff2bdf44ef70c912/models/VJF.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install VJF (for more information, visit https://github.com/catniplab/vjf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /tmp/vjf/\n",
    "!git clone https://github.com/catniplab/vjf.git /tmp/vjf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git --git-dir=/tmp/vjf/.git --work-tree /tmp/vjf/ checkout 0eec61e91c29cf9a44b48c2a6694234b4404a2b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/tmp/vjf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import the packages / functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.special import logsumexp\n",
    "from tqdm.notebook import trange\n",
    "import copy\n",
    "import torch\n",
    "import vjf\n",
    "from vjf import online\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import the dataset\n",
    "### (run ONLY one of the 6 cells below, depending on the dataset you'd like to run with)\n",
    "- Van der Pol dataset\n",
    "- Lorenz attractor dataset\n",
    "- Monkey reach (jPCA) dataset\n",
    "- Wide-field calcium dataset\n",
    "- Mouse video dataset\n",
    "- Neuropixels dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run the cell below to load the simulated Van der Pol dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data loading below is the vdp with (1 trajectory, 2dim, 500 to 20500 time points, with noise sd=0.05)\n",
    "# Use any of the simulated vdp dataset. \n",
    "# You can generate the simulated data using datagen.py (more info in Readme)\n",
    "data = np.load('vdp_1trajectories_2dim_500to20500_noise0.2.npz')\n",
    "\n",
    "xs = data['x']  # state\n",
    "ys = data['y']  # observation\n",
    "us = data['u']  # control input\n",
    "xdim = xs.shape[-1]\n",
    "ydim = ys.shape[-1]\n",
    "udim = us.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run the cell below to load the simulated Lorenz attractor dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data loading below is the lorenz attractor with (1 trajectory, 3dim, 500 to 20500 time points, with noise sd=0.05)\n",
    "# Use any of the simulated lorenz dataset. \n",
    "# You can generate the simulated data using datagen.py (See README.md for more info)\n",
    "data = np.load('lorenz_1trajectories_3dim_500to20500_noise0.2.npz')\n",
    "\n",
    "xs = data['x']  # state\n",
    "ys = data['y']  # observation\n",
    "us = data['u']  # control input\n",
    "xdim = xs.shape[-1]\n",
    "ydim = ys.shape[-1]\n",
    "udim = us.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run the cell below to load the reduced Monkey reach (jPCA) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reduced Monkey reach dataset (See README.md for how the reduced dataset was generated.)\n",
    "data = np.load('jpca_reduced.npy')\n",
    "\n",
    "xs = None  # state\n",
    "ys = data.T  # observation\n",
    "ys = ys[None, ...]\n",
    "us = np.zeros((ys.shape[0], ys.shape[1], 1))  # control input\n",
    "xdim = 6\n",
    "ydim = ys.shape[-1]\n",
    "udim = us.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run the cell below to load the reduced Wide-field calcium imaging dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reduced Wide-field calcium dataset (See README.md for how the reduced dataset was generated.)\n",
    "data = np.load('widefield_reduced.npy')\n",
    "\n",
    "xs = None\n",
    "ys = data.T[None, ...]\n",
    "us = np.zeros((ys.shape[0], ys.shape[1], 1))\n",
    "xdim = ys.shape[-1]\n",
    "ydim = ys.shape[-1]\n",
    "udim = us.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run the cell below for the reduced Mouse video dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reduced Mouse video dataset (See README.md for how the reduced dataset was generated.)\n",
    "data = np.load('reduced_mouse.npy')\n",
    "\n",
    "xs = None\n",
    "ys = data.T[None, ...]\n",
    "us = np.zeros((ys.shape[0], ys.shape[1], 1))\n",
    "xdim = ys.shape[-1]\n",
    "ydim = ys.shape[-1]\n",
    "udim = us.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run the cell below for the example Neuropixels dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reduced Neuropixels dataset with the desired latent dimensions\n",
    "# (See README.md for how the reduced dataset was generated.)\n",
    "data = np.load('neuropixel_reduced.npz')['ssSVD10'] # you can change this to 'ssSVD20'\n",
    "\n",
    "xs = None\n",
    "ys = data.T[None, ...]\n",
    "us = np.zeros((ys.shape[0], ys.shape[1], 1))\n",
    "xdim = ys.shape[-1]\n",
    "ydim = ys.shape[-1]\n",
    "udim = us.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Check your data dimension\n",
    "It should be\n",
    "`number of trials x number of time points x number of latent dimensions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random Seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "    if seed is None:\n",
    "        seed = np.random.choice(2 ** 32)\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    if seed_torch:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    print(f'Random seed {seed} has been set.')\n",
    "\n",
    "SEED = 44\n",
    "set_seed(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training the model and calculating the log probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = 'gaussian'  # Gaussian observation\n",
    "dynamics = 'rbf'  # RBF network dynamic model\n",
    "recognizer = \"mlp\"  # MLP recognitiom model\n",
    "rdim = 50  # number of RBFs\n",
    "hdim = 100  # number of MLP hidden units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagonal_normal_logpdf(mean, variance, sample):\n",
    "    mean = mean.flatten()\n",
    "    variance = variance.flatten()\n",
    "    sample = sample.flatten()\n",
    "    \n",
    "    assert len(mean) == len(variance) == len(sample), f\"inconsistent shape: {mean.shape}, {variance.shape}, {sample.shape}\"\n",
    "    \n",
    "    logprobs = []\n",
    "    for i in range(len(sample)):\n",
    "        x = sample[i]\n",
    "        m = mean[i]\n",
    "        v = variance[i]\n",
    "        logprobs.append(-0.5 * ((x - m) ** 2 / v + np.log(2 * np.pi * v)))\n",
    "    return sum(logprobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = torch.from_numpy(ys).float().to(device)\n",
    "uu = torch.from_numpy(us).float().to(device)\n",
    "\n",
    "q = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 1000  # number of trajectories\n",
    "T = 10   # length of each trajectory\n",
    "P = 10    # calculate T-step-ahead predictive distribution every P steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprobs = []\n",
    "logprob_trajectories = []\n",
    "distances = []\n",
    "trial = 0\n",
    "\n",
    "\n",
    "for trial in trange(yy.shape[0]):\n",
    "    batch_size = 1\n",
    "    filtering_mu = torch.zeros(batch_size, xdim, device=device)\n",
    "    filtering_logvar = torch.zeros(batch_size, xdim, device=device)\n",
    "    q = filtering_mu, filtering_logvar\n",
    "    logprob_per_trial = []\n",
    "    logprob_trajectories_per_trial = []\n",
    "    \n",
    "    mdl = online.VJF(\n",
    "        config=dict(\n",
    "            resume=False,\n",
    "            xdim=xdim,\n",
    "            ydim=ydim,\n",
    "            udim=udim,\n",
    "            Ydim=udim,\n",
    "            Udim=udim,\n",
    "            rdim=rdim,\n",
    "            hdim=hdim,\n",
    "            lr=1e-3,\n",
    "            clip_gradients=5.0,\n",
    "            debug=True,\n",
    "            likelihood=likelihood,  # \n",
    "            system=dynamics,\n",
    "            recognizer=recognizer,\n",
    "            C=(None, True),  # loading matrix: (initial, estimate)\n",
    "            b=(None, True),  # bias: (initial, estimate)\n",
    "            A=(None, False),  # transition matrix if LDS\n",
    "            B=(np.zeros((xdim, udim)), False),  # interaction matrix\n",
    "            Q=(1.0, True),  # state noise\n",
    "            R=(1.0, True),  # observation noise\n",
    "        )\n",
    "    ).to(device)\n",
    "    \n",
    "    for time in trange(yy.shape[1]):\n",
    "\n",
    "        y = yy[trial, time].unsqueeze(0)\n",
    "        u = uu[trial, time].unsqueeze(0)\n",
    "        \n",
    "        filtering_mu, filtering_logvar = q\n",
    "\n",
    "        mu_f = filtering_mu[0].detach().cpu().numpy().T\n",
    "        var_f = filtering_logvar[0].detach().exp().cpu().numpy().T\n",
    "        Sigma_f = np.eye(xdim) * var_f\n",
    "\n",
    "        x = multivariate_normal(mu_f.flatten(), Sigma_f).rvs(size=S).astype(np.float32)\n",
    "        x = torch.from_numpy(x).to(device)\n",
    "        x += mdl.system.velocity(x) + mdl.system.noise.var ** 0.5 * torch.randn_like(x)\n",
    "        y_tilde = mdl.decoder(x).detach().cpu().numpy()\n",
    "\n",
    "        y_var = mdl.likelihood.logvar.detach().exp().cpu().numpy().T\n",
    "        sample_logprobs = [diagonal_normal_logpdf(y_, y_var, y.cpu().numpy()) for y_ in y_tilde]\n",
    "        logprob = logsumexp(sample_logprobs) - np.log(S)\n",
    "\n",
    "        logprob_per_trial.append(logprob)\n",
    "        distances.append(np.linalg.norm(y_tilde - y[0].cpu().numpy(), axis=-1).mean())\n",
    "        \n",
    "        \n",
    "        if time % P == 0 and time + T < yy.shape[1]:\n",
    "            # rolling-predict T-1 more steps\n",
    "            with torch.no_grad():\n",
    "                trajectory_logprobs = [logprob]\n",
    "                mdl_copy = copy.deepcopy(mdl)  # just to make sure we're not touching the original model\n",
    "\n",
    "                for tprime in range(time + 1, time + T):\n",
    "                    y_tprime = yy[trial, tprime].unsqueeze(0)\n",
    "                    u_tprime = uu[trial, tprime].unsqueeze(0)\n",
    "\n",
    "                    x += mdl_copy.system.velocity(x) + mdl_copy.system.noise.var ** 0.5 * torch.randn_like(x)\n",
    "                    y_tilde = mdl_copy.decoder(x).detach().cpu().numpy()\n",
    "                    # y_var didn't change\n",
    "\n",
    "                    sample_logprobs = [diagonal_normal_logpdf(y_, y_var, y_tprime.cpu().numpy()) for y_ in y_tilde]\n",
    "\n",
    "                    logprob = logsumexp(sample_logprobs) - np.log(S)\n",
    "                    trajectory_logprobs.append(logprob)\n",
    "\n",
    "                logprob_trajectories_per_trial.append(trajectory_logprobs)\n",
    "\n",
    "        q, loss = mdl.feed((y, u), q)\n",
    "\n",
    "    logprobs.append(logprob_per_trial)\n",
    "    logprob_trajectories.append(logprob_trajectories_per_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save the log probabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('logprob_vjf_widefield_seed44.npy', np.array(logprob_trajectories[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_logprobs = np.load('logprob_vjf_widefield_seed44.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Plotting the log probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def ewma(data, com):\n",
    "    return np.array(pd.DataFrame(data=dict(data=data)).ewm(com).mean()['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "for i in range(trajectory_logprobs.shape[-1]):\n",
    "    curve = ewma(trajectory_logprobs[:, i], 100)\n",
    "    plt.plot(np.arange(len(curve)) * P, curve, label=f\"{i+1} step{'s' if i > 0 else ''} ahead\")\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(1.01, 0.95))\n",
    "plt.ylabel(\"log probability\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylim([-300, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Compute the mean and std of the last half of the time points (For Table1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = trajectory_logprobs.shape[0]\n",
    "trajectory_logprobs[nn//2:, 0].mean(), trajectory_logprobs[nn//2:, 0].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Compute the mean and std of the last half of the time points (for the new figure)\n",
    "### (1 step prediction to 10 step predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = trajectory_logprobs.shape[0]\n",
    "for i in range(10):\n",
    "    print(f\"{i+1} step:\", trajectory_logprobs[nn//2:, i].mean(), trajectory_logprobs[nn//2:, i].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.zeros((6, 3))\n",
    "i = 0\n",
    "for t in range(500):\n",
    "    if t in [0, 1, 2, 3, 4, 9]:\n",
    "        prediction[i] = int(t+1), trajectory_logprobs[nn//2:, t].mean(), trajectory_logprobs[nn//2:, t].std()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('tensteps_vjf_widefield_seed44.npy', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
