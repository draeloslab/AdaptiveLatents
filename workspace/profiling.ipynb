{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T16:11:17.094613Z",
     "start_time": "2024-11-12T16:11:15.420954Z"
    }
   },
   "outputs": [],
   "source": [
    "import adaptive_latents as al\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from prediction_regression_run import pred_reg_run_with_defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T16:20:40.988983Z",
     "start_time": "2024-11-12T16:11:30.590772Z"
    }
   },
   "outputs": [],
   "source": [
    "run_without_logging = pred_reg_run_with_defaults('odoherty21', log_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T16:38:40.886081Z",
     "start_time": "2024-11-12T16:26:20.850032Z"
    }
   },
   "outputs": [],
   "source": [
    "run_with_logging = pred_reg_run_with_defaults('odoherty21', log_level=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:42:19.319317Z",
     "start_time": "2024-11-12T17:42:18.815310Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "\n",
    "stream_label_mapping = {\n",
    "    0: 'neural sample',\n",
    "    1: 'behavior sample',\n",
    "    2: 'target data sample',\n",
    "    3: 'prediction',\n",
    "    # -1: 'thrown out sample',\n",
    "}\n",
    "\n",
    "\n",
    "def time_scatter(ax, transformer, run, semilogy=True):\n",
    "    a = al.timed_data_source.ArrayWithTime.from_list(transformer.log['step_time'])*1000\n",
    "    stream = np.array(transformer.log['stream'])\n",
    "    for s in stream_label_mapping:\n",
    "        sub_a = a[stream == s]\n",
    "        sub_a.t = sub_a.t[stream==s]\n",
    "        ax.plot(sub_a.t, sub_a, '.', label=stream_label_mapping[s], alpha=1 if s == -1 else 1)\n",
    "\n",
    "    q = np.quantile(a,.999)\n",
    "    # ax.axhline(q, color='k')\n",
    "    # ax.text(0, q*1.2, f'{q:.1f} ms')\n",
    "    sampling_dt = run.sources[0][0].dt * 1000\n",
    "    ax.axhline(sampling_dt, color='k', lw=1.5, ls='-')\n",
    "    ax.set_xlabel('experiment time (s)')\n",
    "    ax.set_ylabel('end-to-end iteration time (ms)')\n",
    "    ax.set_title(f'step times for a \"{type(transformer).__name__}\" step on the {run.dataset} dataset')\n",
    "    ax.legend()\n",
    "    if semilogy:\n",
    "        ax.semilogy()\n",
    "        ax.text(0, sampling_dt*1.2, f'{sampling_dt:.1f} ms (sampling rate)')\n",
    "    else:\n",
    "        ax.set_ylim([0, sampling_dt*2])\n",
    "        ax.text(0, sampling_dt + .2, f'{sampling_dt:.1f} ms (sampling rate)')\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "time_scatter(axs[0], run_without_logging.pipeline, run_without_logging, semilogy=False)\n",
    "time_scatter(axs[1], run_with_logging.pipeline, run_with_logging, semilogy=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:48:25.337330Z",
     "start_time": "2024-11-12T17:48:24.709102Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def row_hist_per_stream(transformer, run):\n",
    "    fig, axs = plt.subplots(nrows=len(stream_label_mapping), squeeze=False, sharex=True)\n",
    "    \n",
    "    \n",
    "    a = al.timed_data_source.ArrayWithTime.from_list(transformer.log['step_time'])*1000\n",
    "    stream = np.array(transformer.log['stream'])\n",
    "    sampling_dt = run.sources[0][0].dt * 1000\n",
    "\n",
    "\n",
    "    for idx, s in enumerate(stream_label_mapping):\n",
    "        sub_a = a[stream == s]\n",
    "        sub_a.t = sub_a.t[stream==s]\n",
    "        if sub_a.size:\n",
    "            l,r = np.quantile(sub_a,.005), np.quantile(sub_a,.995)\n",
    "            axs[idx,0].hist(sub_a, bins=np.linspace(l,r,101), color=f'C{idx}')\n",
    "            axs[idx,0].semilogy()\n",
    "\n",
    "        axs[idx,0].axvline(sampling_dt, color='k', lw=1.5, ls='-')\n",
    "        axs[idx,0].set_xlim([0, sampling_dt*2])\n",
    "\n",
    "    # ax.text(0, q*1.2, f'{q:.1f} ms')\n",
    "    # ax.text(0, sampling_dt*1.2, f'{sampling_dt:.1f} ms (sampling rate)')\n",
    "    axs[0,0].set_title('processing step length by stream')\n",
    "    axs[-1,0].set_xlabel('step time (ms)')\n",
    "    \n",
    "run = run_without_logging\n",
    "row_hist_per_stream(run.pipeline, run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:50:34.015961Z",
     "start_time": "2024-11-12T17:50:32.444531Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def row_hist_per_step(pipeline, run, s):\n",
    "    fig, axs = plt.subplots(nrows=len(pipeline.steps), squeeze=False, sharex=True, figsize=(4,10))\n",
    "    sampling_dt = run.sources[0][0].dt * 1000\n",
    "\n",
    "    for idx, transformer in enumerate(pipeline.steps):\n",
    "            a = al.timed_data_source.ArrayWithTime.from_list(transformer.log['step_time'])*1000\n",
    "            stream = np.array(transformer.log['stream'])\n",
    "            sub_a = a[stream == s]\n",
    "            sub_a.t = sub_a.t[stream==s]\n",
    "            if sub_a.size:\n",
    "                l,r = np.quantile(sub_a,.0005), np.quantile(sub_a,.9995)\n",
    "                axs[idx,0].hist(sub_a, bins=np.linspace(l,r,101), color=f'C{idx}')\n",
    "                axs[idx,0].semilogy()\n",
    "                # axs[idx,0].axvline(sampling_dt, color='k', lw=1.5, ls='-', alpha=.1)\n",
    "                axs[idx,0].text(.98,.65, type(transformer).__name__, horizontalalignment='right', transform=axs[idx,0].transAxes)\n",
    "\n",
    "\n",
    "    axs[0,0].set_title('processing time by step for predictions')\n",
    "    axs[-1,0].set_xlabel('step time (ms)')\n",
    "\n",
    "row_hist_per_step(run.pipeline, run, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T17:51:12.132574Z",
     "start_time": "2024-11-12T17:51:12.121418Z"
    }
   },
   "outputs": [],
   "source": [
    "run.pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T20:02:56.310892Z",
     "start_time": "2024-11-12T20:02:56.282408Z"
    }
   },
   "outputs": [],
   "source": [
    "from adaptive_latents import Pipeline, CenteringTransformer, VanillaOnlineRegressor\n",
    "\n",
    "x = np.arange(1)[:,None] + 1\n",
    "y = x + 1\n",
    "\n",
    "\n",
    "centerer = CenteringTransformer()\n",
    "reg = VanillaOnlineRegressor()\n",
    "\n",
    "for x_i, y_i in zip(x,y):\n",
    "    data, stream = x_i, 0\n",
    "    data, stream = centerer.partial_fit_transform(data, stream=stream, return_output_stream=True)\n",
    "    data, stream = reg.partial_fit_transform(data, stream=stream, return_output_stream=True)\n",
    "\n",
    "    data, stream = y_i, 1\n",
    "    data, stream = centerer.partial_fit_transform(data, stream=stream, return_output_stream=True)\n",
    "    data, stream = reg.partial_fit_transform(data, stream=stream, return_output_stream=True)\n",
    "\n",
    "p = Pipeline([\n",
    "    CenteringTransformer(),\n",
    "    VanillaOnlineRegressor()\n",
    "])\n",
    "\n",
    "for x_i, y_i in zip(x,y):\n",
    "    data, stream = x_i, 0\n",
    "    data, stream = p.partial_fit_transform(data, stream=stream, return_output_stream=True)\n",
    "    \n",
    "    data, stream = y_i, 1\n",
    "    data, stream = p.partial_fit_transform(data, stream=stream, return_output_stream=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: reg.pft(_,_,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T20:03:03.178531Z",
     "start_time": "2024-11-12T20:03:03.167552Z"
    }
   },
   "outputs": [],
   "source": [
    "print(p.steps[-1].c)\n",
    "print(reg.c)\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T19:38:26.457937Z",
     "start_time": "2024-11-12T19:38:26.438678Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from adaptive_latents import Pipeline, CenteringTransformer, VanillaOnlineRegressor\n",
    "\n",
    "p = Pipeline([\n",
    "    CenteringTransformer(),\n",
    "    VanillaOnlineRegressor()\n",
    "])\n",
    "\n",
    "centerer = CenteringTransformer()\n",
    "reg = VanillaOnlineRegressor()\n",
    "\n",
    "x = np.array([[1]])\n",
    "y = np.array([[2]])\n",
    "\n",
    "output, stream = centerer.partial_fit_transform(x, stream=0, return_output_stream=True)\n",
    "output, stream = reg.partial_fit_transform(output, stream=stream, return_output_stream=True)\n",
    "\n",
    "output, stream = centerer.partial_fit_transform(y, stream=1, return_output_stream=True)\n",
    "output, stream = reg.partial_fit_transform(output, stream=stream, return_output_stream=True)\n",
    "\n",
    "p.partial_fit_transform(x, stream=0)\n",
    "p.partial_fit_transform(y, stream=1);\n",
    "\n",
    "# x = np.array([[1]])\n",
    "# y = np.array([[2]])\n",
    "# \n",
    "# output, stream = centerer.partial_fit_transform(x, stream=0, return_output_stream=True)\n",
    "# output, stream = reg.partial_fit_transform(output, stream=stream, return_output_stream=True)\n",
    "# \n",
    "# output, stream = centerer.partial_fit_transform(y, stream=1, return_output_stream=True)\n",
    "# output, stream = reg.partial_fit_transform(output, stream=stream, return_output_stream=True)\n",
    "# \n",
    "# p.partial_fit_transform(x, stream=0)\n",
    "# p.partial_fit_transform(y, stream=1);\n",
    "# \n",
    "# x = np.array([[3]])\n",
    "# y = np.array([[4]])\n",
    "# \n",
    "# output, stream = centerer.partial_fit_transform(x, stream=0, return_output_stream=True)\n",
    "# output, stream = reg.partial_fit_transform(output, stream=stream, return_output_stream=True)\n",
    "# \n",
    "# output, stream = centerer.partial_fit_transform(y, stream=1, return_output_stream=True)\n",
    "# output, stream = reg.partial_fit_transform(output, stream=stream, return_output_stream=True)\n",
    "# \n",
    "# p.partial_fit_transform(x, stream=0)\n",
    "# p.partial_fit_transform(y, stream=1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T18:34:32.137420Z",
     "start_time": "2024-11-12T18:34:32.123390Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "\n",
    "regressor = sklearn.linear_model.LinearRegression()\n",
    "regressor.fit(x,y)\n",
    "\n",
    "import sklearn.pipeline\n",
    "pipeline = sklearn.pipeline.Pipeline([('reg1', regressor)])\n",
    "pipeline.predict(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
