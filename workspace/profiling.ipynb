{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T18:57:26.366937Z",
     "start_time": "2024-11-13T18:57:24.556129Z"
    }
   },
   "outputs": [],
   "source": [
    "import adaptive_latents as al\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from prediction_regression_run import pred_reg_run_with_defaults\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T18:57:26.897272Z",
     "start_time": "2024-11-13T18:57:26.367756Z"
    }
   },
   "outputs": [],
   "source": [
    "run_without_logging = pred_reg_run_with_defaults('leventhal24u', log_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_with_logging = pred_reg_run_with_defaults('odoherty21', log_level=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T18:50:59.034132Z",
     "start_time": "2024-11-13T18:50:59.027572Z"
    }
   },
   "outputs": [],
   "source": [
    "runs_by_bubbles = dict()\n",
    "\n",
    "# runs_by_bubbles[800] = pred_reg_run_with_defaults('odoherty21', log_level=1, n_bubbles=800)\n",
    "# runs_by_bubbles[500] = pred_reg_run_with_defaults('odoherty21', log_level=1, n_bubbles=500)\n",
    "runs_by_bubbles[1100] = run_without_logging\n",
    "# runs_by_bubbles[1400] = pred_reg_run_with_defaults('odoherty21', log_level=1, n_bubbles=1400)\n",
    "# runs_by_bubbles[1700] = pred_reg_run_with_defaults('odoherty21', log_level=1, n_bubbles=1700)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "stream_label_mapping = {\n",
    "    0: 'neural sample',\n",
    "    1: 'behavior sample',\n",
    "    2: 'target data sample',\n",
    "    3: 'prediction',\n",
    "    # -1: 'thrown out sample',\n",
    "}\n",
    "\n",
    "\n",
    "def time_scatter(ax, transformer, run, semilogy=True):\n",
    "    a = al.timed_data_source.ArrayWithTime.from_list(transformer.log['step_time'])*1000\n",
    "    stream = np.array(transformer.log['stream'])\n",
    "    for s in stream_label_mapping:\n",
    "        sub_a = a[stream == s]\n",
    "        sub_a.t = sub_a.t[stream==s]\n",
    "        ax.plot(sub_a.t, sub_a, '.', label=stream_label_mapping[s], alpha=1 if s == -1 else 1)\n",
    "\n",
    "    q = np.quantile(a,.999)\n",
    "    # ax.axhline(q, color='k')\n",
    "    # ax.text(0, q*1.2, f'{q:.1f} ms')\n",
    "    sampling_dt = run.sources[0][0].dt * 1000\n",
    "    ax.axhline(sampling_dt, color='k', lw=1.5, ls='-')\n",
    "    ax.set_xlabel('experiment time (s)')\n",
    "    ax.set_ylabel('end-to-end iteration time (ms)')\n",
    "    ax.set_title(f'step times for a \"{type(transformer).__name__}\" step on the {run.dataset} dataset')\n",
    "    ax.legend()\n",
    "    if semilogy:\n",
    "        ax.semilogy()\n",
    "        ax.text(0, sampling_dt*1.2, f'{sampling_dt:.1f} ms (sampling rate)')\n",
    "    else:\n",
    "        ax.set_ylim([0, sampling_dt*2])\n",
    "        ax.text(0, sampling_dt + .2, f'{sampling_dt:.1f} ms (sampling rate)')\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=[15, 5])\n",
    "time_scatter(axs[0], run_without_logging.pipeline, run_without_logging, semilogy=False)\n",
    "time_scatter(axs[1], run_with_logging.pipeline, run_with_logging, semilogy=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def row_hist_per_stream(transformer, run):\n",
    "    fig, axs = plt.subplots(nrows=len(stream_label_mapping), squeeze=False, sharex=True)\n",
    "    \n",
    "    \n",
    "    a = al.timed_data_source.ArrayWithTime.from_list(transformer.log['step_time'])*1000\n",
    "    stream = np.array(transformer.log['stream'])\n",
    "    sampling_dt = run.sources[0][0].dt * 1000\n",
    "\n",
    "\n",
    "    for idx, s in enumerate(stream_label_mapping):\n",
    "        sub_a = a[stream == s]\n",
    "        sub_a.t = sub_a.t[stream==s]\n",
    "        if sub_a.size:\n",
    "            l,r = np.quantile(sub_a,.005), np.quantile(sub_a,.995)\n",
    "            axs[idx,0].hist(sub_a, bins=np.linspace(l,r,101), color=f'C{idx}')\n",
    "            axs[idx,0].semilogy()\n",
    "\n",
    "        # axs[idx,0].axvline(sampling_dt, color='k', lw=1.5, ls='-')\n",
    "        # axs[idx,0].set_xlim([0, sampling_dt*2])\n",
    "\n",
    "    # ax.text(0, q*1.2, f'{q:.1f} ms')\n",
    "    # ax.text(0, sampling_dt*1.2, f'{sampling_dt:.1f} ms (sampling rate)')\n",
    "    axs[0,0].set_title('processing step length by stream')\n",
    "    axs[-1,0].set_xlabel('step time (ms)')\n",
    "    \n",
    "run = run_without_logging\n",
    "row_hist_per_stream(run.pipeline.steps[1], run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(run.pipeline.steps[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def row_hist_per_step(pipeline, run, s):\n",
    "    fig, axs = plt.subplots(nrows=len(pipeline.steps), squeeze=False, sharex=True, figsize=(4,10))\n",
    "    sampling_dt = run.sources[0][0].dt * 1000\n",
    "\n",
    "    for idx, transformer in enumerate(pipeline.steps):\n",
    "            a = al.timed_data_source.ArrayWithTime.from_list(transformer.log['step_time'])*1000\n",
    "            stream = np.array(transformer.log['stream'])\n",
    "            sub_a = a[stream == s]\n",
    "            sub_a.t = sub_a.t[stream==s]\n",
    "            if sub_a.size:\n",
    "                l,r = np.quantile(sub_a,.0005), np.quantile(sub_a,.9995)\n",
    "                axs[idx,0].hist(sub_a, bins=np.linspace(l,r,101), color=f'C{idx}')\n",
    "                axs[idx,0].semilogy()\n",
    "                # axs[idx,0].axvline(sampling_dt, color='k', lw=1.5, ls='-', alpha=.1)\n",
    "                axs[idx,0].text(.98,.65, type(transformer).__name__, horizontalalignment='right', transform=axs[idx,0].transAxes)\n",
    "\n",
    "\n",
    "    axs[0,0].set_title('processing time by step for predictions')\n",
    "    axs[-1,0].set_xlabel('step time (ms)')\n",
    "\n",
    "run = run_without_logging\n",
    "row_hist_per_step(run.pipeline, run, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_times = al.timed_data_source.ArrayWithTime.from_list(run_without_logging.pipeline.steps[-2].log['step_time'])\n",
    "reg_times = al.timed_data_source.ArrayWithTime.from_list(run_without_logging.pipeline.steps[-1].log['step_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig, ax = plt.subplots()\n",
    "streams = np.array(run_without_logging.pipeline.steps[-1].log['stream'])\n",
    "for stream in stream_label_mapping:\n",
    "    ax.scatter(bw_times[streams==stream], reg_times[streams==stream], s=3)\n",
    "# ax.semilogy()\n",
    "# ax.semilogx()\n",
    "plt.axis('equal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T18:51:04.261268Z",
     "start_time": "2024-11-13T18:51:04.017806Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "    \n",
    "\n",
    "bubbles = []\n",
    "times = []\n",
    "fig, ax = plt.subplots()\n",
    "for n_bubbles, run in runs_by_bubbles.items():\n",
    "    transformer = run.pipeline.steps[7]\n",
    "    step_times = np.array(transformer.log['step_time'])\n",
    "    streams = np.array(transformer.log['stream'])\n",
    "    subset_times = step_times[streams==0]\n",
    "    ax.scatter(n_bubbles + rng.normal(size=subset_times.shape)*2, subset_times * 1000, s=1, color='C0')\n",
    "    \n",
    "    \n",
    "ax.set_ylim([0, 125])\n",
    "ax.set_xlabel('number of bubbles')\n",
    "ax.set_ylabel('pipeline time per neural step (ms)')\n",
    "ax.set_title('Scaling of speed with number of bubbles')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Environment comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T18:58:26.753983Z",
     "start_time": "2024-11-20T18:58:25.061194Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import adaptive_latents as al\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:00:16.836205Z",
     "start_time": "2024-11-20T19:00:16.826872Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(al.CONFIG.bwrun_save_path / 'profile.pkl', 'rb') as fhan:\n",
    "    p_m = pickle.load(fhan)\n",
    "\n",
    "with open(al.CONFIG.bwrun_save_path / 'profile_vc.pkl', 'rb') as fhan:\n",
    "    p_s = pickle.load(fhan)\n",
    "\n",
    "with open(al.CONFIG.bwrun_save_path / 'profile_with_stuff.pkl', 'rb') as fhan:\n",
    "    p_l = pickle.load(fhan)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:00:20.743802Z",
     "start_time": "2024-11-20T19:00:20.730480Z"
    }
   },
   "outputs": [],
   "source": [
    "p_s.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T19:05:02.663688Z",
     "start_time": "2024-11-20T19:05:02.375049Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 'bubblewrap'\n",
    "\n",
    "plt.hist(p_s[k]*1000, np.linspace(0,60,101), label='in virtual console');\n",
    "plt.hist(p_m[k]*1000, np.linspace(0,60,101), label='command line, after reboot');\n",
    "plt.hist(p_l[k]*1000, np.linspace(0,60,101), label='jupyter notebook, with other things open');\n",
    "plt.legend()\n",
    "# plt.semilogx()\n",
    "# plt.semilogy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
