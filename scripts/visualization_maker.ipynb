{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import adaptive_latents as al\n",
    "from adaptive_latents import NumpyTimedDataSource, Bubblewrap, AnimationManager, default_rwd_parameters, SymmetricNoisyRegressor, BWRun\n",
    "import adaptive_latents.input_sources.functional as fin\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from proSVD import proSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = loadmat(al.CONFIG['data_path'] / 'Chestek' / 'first_extraction.mat', squeeze_me=True, simplify_cells=True)\n",
    "pre_smooth_beh = mat[\"feats\"][1]\n",
    "pre_smooth_A = mat[\"feats\"][0]\n",
    "pre_smooth_t = mat[\"feats\"][2] / 1000\n",
    "\n",
    "pre_smooth_beh = pre_smooth_beh.reshape((pre_smooth_beh.shape[0], 3, 5))\n",
    "\n",
    "nonzero_columns = pre_smooth_beh.std(axis=0) > 0\n",
    "assert np.all(~(nonzero_columns[0,:] ^ nonzero_columns)) # checks that fingers always have the same values\n",
    "pre_smooth_beh = pre_smooth_beh[:,:,nonzero_columns[0,:]] # the booleans select for position, velocity, and acceleration\n",
    "pre_smooth_beh = pre_smooth_beh[:, [True, False, False], :].reshape(pre_smooth_beh.shape[0], -1) # the three booleans select for position, velocity, and acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_A, pre_beh, pre_t, _ = al.input_sources.datasets.construct_nason20_dataset()\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2, layout=\"tight\")\n",
    "ax[0].plot(pre_smooth_t, pre_smooth_A[:,0])\n",
    "signal = pre_smooth_A[:,0]\n",
    "\n",
    "kernel = np.exp(np.linspace(0,-1,5))\n",
    "kernel /= kernel.sum()\n",
    "ax[1].plot(kernel)\n",
    "\n",
    "mode = 'valid'\n",
    "smoothed = np.convolve(kernel, signal, mode)\n",
    "smoothed_t = np.convolve(np.hstack([[1],kernel[:-1]*0]), pre_smooth_t, mode)\n",
    "ax[0].plot(smoothed_t,smoothed)\n",
    "\n",
    "\n",
    "ax[0].set_xlim([80, 100])\n",
    "ax[0].set_ylim([10, 30])\n",
    "ax[0].set_title(\"Original and smoothed data\")\n",
    "ax[1].set_title(\"Convolution kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'valid'\n",
    "pre_prosvd_A = np.column_stack([np.convolve(kernel, column, mode) for column in pre_smooth_A.T])\n",
    "pre_prosvd_t = np.convolve(np.hstack([[1],kernel[:-1]*0]), pre_smooth_t, mode)\n",
    "pre_prosvd_beh = pre_smooth_beh\n",
    "\n",
    "\n",
    "pre_prosvd_A = fin.center_from_first_n(pre_prosvd_A, 100)\n",
    "pre_prosvd_A, pre_prosvd_beh, pre_prosvd_t = fin.clip(pre_prosvd_A, pre_prosvd_beh, pre_prosvd_t)\n",
    "\n",
    "\n",
    "\n",
    "pre_jpca_A, Qs = fin.prosvd_data_with_Qs(pre_prosvd_A, 4, 50)\n",
    "pre_jpca_A, pre_jpca_t, pre_jpca_beh = fin.clip(pre_jpca_A, pre_prosvd_t, pre_prosvd_beh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, beh, t = pre_jpca_A, pre_jpca_beh, pre_jpca_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "##### to skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(pre_prosvd_A)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "var_explained = np.cumsum([0] + list(pca.explained_variance_ratio_))\n",
    "ax.plot(var_explained, '.-')\n",
    "ax.set_ylim([0,1])\n",
    "cutoff = np.nonzero(var_explained > .9)[0][0]\n",
    "ax.axvline(cutoff, color='k', alpha=.5)\n",
    "ax.axhline(.9, color='k', alpha=.25)\n",
    "ax.text(.65,.1, f'n_components $\\\\approx$ {cutoff}', transform=ax.transAxes)\n",
    "ax.set_ylabel(\"cumulative variance explained\")\n",
    "ax.set_xlabel(\"number of components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, layout=\"tight\")\n",
    "dQ = np.linalg.norm(np.diff(Qs, axis=0), axis=1)\n",
    "dt = np.diff(t)\n",
    "ax[0].plot(t[:-1], dQ/dt[:,None]);\n",
    "ax[0].set_ylabel(\"$\\\\frac{ \\\\Vert dQ_i \\\\Vert}{dt}$\");\n",
    "ax[0].set_title(\"Change in proSVD vectors over time\");\n",
    "ax[0].set_xlabel(\"time (s)\");\n",
    "\n",
    "ax[1].plot(t[:-1], np.log(dQ/dt[:,None]));\n",
    "ax[1].set_ylabel(\"$\\\\ln \\\\frac{ \\\\Vert dQ_i \\\\Vert}{dt}$\");\n",
    "ax[1].set_title(\"(log scale)\");\n",
    "ax[1].set_xlabel(\"time (s)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, axs = plt.subplots(nrows=3, ncols=3, sharey='row')\n",
    "\n",
    "slice_half_width = 20\n",
    "time_slices = [slice(0,slice_half_width*2), \n",
    "               slice(len(t)//2-slice_half_width, len(t)//2+slice_half_width) , \n",
    "               slice(-slice_half_width*2, -1)]\n",
    "for i in range(3):\n",
    "    s = time_slices[i]\n",
    "    axs[0,i].plot(t[s],beh[s])\n",
    "    axs[0,i].set_xlim([min(t[s]), max(t[s])])\n",
    "    axs[1,i].imshow(A[s,:].T, aspect='auto', interpolation='none')\n",
    "    axs[1,i].set_xticks([])\n",
    "    axs[2,i].plot(t[s],A[s,:], color='k', alpha=.25)\n",
    "    axs[2,i].set_xlim([min(t[s]), max(t[s])])\n",
    "\n",
    "axs[0,0].set_title(f\"first {slice_half_width*2} points\")\n",
    "axs[0,1].set_title(f\"middle {slice_half_width*2} points\")\n",
    "axs[0,2].set_title(f\"last {slice_half_width*2} points\")\n",
    "\n",
    "axs[0,0].set_ylabel(\"Behavior\")\n",
    "axs[1,0].set_ylabel(\"Neural Latents\")\n",
    "axs[2,0].set_ylabel(\"Neural Latents\")\n",
    "axs[2,1].set_xlabel(\"time (s)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "##### bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ds = NumpyTimedDataSource(A, t, time_offsets=(0,1))\n",
    "out_ds = NumpyTimedDataSource(beh, t, time_offsets=(0,1))\n",
    "\n",
    "# define the adaptive_latents object\n",
    "bw = Bubblewrap(dim=in_ds.output_shape,  **dict(default_rwd_parameters, M=300, num=1000, num_grad_q=1))\n",
    "\n",
    "# define the (optional) method to regress the HMM state from `bw.alpha`\n",
    "# reg = SymmetricNoisyRegressor(input_d=bw.N, output_d=1)\n",
    "reg = SymmetricNoisyRegressor(input_d=bw.N, output_d=out_ds.output_shape)\n",
    "\n",
    "class CustomAnimation(AnimationManager):\n",
    "    n_rows = 1\n",
    "    n_cols = 3\n",
    "    figsize = (15,10)\n",
    "    extension = \"mp4\"\n",
    "    fps=10\n",
    "\n",
    "    def custom_draw_frame(self, step, bw: Bubblewrap, br: BWRun):\n",
    "        historical_observations, _ = br.obs_ds.get_history()\n",
    "\n",
    "        al.plotting_functions.show_active_bubbles_2d(self.ax[0,1], historical_observations, bw, n_sds=3, history_length=10)\n",
    "        self.ax[0,1].set_title(f\"Step {step}\")\n",
    "        al.plotting_functions.show_alpha(self.ax[0,0], br)\n",
    "        al.plotting_functions.show_behavior(self.ax[0,2], br)\n",
    "        \n",
    "    def frame_draw_condition(self, step_number, bw):\n",
    "        condition = True\n",
    "        condition = condition and (step_number % 1 == 0)\n",
    "        condition = condition and (2900 < step_number < 3100)\n",
    "        return condition\n",
    "        \n",
    "# am = CustomAnimation()\n",
    "am = None\n",
    "\n",
    "br = BWRun(bw=bw, obs_ds=in_ds, beh_ds=out_ds, behavior_regressor=reg, animation_manager=am, show_tqdm=True)\n",
    "\n",
    "br.run(limit=None, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../tests/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jgould/Documents/AdaptiveLatents/tests\")\n",
    "from test_speed import get_steady_state_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_elapsed, steps_elapsed = get_steady_state_speed(pre_prosvd_A, beh, prosvd_k=4, bw_params={\"num\":1000}, max_steps=5000)\n",
    "print(f\"{steps_elapsed/time_elapsed:.2f} it/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import importlib\n",
    "importlib.reload(al.plotting_functions)\n",
    "al.plotting_functions.compare_metrics([br], offset=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0,1], [0,1], linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polar_path(points):\n",
    "    angles = []\n",
    "    lengths = []\n",
    "    for i in range(1,points.shape[0]-1):\n",
    "        # here we define unit vectors paralell to the i and (i+1)th line segments in `points`\n",
    "        current_segment = points[i] - points[i-1]\n",
    "        next_segment = points[i+1] - points[i]\n",
    "        lengths.append(np.linalg.norm(next_segment))\n",
    "        current_segment /= np.linalg.norm(current_segment)\n",
    "        next_segment /= np.linalg.norm(next_segment)\n",
    "        \n",
    "        # calculate the angle using arccos\n",
    "        angle_magnitude = np.arccos(current_segment @ next_segment)\n",
    "        angle_sign = -np.sign(np.linalg.det(np.column_stack([current_segment, next_segment])))\n",
    "        angle_by_cos = angle_magnitude * angle_sign\n",
    "        \n",
    "        # calculate the angle using atan2\n",
    "        orth_to_current_segment = np.array([[0,-1],[1,0]]) @ current_segment\n",
    "        angle_by_atan2 = np.arctan2(next_segment @ orth_to_current_segment, next_segment @ current_segment)\n",
    "        \n",
    "        # check that both methods give the correct answer\n",
    "        if not np.isclose(-angle_by_cos, angle_by_atan2):\n",
    "            print(f\"{-angle_by_cos} {angle_by_atan2}\")\n",
    "        \n",
    "        \n",
    "        angles.append(angle_by_cos)\n",
    "    return angles, lengths\n",
    "def make_angle_plot(ax, angles, lengths, bins=16, density=True):\n",
    "    bins = np.linspace(-np.pi, np.pi, num=bins+1)\n",
    "    \n",
    "    # Bin data and record counts\n",
    "    n, bins = np.histogram(angles, weights=lengths, bins=bins)\n",
    "    widths = np.diff(bins)\n",
    "    \n",
    "    if density:\n",
    "        # Area to assign each bin\n",
    "        area = n / len(angles)\n",
    "        # Calculate corresponding bin radius\n",
    "        radius = (area/np.pi) ** .5\n",
    "    # Otherwise plot frequency proportional to radius\n",
    "    else:\n",
    "        radius = n\n",
    "    \n",
    "    # Plot data on ax\n",
    "    patches = ax.bar(bins[:-1], radius, zorder=1, align='edge', width=widths,\n",
    "                     edgecolor='C0', fill=False, linewidth=1)\n",
    "    \n",
    "    # Set the direction of the zero angle\n",
    "    ax.set_theta_offset(np.pi/2)\n",
    "    \n",
    "    # Remove ylabels for area plots (they are mostly obstructive)\n",
    "    if density:\n",
    "        ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_high_d(A, fig=None, axs=None):\n",
    "    k = A.shape[1]\n",
    "    if fig is None or axs is None:\n",
    "        fig, axs = plt.subplots(nrows=k, ncols=k, figsize=(8,8), tight_layout=True)\n",
    "    \n",
    "    for i in range(k):\n",
    "        for j in range(k):\n",
    "            if i < j:\n",
    "                axs[i,j].scatter(A[:,i], A[:,j], c=t, s=1)\n",
    "                axs[i,j].set_xticks([])\n",
    "                axs[i,j].set_yticks([])\n",
    "            elif i == j:\n",
    "                axs[i,j].hist(A[:,i], bins=A.shape[0]//100)\n",
    "                axs[i,i].set_xticks([])\n",
    "                axs[i,i].set_yticks([])\n",
    "            else:\n",
    "                axs[i,j].remove()\n",
    "                axs[i,j] = fig.add_subplot(k, k, (i*k +j)+1, projection='polar')\n",
    "                angles, lengths = get_polar_path(A[:,[i,j]])\n",
    "                make_angle_plot(axs[i,j], angles, lengths)\n",
    "                \n",
    "                axs[i,j].set_yticks([])\n",
    "                axs[i,j].set_xticks([0])\n",
    "                axs[i,j].set_xticklabels([\"\"])\n",
    "inspect_high_d(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Some sort of continuity measure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_making_powerpoints():\n",
    "    from pathlib import Path\n",
    "    import io\n",
    "    from pptx import Presentation\n",
    "    from pptx.util import Inches, Pt\n",
    "    \n",
    "    layouts_to_indexes = {\n",
    "        \"title\":0,\n",
    "        \"blank\":6,\n",
    "    }\n",
    "    \n",
    "    prs = Presentation()\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[layouts_to_indexes[\"blank\"]])\n",
    "    \n",
    "    In = Inches(1)\n",
    "    left = top = width = height = Inches(0)\n",
    "    txBox = slide.shapes.add_textbox(0, 0, 3*In, 2*In)\n",
    "    tf = txBox.text_frame\n",
    "    \n",
    "    tf.text = \"This is text inside a textbox\"\n",
    "    \n",
    "    tf.paragraphs[0].font.size = Pt(10)\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='svg')\n",
    "    buf.seek(0)\n",
    "    slide.shapes.add_picture(buf, 1*In, 1*In, 2*In)\n",
    "    \n",
    "    prs.save(Path(\"/home/jgould/Dropbox (University of Michigan)/bwruns\") / \"test.pptx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
