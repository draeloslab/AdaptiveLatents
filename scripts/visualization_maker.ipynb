{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import adaptive_latents as al\n",
    "from adaptive_latents import NumpyTimedDataSource, Bubblewrap, AnimationManager, default_rwd_parameters, SymmetricNoisyRegressor, BWRun\n",
    "from adaptive_latents.input_sources.functional import prosvd_data, clip, zscore\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from proSVD import proSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/home/jgould/Documents/Bubblewrap/generated/datasets/sbp/OnlineTrainingData.mat'\n",
    "mat = loadmat(file, squeeze_me=True, simplify_cells=True)\n",
    "data = mat['OnlineTrainingData']\n",
    "n_channels = data[0]['SpikingBandPower'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)-1):\n",
    "    assert data[i+1]['ExperimentTime'][0] - data[i]['ExperimentTime'][-1] == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = []\n",
    "t = []\n",
    "beh = []\n",
    "for i, trial in enumerate(data):\n",
    "    A_spacer = np.nan * np.zeros((3,n_channels))\n",
    "    t_spacer = np.arange(1,4) + trial['ExperimentTime'][-1]\n",
    "    beh_spacer = t_spacer * np.nan\n",
    "    if i == len(data)-1:\n",
    "        A_spacer = np.zeros((0,n_channels))\n",
    "        t_spacer = []\n",
    "        beh_spacer = []\n",
    "    sub_A_spaced = np.vstack([trial['SpikingBandPower'], A_spacer])\n",
    "    sub_t_spaced = np.hstack([trial['ExperimentTime'], t_spacer])\n",
    "    sub_beh_spaced = np.hstack([trial['FingerAngle'], beh_spacer])\n",
    "    A.append(sub_A_spaced)\n",
    "    t.append(sub_t_spaced)\n",
    "    beh.append(sub_beh_spaced)\n",
    "A = np.vstack(A)\n",
    "t = np.hstack(t) / 1000 # converts to seconds\n",
    "beh = np.hstack(beh)\n",
    "\n",
    "s = t > 1.260\n",
    "A, beh, t = A[s], beh[s], t[s]\n",
    "\n",
    "\n",
    "bin_size = 150\n",
    "aug = np.column_stack([t,beh, A])\n",
    "binned_aug = aug[aug.shape[0] % bin_size:,:].reshape(( -1, bin_size, aug.shape[1]))\n",
    "t = binned_aug[:,:,0].max(axis=1)\n",
    "beh = np.nanmean(binned_aug[:,:,1], axis=1)\n",
    "A = np.nanmean(binned_aug[:,:,2:], axis=1)\n",
    "\n",
    "# kernel = np.exp(np.linspace(-3,0, 10))\n",
    "# kernel /= kernel.sum()\n",
    "# kernel = np.flip(kernel)\n",
    "\n",
    "# A, beh, t = clip(zscore(A), beh, t)\n",
    "edge = 100\n",
    "pre_pro_A = (A[edge:] - A[:edge].mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_pro_A, raw_behavior, bin_centers, beh_t = al.input_sources.datasets.construct_indy_data(\n",
    "#     individual_identifier=al.input_sources.datasets.individual_identifiers[\"indy\"][0], \n",
    "#     bin_width=.03\n",
    "# )\n",
    "# resampled_behavior = al.input_sources.functional.resample_behavior(raw_behavior, bin_centers, beh_t)\n",
    "# beh = resampled_behavior\n",
    "# t = bin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(pre_pro_A)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "var_explained = np.cumsum([0] + list(pca.explained_variance_ratio_))\n",
    "ax.plot(var_explained, '.-')\n",
    "ax.set_ylim([0,1])\n",
    "cutoff = np.nonzero(var_explained > .9)[0][0]\n",
    "ax.axvline(cutoff, color='k', alpha=.5)\n",
    "ax.axhline(.9, color='k', alpha=.25)\n",
    "ax.text(.65,.1, f'n_components $\\\\approx$ {cutoff}', transform=ax.transAxes)\n",
    "ax.set_ylabel(\"cumulative variance explained\")\n",
    "ax.set_xlabel(\"number of components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prosvd_data_and_Qs(input_arr, output_d, init_size):\n",
    "    pro = proSVD(k=output_d)\n",
    "    pro.initialize(input_arr[:init_size].T)\n",
    "\n",
    "    output = []\n",
    "    old_Qs = []\n",
    "    for i in range(init_size, len(input_arr)):\n",
    "        obs = input_arr[i:i + 1, :]\n",
    "        if np.any(np.isnan(obs)):\n",
    "            output.append(np.zeros(output_d) * np.nan)\n",
    "            continue\n",
    "        old_Qs.append(np.array(pro.Q))\n",
    "        pro.preupdate()\n",
    "        pro.updateSVD(obs.T)\n",
    "        pro.postupdate()\n",
    "\n",
    "        obs = obs @ pro.Q\n",
    "\n",
    "        output.append(obs)\n",
    "    return np.array(output).reshape((-1, output_d)), np.array(old_Qs)\n",
    "\n",
    "A, Qs = prosvd_data_and_Qs(pre_pro_A, 7, 50)\n",
    "A, t, beh = clip(A, t, beh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "dQ = np.linalg.norm(np.diff(Qs, axis=0), axis=1)\n",
    "dt = np.diff(t)\n",
    "ax.plot(t[:-1], dQ/dt[:,None]);\n",
    "ax.set_ylabel(\"$\\\\frac{ \\\\Vert dQ \\\\Vert}{dt}$\");\n",
    "ax.set_title(\"Change in proSVD vectors over time\");\n",
    "ax.set_xlabel(\"time (s)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, axs = plt.subplots(nrows=3, ncols=3, sharey='row')\n",
    "\n",
    "slice_half_width = 20\n",
    "time_slices = [slice(0,slice_half_width*2), \n",
    "               slice(len(t)//2-slice_half_width, len(t)//2+slice_half_width) , \n",
    "               slice(-slice_half_width*2, -1)]\n",
    "for i in range(3):\n",
    "    s = time_slices[i]\n",
    "    axs[0,i].plot(t[s],beh[s])\n",
    "    axs[0,i].set_xlim([min(t[s]), max(t[s])])\n",
    "    axs[1,i].imshow(A[s,:].T, aspect='auto', interpolation='none')\n",
    "    axs[1,i].set_xticks([])\n",
    "    axs[2,i].plot(t[s],A[s,:], color='k', alpha=.25)\n",
    "    axs[2,i].set_xlim([min(t[s]), max(t[s])])\n",
    "\n",
    "axs[0,0].set_title(f\"first {slice_half_width*2} points\")\n",
    "axs[0,1].set_title(f\"middle {slice_half_width*2} points\")\n",
    "axs[0,2].set_title(f\"last {slice_half_width*2} points\")\n",
    "\n",
    "axs[0,0].set_ylabel(\"Behavior\")\n",
    "axs[1,0].set_ylabel(\"Neural Latents\")\n",
    "axs[2,0].set_ylabel(\"Neural Latents\")\n",
    "axs[2,1].set_xlabel(\"time (s)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptive_latents import default_rwd_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ds = NumpyTimedDataSource(A, t, time_offsets=(1,))\n",
    "out_ds = NumpyTimedDataSource(beh, t, time_offsets=(1,))\n",
    "\n",
    "# define the adaptive_latents object\n",
    "bw = Bubblewrap(dim=in_ds.output_shape,  **dict(default_rwd_parameters, M=300, num=100, num_grad_q=3))\n",
    "\n",
    "# define the (optional) method to regress the HMM state from `bw.alpha`\n",
    "# reg = SymmetricNoisyRegressor(input_d=bw.N, output_d=1)\n",
    "reg = SymmetricNoisyRegressor(input_d=bw.N, output_d=out_ds.output_shape)\n",
    "\n",
    "class CustomAnimation(AnimationManager):\n",
    "    n_rows = 1\n",
    "    n_cols = 1\n",
    "    figsize = (15,10)\n",
    "    extension = \"mp4\"\n",
    "    fps=10\n",
    "\n",
    "    def custom_draw_frame(self, step, bw: Bubblewrap, br: BWRun):\n",
    "        historical_observations = br.obs_ds.get_history()\n",
    "\n",
    "        # al.plotting_functions.show_data_2d(self.ax[0,0], historical_observations, bw, n=7)\n",
    "        al.plotting_functions.show_bubbles_2d(self.ax[0,0], historical_observations, bw, n_sds=3)\n",
    "        self.ax[0,0].set_title(f\"Step {step}\")\n",
    "        \n",
    "    def frame_draw_condition(self, step_number, bw):\n",
    "        return (step_number % 10 == 0) and (step_number > 100)\n",
    "        \n",
    "# am = CustomAnimation()\n",
    "am = None\n",
    "\n",
    "br = BWRun(bw=bw, obs_ds=in_ds, beh_ds=out_ds, behavior_regressor=reg, animation_manager=am, show_tqdm=True)\n",
    "\n",
    "br.run(limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "al.plotting_functions.compare_metrics([br], offset=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polar_path(points):\n",
    "    angles = []\n",
    "    lengths = []\n",
    "    for i in range(1,points.shape[0]-1):\n",
    "        # here we define unit vectors paralell to the i and (i+1)th line segments in `points`\n",
    "        current_segment = points[i] - points[i-1]\n",
    "        next_segment = points[i+1] - points[i]\n",
    "        lengths.append(np.linalg.norm(next_segment))\n",
    "        current_segment /= np.linalg.norm(current_segment)\n",
    "        next_segment /= np.linalg.norm(next_segment)\n",
    "        \n",
    "        # calculate the angle using arccos\n",
    "        angle_magnitude = np.arccos(current_segment @ next_segment)\n",
    "        angle_sign = -np.sign(np.linalg.det(np.column_stack([current_segment, next_segment])))\n",
    "        angle_by_cos = angle_magnitude * angle_sign\n",
    "        \n",
    "        # calculate the angle using atan2\n",
    "        orth_to_current_segment = np.array([[0,-1],[1,0]]) @ current_segment\n",
    "        angle_by_atan2 = np.arctan2(next_segment @ orth_to_current_segment, next_segment @ current_segment)\n",
    "        \n",
    "        # check that both methods give the correct answer\n",
    "        if not np.isclose(-angle_by_cos, angle_by_atan2):\n",
    "            print(f\"{-angle_by_cos} {angle_by_atan2}\")\n",
    "        \n",
    "        \n",
    "        angles.append(angle_by_cos)\n",
    "    return angles, lengths\n",
    "def make_angle_plot(ax, angles, lengths, bins=16, density=True):\n",
    "    bins = np.linspace(-np.pi, np.pi, num=bins+1)\n",
    "    \n",
    "    # Bin data and record counts\n",
    "    n, bins = np.histogram(angles, weights=lengths, bins=bins)\n",
    "    widths = np.diff(bins)\n",
    "    \n",
    "    if density:\n",
    "        # Area to assign each bin\n",
    "        area = n / len(angles)\n",
    "        # Calculate corresponding bin radius\n",
    "        radius = (area/np.pi) ** .5\n",
    "    # Otherwise plot frequency proportional to radius\n",
    "    else:\n",
    "        radius = n\n",
    "    \n",
    "    # Plot data on ax\n",
    "    patches = ax.bar(bins[:-1], radius, zorder=1, align='edge', width=widths,\n",
    "                     edgecolor='C0', fill=False, linewidth=1)\n",
    "    \n",
    "    # Set the direction of the zero angle\n",
    "    ax.set_theta_offset(np.pi/2)\n",
    "    \n",
    "    # Remove ylabels for area plots (they are mostly obstructive)\n",
    "    if density:\n",
    "        ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_high_d(A, fig=None, axs=None):\n",
    "    k = A.shape[1]\n",
    "    if fig is None or axs is None:\n",
    "        fig, axs = plt.subplots(nrows=k, ncols=k, figsize=(8,8), tight_layout=True)\n",
    "    \n",
    "    for i in range(k):\n",
    "        for j in range(k):\n",
    "            if i < j:\n",
    "                axs[i,j].scatter(A[:,i], A[:,j], c=t, s=1)\n",
    "                axs[i,j].set_xticks([])\n",
    "                axs[i,j].set_yticks([])\n",
    "            elif i == j:\n",
    "                axs[i,j].hist(A[:,i], bins=A.shape[0]//100)\n",
    "                axs[i,i].set_xticks([])\n",
    "                axs[i,i].set_yticks([])\n",
    "            else:\n",
    "                axs[i,j].remove()\n",
    "                axs[i,j] = fig.add_subplot(k, k, (i*k +j)+1, projection='polar')\n",
    "                angles, lengths = get_polar_path(A[:,[i,j]])\n",
    "                make_angle_plot(axs[i,j], angles, lengths)\n",
    "                \n",
    "                axs[i,j].set_yticks([])\n",
    "                axs[i,j].set_xticks([0])\n",
    "                axs[i,j].set_xticklabels([\"\"])\n",
    "inspect_high_d(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Some sort of continuity measure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_making_powerpoints():\n",
    "    from pathlib import Path\n",
    "    import io\n",
    "    from pptx import Presentation\n",
    "    from pptx.util import Inches, Pt\n",
    "    \n",
    "    layouts_to_indexes = {\n",
    "        \"title\":0,\n",
    "        \"blank\":6,\n",
    "    }\n",
    "    \n",
    "    prs = Presentation()\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[layouts_to_indexes[\"blank\"]])\n",
    "    \n",
    "    In = Inches(1)\n",
    "    left = top = width = height = Inches(0)\n",
    "    txBox = slide.shapes.add_textbox(0, 0, 3*In, 2*In)\n",
    "    tf = txBox.text_frame\n",
    "    \n",
    "    tf.text = \"This is text inside a textbox\"\n",
    "    \n",
    "    tf.paragraphs[0].font.size = Pt(10)\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='svg')\n",
    "    buf.seek(0)\n",
    "    slide.shapes.add_picture(buf, 1*In, 1*In, 2*In)\n",
    "    \n",
    "    prs.save(Path(\"/home/jgould/Dropbox (University of Michigan)/bwruns\") / \"test.pptx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
