{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import adaptive_latents as al\n",
    "import glob\n",
    "import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the same script, using cpu and gpu\n",
    "subprocess.call([\"python\", \"run_example.py\", \"gpu\"])\n",
    "subprocess.call([\"python\", \"run_example.py\", \"cpu\"])\n",
    "backends = [\"gpu\", \"cpu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the two most recent bubblewrap runs\n",
    "files = sorted(glob.glob(f\"{al.CONFIG[\"output_path\"]/\"bubblewrap_runs\"}/*.pickle\"))\n",
    "brs = []\n",
    "for file in files[-2:]:\n",
    "    with open(file, 'br') as fhan:\n",
    "        brs.append(pickle.load(fhan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish there's still a divergence\n",
    "%matplotlib inline\n",
    "al.plotting_functions.compare_metrics(brs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=5, ncols=2, layout='tight', figsize=(10,10), sharey=\"row\")\n",
    "for i in range(2):\n",
    "    br = brs[i]\n",
    "\n",
    "    log_Q = np.log(np.abs(br.h.Q))\n",
    "    axs[0,i].plot(log_Q)\n",
    "    axs[0,i].set_title(f\"{backends[i]} Q\")\n",
    "    for j in range(0,4):\n",
    "        axs[j+1,i].plot(np.squeeze(br.h.Q_parts[:, j, :]))\n",
    "        axs[j+1,i].set_title(f\"{backends[i]} Q_{{{j}}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, squeeze=False, figsize=(10,3))\n",
    "for i in [0,1]:\n",
    "    axs[0,i].plot(np.squeeze(brs[i].h.Q_parts[:, 0, :]) + np.squeeze(brs[i].h.Q_parts[:, 1, :]));\n",
    "    axs[0,i].set_ylim([-200, 10])\n",
    "    axs[0,i].set_title(f\"{backends[i]} Q_0 + Q_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, squeeze=False, figsize=(10,3))\n",
    "for i in [0,1]:\n",
    "    axs[0,i].plot(np.squeeze(brs[i].h.Q_parts[:, 2, :]) + np.squeeze(brs[i].h.Q_parts[:, 3, :]));\n",
    "    axs[0,i].set_ylim([-1000, 1000])\n",
    "    axs[0,i].set_title(f\"{backends[i]} Q_2 + Q_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the entropy divergence can be reconstructed offline\n",
    "%matplotlib inline\n",
    "entropies = []\n",
    "\n",
    "for br in brs:\n",
    "    entropies.append([])\n",
    "    for i in np.arange(br.alpha_history[1].shape[0]):\n",
    "        p = br.alpha_history[0][i] @ br.A_history[i]\n",
    "        entropies[-1].append(-(p @ np.log2(p)).mean())\n",
    "entropies = np.array(entropies)\n",
    "plt.plot(entropies.T)\n",
    "\n",
    "first_divergence_index = np.nonzero(np.abs(np.diff(entropies, axis=0)) > 1)[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## B and pre_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show how B is different in the cpu vs gpu runs \n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True, figsize=(12,3), layout='tight');\n",
    "ax[0].imshow(brs[0].B_history, interpolation='none', aspect='auto', vmin=0, vmax=1);\n",
    "img = ax[1].imshow(brs[1].B_history, interpolation='none', aspect='auto', vmin=0, vmax=1);\n",
    "fig.colorbar(img)\n",
    "\n",
    "ax[0].set_ylabel(\"timestep\");\n",
    "ax[0].set_xlabel(\"bubble #\");\n",
    "ax[1].set_xlabel(\"bubble #\");\n",
    "\n",
    "ax[0].set_title(\"gpu B history\");\n",
    "ax[1].set_title(\"cpu B history\");\n",
    "\n",
    "\n",
    "ax[0].set_ylim([270,200]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the pre-exp B to real B on the GPU\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True, figsize=(12,3));\n",
    "ax[0].imshow(brs[0].B_history, interpolation='none', aspect='auto');\n",
    "ax[1].imshow(brs[0].pre_B_history, interpolation='none', aspect='auto', vmin = -12.5e3);\n",
    "ax[0].set_ylim([260,150]);\n",
    "ax[0].set_title(\"GPU B\")\n",
    "ax[1].set_title(\"GPU pre_B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Note that you can manually suppress B elements beyond 10 but it doesn't help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare pre_B on gpu and cpu\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True, figsize=(12,3));\n",
    "img = ax[0].imshow(brs[0].pre_B_history, interpolation='none', aspect='auto', vmin = -12.5e3);\n",
    "img = ax[1].imshow(brs[1].pre_B_history, interpolation='none', aspect='auto', vmin = -12.5e3);\n",
    "fig.colorbar(img);\n",
    "ax[0].set_ylim([260,150]);\n",
    "ax[0].set_title(\"GPU pre_B\")\n",
    "ax[1].set_title(\"CPU pre_B\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the transition from a \"good\" B to a \"bad\" B \n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(nrows=2, figsize=(5,10), sharex=True)\n",
    "k = 0\n",
    "i = 255\n",
    "\n",
    "\n",
    "ax[0].plot(brs[k].pre_B_history[(i-1)-1])\n",
    "ax[0].plot(brs[k].pre_B_history[(i)-1])\n",
    "ax[0].set_title(f\"{backends[k]} Pre_B's\")\n",
    "ax[0].set_ylim([0,10])\n",
    "\n",
    "ax[1].plot(brs[k].B_history[i-1], label=\"t=254\")\n",
    "ax[1].plot(brs[k].B_history[i], label=\"t=255\")\n",
    "ax[1].set_title(f\"{backends[k]} B's\")\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the normalization or b_exp didn't cause the issue\n",
    "%matplotlib inline\n",
    "i=255\n",
    "k = 0\n",
    "B = np.array(brs[k].pre_B_history[i-1])\n",
    "print(f\"{np.argmax(B)}: {B.max()}\")\n",
    "B -= B.max()\n",
    "B = np.exp(B)\n",
    "plt.plot(B, label=backends[k])\n",
    "\n",
    "B = np.array(brs[1-k].pre_B_history[i-1])\n",
    "print(f\"{np.argmax(B)}: {B.max()}\")\n",
    "B -= B.max()\n",
    "B = np.exp(B)\n",
    "plt.plot(B,label=backends[1-k])\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## logB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_logB(x, mu, L, L_diag):\n",
    "    n = mu.shape[0]\n",
    "    B = (-1 / 2) * np.linalg.norm((x - mu) @ L) ** 2 - (n / 2) * np.log(2 * np.pi) + np.sum(L_diag)\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 255\n",
    "B = [[], []]\n",
    "for k in [0,1]:\n",
    "    for m in range(200):\n",
    "        L = brs[k].L_history[i-1][m]\n",
    "        L_diag = brs[k].L_diag_history[i-1][m]\n",
    "        mu = brs[k].mu_history[i-1][m]\n",
    "        x = brs[k].input_ds.get_history()[0][i + 30]\n",
    "        B[k].append(single_logB(x, mu, L, L_diag))\n",
    "B = np.array(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show there isn't a problem in the logB calculations\n",
    "k = 0\n",
    "plt.plot(brs[k].pre_B_history[i-1])\n",
    "plt.plot(B[k])\n",
    "np.allclose(B[k], brs[k].pre_B_history[i-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the on-bubble at i=254 has high probability\n",
    "i = 254\n",
    "k = 0\n",
    "m = 4\n",
    "\n",
    "L = brs[k].L_history[i-1][m]\n",
    "L_diag = brs[k].L_diag_history[i-1][m]\n",
    "mu = brs[k].mu_history[i-1][m]\n",
    "x = brs[k].input_ds.get_history()[0][i + 30]\n",
    "\n",
    "logB = single_logB(x, mu, L, L_diag)\n",
    "assert np.allclose(brs[k].pre_B_history[i-1,m], logB)\n",
    "logB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the on-bubble at i=255 has low probability\n",
    "i = 255\n",
    "k = 0\n",
    "m = 5\n",
    "\n",
    "L = brs[k].L_history[i-1][m]\n",
    "L_diag = brs[k].L_diag_history[i-1][m]\n",
    "mu = brs[k].mu_history[i-1][m]\n",
    "x = brs[k].input_ds.get_history()[0][i + 30]\n",
    "\n",
    "logB = single_logB(x, mu, L, L_diag)\n",
    "assert np.allclose(brs[k].pre_B_history[i-1,m], logB)\n",
    "logB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the on-bubble at i=255 should have had high probability\n",
    "k = 0\n",
    "m = 5\n",
    "\n",
    "i = 254 # i==255 ⇔ bw_step==285\n",
    "L = brs[k].L_history[i-1][m]\n",
    "L_diag = brs[k].L_diag_history[i-1][m]\n",
    "mu = brs[k].mu_history[i-1][m]\n",
    "\n",
    "\n",
    "i = 255\n",
    "x = brs[k].input_ds.get_history()[0][i + 30]\n",
    "\n",
    "n = mu.shape[0]\n",
    "logB = (-1 / 2) * np.linalg.norm((x - mu) @ L) ** 2 - (n / 2) * np.log(2 * np.pi) + np.sum(L_diag)\n",
    "logB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show that it's mu's fault\n",
    "k = 0\n",
    "m = 5\n",
    "\n",
    "i = 254 # i==255 ⇔ bw_step==285\n",
    "mu = brs[k].mu_history[i-1][m]\n",
    "\n",
    "\n",
    "i = 255\n",
    "x = brs[k].input_ds.get_history()[0][i + 30]\n",
    "L_diag = brs[k].L_diag_history[i-1][m]\n",
    "L = brs[k].L_history[i-1][m]\n",
    "# print(brs[k].mu_history[i-1][m] - mu)\n",
    "\n",
    "\n",
    "n = mu.shape[0]\n",
    "logB = (-1 / 2) * np.linalg.norm((x - mu) @ L) ** 2 - (n / 2) * np.log(2 * np.pi) + np.sum(L_diag)\n",
    "logB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "brs[k].mu_history[255-1][m] - brs[k].mu_history[(255-1)-1][m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "m = 5\n",
    "\n",
    "k = 0\n",
    "l = []\n",
    "for i in range(450):    \n",
    "    L = brs[k].L_history[i-1][m]\n",
    "    L_diag = brs[k].L_diag_history[i-1][m]\n",
    "    mu = brs[k].mu_history[i-1][m]\n",
    "    \n",
    "    i = i+1\n",
    "    x = brs[k].obs_ds.get_history()[0][i + 30]\n",
    "    \n",
    "    l.append(single_logB(x, mu, L, L_diag))\n",
    "ax.plot(l)\n",
    "\n",
    "k = 1\n",
    "l = []\n",
    "for i in range(450):    \n",
    "    L = brs[k].L_history[i-1][m]\n",
    "    L_diag = brs[k].L_diag_history[i-1][m]\n",
    "    mu = brs[k].mu_history[i-1][m]\n",
    "    \n",
    "    i = i+1\n",
    "    x = brs[k].obs_ds.get_history()[0][i + 30]\n",
    "    \n",
    "    l.append(single_logB(x, mu, L, L_diag))\n",
    "ax.plot(l)\n",
    "\n",
    "ax.set_ylim([-2e4,2e3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "m = 5\n",
    "\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "gpu_line = np.log(np.linalg.det(brs[k].L_history[:, m, ...]))\n",
    "ax.plot(gpu_line, label='gpu')\n",
    "cpu_line = np.log(np.linalg.det(brs[1-k].L_history[:, m, ...]))\n",
    "ax.plot(cpu_line, label='cpu')\n",
    "ax.set_title(f\"log-determinant of L for bubble {m} per iteration\");\n",
    "ax.axvline(first_divergence_index, color='k', alpha=.25)\n",
    "ax.legend();\n",
    "print(gpu_line[first_divergence_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "(460, 9.8)\n",
    "(178, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "i = -300\n",
    "m = 5\n",
    "\n",
    "for k in [0,1]:\n",
    "    L = brs[k].L_history[i,m,...]\n",
    "    mu = brs[k].mu_history[i,m,:]\n",
    "    al.plotting_functions.add_2d_bubble(ax, L, mu, 3, alpha=.5, facecolor=[\"red\", 'blue'][k])\n",
    "\n",
    "ax.set_xlim(mu[0] + np.array([-1,1])*.05)\n",
    "ax.set_ylim(mu[1] + np.array([-1,1])*.05)\n",
    "ax.axis('scaled');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "i=50\n",
    "\n",
    "m = 5\n",
    "for k in [0,1]:\n",
    "    ratios = []\n",
    "    for i in range(brs[k].L_history.shape[0]):\n",
    "        L = brs[k].L_history[i,m,...]\n",
    "        _, s, _= np.linalg.svd(np.linalg.pinv(L.T@L))\n",
    "        ratios.append(s.max() / s.min())\n",
    "    ratios = np.log(ratios)\n",
    "    if backends[k] == 'gpu':\n",
    "        print(ratios[first_divergence_index])\n",
    "    ax.plot(ratios, label=backends[k])\n",
    "\n",
    "ax.set_title(\"log aspect ratio\");\n",
    "ax.legend();\n",
    "ax.axvline(first_divergence_index, color='k', alpha=.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "m=1\n",
    "plt.plot(np.log(np.abs(np.diff(brs[k].L_history[:, m, ...], axis=0))).reshape([-1,4]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "m=3\n",
    "plt.plot(np.log(np.abs(np.diff(brs[k].L_diag_history[:, m, ...], axis=0))).reshape([brs[k].L_diag_history.shape[0]-1,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "print(brs[k].bw.backend_note)\n",
    "Q = brs[k].model_step_variable_history['Q'];\n",
    "plt.plot(np.log(Q));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
